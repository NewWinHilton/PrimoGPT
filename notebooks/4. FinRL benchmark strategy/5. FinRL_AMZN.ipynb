{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FinRL and stable_baselines3 for machine learning and trading\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_primo_trading.env_primo_default import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "# Configuration files and helper functions from FinRL\n",
    "from finrl.config import INDICATORS\n",
    "from finrl.main import check_and_make_directories\n",
    "\n",
    "# Enabling chart display within Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "TRAINED_MODEL_DIR = 'files/models_AMZN'\n",
    "RESULTS_DIR = 'files/results_AMZN'\n",
    "DATA_DIR = 'files/data_AMZN'\n",
    "\n",
    "# Checking and creating directories\n",
    "check_and_make_directories([TRAINED_MODEL_DIR, DATA_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a class called YahooDownloader that uses yfinance to fetch data from Yahoo Finance.\n",
    "\n",
    "In the YahooDownloader of FinRL, we modified the data frame into a format suitable for further data processing. We use a custom closing price instead of the regular closing price and add a column that represents the day of the week (0-4 corresponding to Monday-Friday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and trading intervals\n",
    "TRAIN_START_DATE = '2022-04-01'\n",
    "TRAIN_END_DATE = '2024-07-31'\n",
    "TRADE_START_DATE = '2024-08-01'\n",
    "TRADE_END_DATE = '2025-02-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (729, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetching all data\n",
    "df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                         end_date = TRADE_END_DATE,\n",
    "                         ticker_list = ['AMZN']).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>165.826996</td>\n",
       "      <td>164.149506</td>\n",
       "      <td>57090000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>168.346497</td>\n",
       "      <td>168.346497</td>\n",
       "      <td>168.394501</td>\n",
       "      <td>164.125000</td>\n",
       "      <td>49882000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>164.054993</td>\n",
       "      <td>164.054993</td>\n",
       "      <td>168.110504</td>\n",
       "      <td>167.741501</td>\n",
       "      <td>53728000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>158.755997</td>\n",
       "      <td>158.755997</td>\n",
       "      <td>162.199997</td>\n",
       "      <td>161.650497</td>\n",
       "      <td>79056000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>157.784500</td>\n",
       "      <td>157.784500</td>\n",
       "      <td>160.078995</td>\n",
       "      <td>158.399994</td>\n",
       "      <td>68136000</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close    volume   tic  \\\n",
       "0  2022-04-01  163.559998  163.559998  165.826996  164.149506  57090000  AMZN   \n",
       "1  2022-04-04  168.346497  168.346497  168.394501  164.125000  49882000  AMZN   \n",
       "2  2022-04-05  164.054993  164.054993  168.110504  167.741501  53728000  AMZN   \n",
       "3  2022-04-06  158.755997  158.755997  162.199997  161.650497  79056000  AMZN   \n",
       "4  2022-04-07  157.784500  157.784500  160.078995  158.399994  68136000  AMZN   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    0  \n",
       "2    1  \n",
       "3    2  \n",
       "4    3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the defined class FeatureEngineer to process data and add technical indicators.\n",
    "\n",
    "The use_vix option includes the VIX index, known as the \"fear index,\" which represents the expected volatility of the stock market based on S&P 500 options. The VIX helps the model understand market uncertainty, with higher values indicating greater uncertainty.\n",
    "\n",
    "The use_turbulence option includes the turbulence index, which measures unusual market fluctuations and serves as an indicator of risk and market shocks. It is useful for identifying periods of high volatility, helping the model to adapt to financial crises.\n",
    "\n",
    "Overall, a quite handy class that contains useful methods for processing financial data and can be applied to numerous other purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Shape of DataFrame:  (728, 8)\n",
      "Successfully added vix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_vix=True,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of unique stock tickers from the 'tic' column of the 'processed' DataFrame.\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "\n",
    "# Creates a list of dates between the earliest and latest dates in the 'processed' DataFrame, converting them to strings.\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "\n",
    "# Creates combinations of all dates and stock tickers using the Cartesian product.\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# Creates a new DataFrame 'processed_full' with columns \"date\" and \"tic\", containing all combinations of dates and stock tickers.\n",
    "# Merges this DataFrame with the original 'processed' DataFrame based on the \"date\" and \"tic\" columns, using a 'left' join.\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "\n",
    "# Filters the 'processed_full' DataFrame to only include rows where the dates are present in the original 'processed' DataFrame.\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "\n",
    "# Sorts the 'processed_full' DataFrame by date and stock ticker.\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# Replaces all missing values (NaN) with 0 in the 'processed_full' DataFrame.\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>163.559998</td>\n",
       "      <td>165.826996</td>\n",
       "      <td>164.149506</td>\n",
       "      <td>57090000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.171909</td>\n",
       "      <td>164.102597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>164.149506</td>\n",
       "      <td>164.149506</td>\n",
       "      <td>20.620001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>168.346497</td>\n",
       "      <td>168.346497</td>\n",
       "      <td>168.394501</td>\n",
       "      <td>164.125000</td>\n",
       "      <td>49882000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>164.171909</td>\n",
       "      <td>164.102597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>164.137253</td>\n",
       "      <td>164.137253</td>\n",
       "      <td>20.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>164.054993</td>\n",
       "      <td>164.054993</td>\n",
       "      <td>168.110504</td>\n",
       "      <td>167.741501</td>\n",
       "      <td>53728000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111447</td>\n",
       "      <td>169.500568</td>\n",
       "      <td>161.176770</td>\n",
       "      <td>99.349244</td>\n",
       "      <td>39.500002</td>\n",
       "      <td>88.434139</td>\n",
       "      <td>165.338669</td>\n",
       "      <td>165.338669</td>\n",
       "      <td>18.790001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>158.755997</td>\n",
       "      <td>158.755997</td>\n",
       "      <td>162.199997</td>\n",
       "      <td>161.650497</td>\n",
       "      <td>79056000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.060259</td>\n",
       "      <td>169.431625</td>\n",
       "      <td>159.401627</td>\n",
       "      <td>36.378815</td>\n",
       "      <td>-125.835733</td>\n",
       "      <td>16.066422</td>\n",
       "      <td>164.416626</td>\n",
       "      <td>164.416626</td>\n",
       "      <td>21.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>157.784500</td>\n",
       "      <td>157.784500</td>\n",
       "      <td>160.078995</td>\n",
       "      <td>158.399994</td>\n",
       "      <td>68136000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.281638</td>\n",
       "      <td>170.128684</td>\n",
       "      <td>156.297915</td>\n",
       "      <td>26.949055</td>\n",
       "      <td>-106.928906</td>\n",
       "      <td>30.395985</td>\n",
       "      <td>163.213300</td>\n",
       "      <td>163.213300</td>\n",
       "      <td>21.969999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>154.460495</td>\n",
       "      <td>154.460495</td>\n",
       "      <td>157.368500</td>\n",
       "      <td>156.750000</td>\n",
       "      <td>46002000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.479978</td>\n",
       "      <td>170.266737</td>\n",
       "      <td>154.005429</td>\n",
       "      <td>23.720351</td>\n",
       "      <td>-109.964746</td>\n",
       "      <td>43.212759</td>\n",
       "      <td>162.136083</td>\n",
       "      <td>162.136083</td>\n",
       "      <td>21.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>151.121994</td>\n",
       "      <td>151.121994</td>\n",
       "      <td>154.136505</td>\n",
       "      <td>152.712997</td>\n",
       "      <td>52112000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.781791</td>\n",
       "      <td>171.077267</td>\n",
       "      <td>150.502589</td>\n",
       "      <td>18.201080</td>\n",
       "      <td>-126.437729</td>\n",
       "      <td>53.723833</td>\n",
       "      <td>160.789928</td>\n",
       "      <td>160.789928</td>\n",
       "      <td>23.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>150.787506</td>\n",
       "      <td>150.787506</td>\n",
       "      <td>155.098999</td>\n",
       "      <td>153.692505</td>\n",
       "      <td>55178000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.925010</td>\n",
       "      <td>170.668324</td>\n",
       "      <td>149.137176</td>\n",
       "      <td>22.714744</td>\n",
       "      <td>-94.698242</td>\n",
       "      <td>53.723833</td>\n",
       "      <td>159.902750</td>\n",
       "      <td>159.902750</td>\n",
       "      <td>24.940001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-04-13</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>155.541000</td>\n",
       "      <td>155.541000</td>\n",
       "      <td>156.024994</td>\n",
       "      <td>150.018494</td>\n",
       "      <td>53390000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.192394</td>\n",
       "      <td>170.839114</td>\n",
       "      <td>146.769885</td>\n",
       "      <td>18.708962</td>\n",
       "      <td>-74.727641</td>\n",
       "      <td>19.043029</td>\n",
       "      <td>158.804499</td>\n",
       "      <td>158.804499</td>\n",
       "      <td>23.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>151.706497</td>\n",
       "      <td>151.706497</td>\n",
       "      <td>155.897003</td>\n",
       "      <td>155.389999</td>\n",
       "      <td>51598000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.088037</td>\n",
       "      <td>170.013072</td>\n",
       "      <td>146.913026</td>\n",
       "      <td>35.825652</td>\n",
       "      <td>-62.569933</td>\n",
       "      <td>19.548587</td>\n",
       "      <td>158.463049</td>\n",
       "      <td>158.463049</td>\n",
       "      <td>21.719999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>152.785004</td>\n",
       "      <td>152.785004</td>\n",
       "      <td>154.039505</td>\n",
       "      <td>151.523499</td>\n",
       "      <td>46514000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.203359</td>\n",
       "      <td>169.561397</td>\n",
       "      <td>146.102966</td>\n",
       "      <td>30.969844</td>\n",
       "      <td>-75.702954</td>\n",
       "      <td>26.444684</td>\n",
       "      <td>157.832181</td>\n",
       "      <td>157.832181</td>\n",
       "      <td>24.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>158.115494</td>\n",
       "      <td>158.115494</td>\n",
       "      <td>158.649002</td>\n",
       "      <td>152.029495</td>\n",
       "      <td>54926000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.243741</td>\n",
       "      <td>169.023017</td>\n",
       "      <td>145.674231</td>\n",
       "      <td>32.213678</td>\n",
       "      <td>-26.653297</td>\n",
       "      <td>0.795533</td>\n",
       "      <td>157.348624</td>\n",
       "      <td>157.348624</td>\n",
       "      <td>22.549999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>153.998001</td>\n",
       "      <td>153.998001</td>\n",
       "      <td>157.602493</td>\n",
       "      <td>157.602493</td>\n",
       "      <td>59630000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.942382</td>\n",
       "      <td>168.546419</td>\n",
       "      <td>146.189885</td>\n",
       "      <td>43.759769</td>\n",
       "      <td>-24.085172</td>\n",
       "      <td>4.720803</td>\n",
       "      <td>157.368152</td>\n",
       "      <td>157.368152</td>\n",
       "      <td>21.129999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>148.296005</td>\n",
       "      <td>148.296005</td>\n",
       "      <td>156.738007</td>\n",
       "      <td>154.714005</td>\n",
       "      <td>63970000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.871977</td>\n",
       "      <td>168.011601</td>\n",
       "      <td>146.345540</td>\n",
       "      <td>40.097770</td>\n",
       "      <td>-68.806092</td>\n",
       "      <td>7.837060</td>\n",
       "      <td>157.178570</td>\n",
       "      <td>157.178570</td>\n",
       "      <td>20.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>144.350006</td>\n",
       "      <td>144.350006</td>\n",
       "      <td>149.615005</td>\n",
       "      <td>148.250000</td>\n",
       "      <td>73078000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.191340</td>\n",
       "      <td>167.995194</td>\n",
       "      <td>145.171471</td>\n",
       "      <td>33.590312</td>\n",
       "      <td>-144.267449</td>\n",
       "      <td>27.929066</td>\n",
       "      <td>156.583332</td>\n",
       "      <td>156.583332</td>\n",
       "      <td>22.709999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>146.074005</td>\n",
       "      <td>146.074005</td>\n",
       "      <td>146.221497</td>\n",
       "      <td>144.022995</td>\n",
       "      <td>61874000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.675063</td>\n",
       "      <td>168.486458</td>\n",
       "      <td>143.110165</td>\n",
       "      <td>30.267387</td>\n",
       "      <td>-155.975301</td>\n",
       "      <td>34.921287</td>\n",
       "      <td>155.798311</td>\n",
       "      <td>155.798311</td>\n",
       "      <td>30.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>139.391006</td>\n",
       "      <td>139.391006</td>\n",
       "      <td>144.856003</td>\n",
       "      <td>144.800003</td>\n",
       "      <td>77530000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.975097</td>\n",
       "      <td>168.544973</td>\n",
       "      <td>141.757731</td>\n",
       "      <td>31.554939</td>\n",
       "      <td>-163.586655</td>\n",
       "      <td>37.447465</td>\n",
       "      <td>155.151352</td>\n",
       "      <td>155.151352</td>\n",
       "      <td>27.379999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>138.167007</td>\n",
       "      <td>138.167007</td>\n",
       "      <td>141.948502</td>\n",
       "      <td>140.191498</td>\n",
       "      <td>71336000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.471194</td>\n",
       "      <td>169.104345</td>\n",
       "      <td>139.536153</td>\n",
       "      <td>28.343896</td>\n",
       "      <td>-174.327673</td>\n",
       "      <td>42.374578</td>\n",
       "      <td>154.320249</td>\n",
       "      <td>154.320249</td>\n",
       "      <td>31.110001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>144.596497</td>\n",
       "      <td>144.596497</td>\n",
       "      <td>145.937500</td>\n",
       "      <td>142.177994</td>\n",
       "      <td>117316000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.694960</td>\n",
       "      <td>169.091100</td>\n",
       "      <td>138.271265</td>\n",
       "      <td>31.454252</td>\n",
       "      <td>-113.956996</td>\n",
       "      <td>20.637136</td>\n",
       "      <td>153.681183</td>\n",
       "      <td>153.681183</td>\n",
       "      <td>29.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>124.281502</td>\n",
       "      <td>124.281502</td>\n",
       "      <td>130.761002</td>\n",
       "      <td>129.848999</td>\n",
       "      <td>272662000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-3.638564</td>\n",
       "      <td>170.889627</td>\n",
       "      <td>134.089520</td>\n",
       "      <td>24.598825</td>\n",
       "      <td>-239.280056</td>\n",
       "      <td>42.189723</td>\n",
       "      <td>152.489574</td>\n",
       "      <td>152.489574</td>\n",
       "      <td>28.969999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>124.500000</td>\n",
       "      <td>124.500000</td>\n",
       "      <td>124.667999</td>\n",
       "      <td>122.401001</td>\n",
       "      <td>148788000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.816762</td>\n",
       "      <td>172.360917</td>\n",
       "      <td>128.443380</td>\n",
       "      <td>21.650005</td>\n",
       "      <td>-220.661587</td>\n",
       "      <td>48.049182</td>\n",
       "      <td>151.056784</td>\n",
       "      <td>151.056784</td>\n",
       "      <td>33.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>124.253502</td>\n",
       "      <td>124.253502</td>\n",
       "      <td>126.220497</td>\n",
       "      <td>124.053497</td>\n",
       "      <td>79134000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.560699</td>\n",
       "      <td>172.310865</td>\n",
       "      <td>124.486281</td>\n",
       "      <td>23.748023</td>\n",
       "      <td>-178.274877</td>\n",
       "      <td>48.049182</td>\n",
       "      <td>149.829362</td>\n",
       "      <td>149.829362</td>\n",
       "      <td>31.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>125.928497</td>\n",
       "      <td>125.928497</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>123.599998</td>\n",
       "      <td>110746000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-6.102544</td>\n",
       "      <td>170.726912</td>\n",
       "      <td>121.656084</td>\n",
       "      <td>23.568852</td>\n",
       "      <td>-153.510246</td>\n",
       "      <td>43.762446</td>\n",
       "      <td>148.688955</td>\n",
       "      <td>148.688955</td>\n",
       "      <td>29.120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>116.406998</td>\n",
       "      <td>116.406998</td>\n",
       "      <td>123.499001</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>144392000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-6.492602</td>\n",
       "      <td>169.737996</td>\n",
       "      <td>118.779950</td>\n",
       "      <td>23.327965</td>\n",
       "      <td>-158.720565</td>\n",
       "      <td>46.169959</td>\n",
       "      <td>147.618582</td>\n",
       "      <td>147.618582</td>\n",
       "      <td>25.969999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>114.772499</td>\n",
       "      <td>114.772499</td>\n",
       "      <td>119.050499</td>\n",
       "      <td>114.849998</td>\n",
       "      <td>124260000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-7.286053</td>\n",
       "      <td>169.815918</td>\n",
       "      <td>114.347029</td>\n",
       "      <td>20.398403</td>\n",
       "      <td>-164.283613</td>\n",
       "      <td>50.100580</td>\n",
       "      <td>146.307839</td>\n",
       "      <td>146.307839</td>\n",
       "      <td>32.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>108.789001</td>\n",
       "      <td>108.789001</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>111.312500</td>\n",
       "      <td>128124000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.066719</td>\n",
       "      <td>169.834265</td>\n",
       "      <td>109.784932</td>\n",
       "      <td>19.309572</td>\n",
       "      <td>-168.169791</td>\n",
       "      <td>54.041904</td>\n",
       "      <td>144.961864</td>\n",
       "      <td>144.961864</td>\n",
       "      <td>31.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>108.859001</td>\n",
       "      <td>108.859001</td>\n",
       "      <td>112.642502</td>\n",
       "      <td>111.250000</td>\n",
       "      <td>105434000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.585138</td>\n",
       "      <td>169.674635</td>\n",
       "      <td>105.798262</td>\n",
       "      <td>19.290752</td>\n",
       "      <td>-152.447823</td>\n",
       "      <td>55.029552</td>\n",
       "      <td>143.713277</td>\n",
       "      <td>143.713277</td>\n",
       "      <td>33.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>105.372002</td>\n",
       "      <td>105.372002</td>\n",
       "      <td>110.155998</td>\n",
       "      <td>108.103500</td>\n",
       "      <td>109704000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.114290</td>\n",
       "      <td>169.064093</td>\n",
       "      <td>101.849904</td>\n",
       "      <td>18.358862</td>\n",
       "      <td>-149.447485</td>\n",
       "      <td>56.789121</td>\n",
       "      <td>142.441499</td>\n",
       "      <td>142.441499</td>\n",
       "      <td>32.869999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>106.930496</td>\n",
       "      <td>106.930496</td>\n",
       "      <td>110.780502</td>\n",
       "      <td>102.750000</td>\n",
       "      <td>132026000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.807074</td>\n",
       "      <td>168.961225</td>\n",
       "      <td>97.225922</td>\n",
       "      <td>16.920214</td>\n",
       "      <td>-139.676506</td>\n",
       "      <td>52.909816</td>\n",
       "      <td>141.072827</td>\n",
       "      <td>141.072827</td>\n",
       "      <td>33.740002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>113.055000</td>\n",
       "      <td>113.055000</td>\n",
       "      <td>113.183998</td>\n",
       "      <td>109.069000</td>\n",
       "      <td>93684000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.775130</td>\n",
       "      <td>166.565166</td>\n",
       "      <td>94.989882</td>\n",
       "      <td>24.175463</td>\n",
       "      <td>-111.454677</td>\n",
       "      <td>38.935220</td>\n",
       "      <td>140.006032</td>\n",
       "      <td>140.006032</td>\n",
       "      <td>31.090000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   tic        open        high         low       close  \\\n",
       "0   2022-04-01  AMZN  163.559998  163.559998  165.826996  164.149506   \n",
       "3   2022-04-04  AMZN  168.346497  168.346497  168.394501  164.125000   \n",
       "4   2022-04-05  AMZN  164.054993  164.054993  168.110504  167.741501   \n",
       "5   2022-04-06  AMZN  158.755997  158.755997  162.199997  161.650497   \n",
       "6   2022-04-07  AMZN  157.784500  157.784500  160.078995  158.399994   \n",
       "7   2022-04-08  AMZN  154.460495  154.460495  157.368500  156.750000   \n",
       "10  2022-04-11  AMZN  151.121994  151.121994  154.136505  152.712997   \n",
       "11  2022-04-12  AMZN  150.787506  150.787506  155.098999  153.692505   \n",
       "12  2022-04-13  AMZN  155.541000  155.541000  156.024994  150.018494   \n",
       "13  2022-04-14  AMZN  151.706497  151.706497  155.897003  155.389999   \n",
       "17  2022-04-18  AMZN  152.785004  152.785004  154.039505  151.523499   \n",
       "18  2022-04-19  AMZN  158.115494  158.115494  158.649002  152.029495   \n",
       "19  2022-04-20  AMZN  153.998001  153.998001  157.602493  157.602493   \n",
       "20  2022-04-21  AMZN  148.296005  148.296005  156.738007  154.714005   \n",
       "21  2022-04-22  AMZN  144.350006  144.350006  149.615005  148.250000   \n",
       "24  2022-04-25  AMZN  146.074005  146.074005  146.221497  144.022995   \n",
       "25  2022-04-26  AMZN  139.391006  139.391006  144.856003  144.800003   \n",
       "26  2022-04-27  AMZN  138.167007  138.167007  141.948502  140.191498   \n",
       "27  2022-04-28  AMZN  144.596497  144.596497  145.937500  142.177994   \n",
       "28  2022-04-29  AMZN  124.281502  124.281502  130.761002  129.848999   \n",
       "31  2022-05-02  AMZN  124.500000  124.500000  124.667999  122.401001   \n",
       "32  2022-05-03  AMZN  124.253502  124.253502  126.220497  124.053497   \n",
       "33  2022-05-04  AMZN  125.928497  125.928497  126.000000  123.599998   \n",
       "34  2022-05-05  AMZN  116.406998  116.406998  123.499001  123.000000   \n",
       "35  2022-05-06  AMZN  114.772499  114.772499  119.050499  114.849998   \n",
       "38  2022-05-09  AMZN  108.789001  108.789001  114.000000  111.312500   \n",
       "39  2022-05-10  AMZN  108.859001  108.859001  112.642502  111.250000   \n",
       "40  2022-05-11  AMZN  105.372002  105.372002  110.155998  108.103500   \n",
       "41  2022-05-12  AMZN  106.930496  106.930496  110.780502  102.750000   \n",
       "42  2022-05-13  AMZN  113.055000  113.055000  113.183998  109.069000   \n",
       "\n",
       "         volume  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
       "0    57090000.0  4.0  0.000000  164.171909  164.102597   0.000000   66.666667   \n",
       "3    49882000.0  0.0 -0.000550  164.171909  164.102597   0.000000   66.666667   \n",
       "4    53728000.0  1.0  0.111447  169.500568  161.176770  99.349244   39.500002   \n",
       "5    79056000.0  2.0 -0.060259  169.431625  159.401627  36.378815 -125.835733   \n",
       "6    68136000.0  3.0 -0.281638  170.128684  156.297915  26.949055 -106.928906   \n",
       "7    46002000.0  4.0 -0.479978  170.266737  154.005429  23.720351 -109.964746   \n",
       "10   52112000.0  0.0 -0.781791  171.077267  150.502589  18.201080 -126.437729   \n",
       "11   55178000.0  1.0 -0.925010  170.668324  149.137176  22.714744  -94.698242   \n",
       "12   53390000.0  2.0 -1.192394  170.839114  146.769885  18.708962  -74.727641   \n",
       "13   51598000.0  3.0 -1.088037  170.013072  146.913026  35.825652  -62.569933   \n",
       "17   46514000.0  0.0 -1.203359  169.561397  146.102966  30.969844  -75.702954   \n",
       "18   54926000.0  1.0 -1.243741  169.023017  145.674231  32.213678  -26.653297   \n",
       "19   59630000.0  2.0 -0.942382  168.546419  146.189885  43.759769  -24.085172   \n",
       "20   63970000.0  3.0 -0.871977  168.011601  146.345540  40.097770  -68.806092   \n",
       "21   73078000.0  4.0 -1.191340  167.995194  145.171471  33.590312 -144.267449   \n",
       "24   61874000.0  0.0 -1.675063  168.486458  143.110165  30.267387 -155.975301   \n",
       "25   77530000.0  1.0 -1.975097  168.544973  141.757731  31.554939 -163.586655   \n",
       "26   71336000.0  2.0 -2.471194  169.104345  139.536153  28.343896 -174.327673   \n",
       "27  117316000.0  3.0 -2.694960  169.091100  138.271265  31.454252 -113.956996   \n",
       "28  272662000.0  4.0 -3.638564  170.889627  134.089520  24.598825 -239.280056   \n",
       "31  148788000.0  0.0 -4.816762  172.360917  128.443380  21.650005 -220.661587   \n",
       "32   79134000.0  1.0 -5.560699  172.310865  124.486281  23.748023 -178.274877   \n",
       "33  110746000.0  2.0 -6.102544  170.726912  121.656084  23.568852 -153.510246   \n",
       "34  144392000.0  3.0 -6.492602  169.737996  118.779950  23.327965 -158.720565   \n",
       "35  124260000.0  4.0 -7.286053  169.815918  114.347029  20.398403 -164.283613   \n",
       "38  128124000.0  0.0 -8.066719  169.834265  109.784932  19.309572 -168.169791   \n",
       "39  105434000.0  1.0 -8.585138  169.674635  105.798262  19.290752 -152.447823   \n",
       "40  109704000.0  2.0 -9.114290  169.064093  101.849904  18.358862 -149.447485   \n",
       "41  132026000.0  3.0 -9.807074  168.961225   97.225922  16.920214 -139.676506   \n",
       "42   93684000.0  4.0 -9.775130  166.565166   94.989882  24.175463 -111.454677   \n",
       "\n",
       "         dx_30  close_30_sma  close_60_sma        vix  \n",
       "0   100.000000    164.149506    164.149506  20.620001  \n",
       "3   100.000000    164.137253    164.137253  20.750000  \n",
       "4    88.434139    165.338669    165.338669  18.790001  \n",
       "5    16.066422    164.416626    164.416626  21.270000  \n",
       "6    30.395985    163.213300    163.213300  21.969999  \n",
       "7    43.212759    162.136083    162.136083  21.250000  \n",
       "10   53.723833    160.789928    160.789928  23.090000  \n",
       "11   53.723833    159.902750    159.902750  24.940001  \n",
       "12   19.043029    158.804499    158.804499  23.520000  \n",
       "13   19.548587    158.463049    158.463049  21.719999  \n",
       "17   26.444684    157.832181    157.832181  24.520000  \n",
       "18    0.795533    157.348624    157.348624  22.549999  \n",
       "19    4.720803    157.368152    157.368152  21.129999  \n",
       "20    7.837060    157.178570    157.178570  20.240000  \n",
       "21   27.929066    156.583332    156.583332  22.709999  \n",
       "24   34.921287    155.798311    155.798311  30.040001  \n",
       "25   37.447465    155.151352    155.151352  27.379999  \n",
       "26   42.374578    154.320249    154.320249  31.110001  \n",
       "27   20.637136    153.681183    153.681183  29.910000  \n",
       "28   42.189723    152.489574    152.489574  28.969999  \n",
       "31   48.049182    151.056784    151.056784  33.349998  \n",
       "32   48.049182    149.829362    149.829362  31.760000  \n",
       "33   43.762446    148.688955    148.688955  29.120001  \n",
       "34   46.169959    147.618582    147.618582  25.969999  \n",
       "35   50.100580    146.307839    146.307839  32.230000  \n",
       "38   54.041904    144.961864    144.961864  31.900000  \n",
       "39   55.029552    143.713277    143.713277  33.660000  \n",
       "40   56.789121    142.441499    142.441499  32.869999  \n",
       "41   52.909816    141.072827    141.072827  33.740002  \n",
       "42   38.935220    140.006032    140.006032  31.090000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "# Preparing the training and trade set according to the defined dates\n",
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data\n",
    "train.to_csv(DATA_DIR + '/train_data.csv')\n",
    "trade.to_csv(DATA_DIR + '/trade_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stock_dimension represents the number of unique stocks in the dataset. This value is used to determine how many different stocks the model can trade.\n",
    "\n",
    "state_space denotes the total size of the state space that the model uses for decision-making. The state space includes current stock data (such as prices and technical indicators) and information about the current portfolio (such as the number of shares owned). The size of the state space is determined by a formula that takes into account the number of stocks and the number of technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 11\n"
     ]
    }
   ],
   "source": [
    "# Calculating the dimension (number of unique stocks) from the 'train' DataFrame.\n",
    "stock_dimension = len(train.tic.unique())\n",
    "\n",
    "# Calculating the state size based on the dimension and the number of technical indicators.\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates lists of buy and sell costs for each stock.\n",
    "buy_cost_list = sell_cost_list = [0] * stock_dimension\n",
    "\n",
    "# Initializes the number of shares for each stock to 0.\n",
    "num_stock_shares = [0] * stock_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e_train_gym is an instance of the StockTradingEnv class, which represents the trading environment. This environment uses the data and parameters defined to simulate the stock market. The model learns how to trade within this environment, trying to maximize the total reward (profit) through a series of trading decisions.\n",
    "\n",
    "env_train is obtained by calling the get_sb_env() method on the e_train_gym instance. This method returns an environment compatible with the Stable Baselines 3 library, which is used for implementing reinforcement learning algorithms. The second return element, which is ignored here (_), can be used for additional information or functionalities provided by the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "# Define arguments for the trading environment.\n",
    "env_kwargs = {\n",
    "    \"hmax\": 1000,  # Maximum number of shares that can be bought or sold in a single transaction.\n",
    "    \"initial_amount\": 100000,  # Initial amount of capital.\n",
    "    \"num_stock_shares\": num_stock_shares,  # Initial number of shares for each stock in the portfolio, initially set to 0.\n",
    "    \"buy_cost_pct\": buy_cost_list,  # Percentages of costs for buying and selling stocks, simulating actual transaction costs.\n",
    "    \"sell_cost_pct\": sell_cost_list,  # Percentages of costs for buying and selling stocks, simulating actual transaction costs.\n",
    "    \"state_space\": state_space,  # Previously defined sizes that affect the structure of the environment.\n",
    "    \"stock_dim\": stock_dimension,  # Previously defined sizes that affect the structure of the environment.\n",
    "    \"tech_indicator_list\": INDICATORS,  # List of technical indicators to be used for market state analysis.\n",
    "    \"action_space\": stock_dimension,  # Size of the action space, i.e., the number of different actions the model can take.\n",
    "    \"reward_scaling\": 1e-4  # Scaling factor for the reward, used to adjust the reward size to facilitate learning.\n",
    "}\n",
    "\n",
    "# Create the training environment.\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "# Retrieve the environment suitable for Stable Baselines and an unused object.\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training DRL Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the deep reinforcement learning (DRL) algorithms from the Stable Baselines 3 library. This is a library that has implemented popular DRL algorithms using PyTorch.\n",
    "\n",
    "As an alternative, the ElegantRL and Ray RLlib libraries can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 5 different DRL agents (A2C, DDPG, PPO, TD3, SAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the appropriate values to 'True' for the algorithms you want to use\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.00025}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# A new instance of the DRL agent is created with the given environment (it is not necessary to do this again, but for easier instructions, it remains)\n",
    "agent = DRLAgent(env = env_train)\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.01, \"learning_rate\": 0.00025}\n",
    "model_a2c = agent.get_model(\"a2c\", model_kwargs = A2C_PARAMS)\n",
    "\n",
    "if if_using_a2c:\n",
    "  # Setting up the logger to monitor and record information during training\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  # Configures a new logger that will print information to standard output, log to a CSV file, and TensorBoard\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Sets the new logger for the A2C model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the A2C model with the defined total number of time steps, only if if_using_a2c is set to True.\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained A2C model to the defined directory, only if if_using_a2c is set to True.\n",
    "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.00025}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.00025}\n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs = DDPG_PARAMS)\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to files/results_AMZN/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "       \"n_steps\": 2048,\n",
    "       \"ent_coef\": 0.01,\n",
    "       \"learning_rate\": 0.00025,\n",
    "       \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 3657        |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 0           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | 0.078764096 |\n",
      "------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 3126          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 1             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00081606454 |\n",
      "|    clip_fraction        | 0.00132       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | -0.295        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.0674        |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00111      |\n",
      "|    reward               | 0.0           |\n",
      "|    std                  | 0.996         |\n",
      "|    value_loss           | 0.194         |\n",
      "-------------------------------------------\n",
      "day: 583, episode: 10\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 130790.72\n",
      "total_reward: 30790.72\n",
      "total_cost: 0.00\n",
      "total_trades: 460\n",
      "Sharpe: 0.596\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2990         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013875891 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.0464      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.056        |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | -0.18796386  |\n",
      "|    std                  | 0.995        |\n",
      "|    value_loss           | 0.151        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2942         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027606068 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.0542      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0501       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | 0.009945703  |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 0.157        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2912        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004449428 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -0.0175     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0642      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 20\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 89349.84\n",
      "total_reward: -10650.16\n",
      "total_cost: 0.00\n",
      "total_trades: 426\n",
      "Sharpe: -0.126\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2891          |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 4             |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056046573 |\n",
      "|    clip_fraction        | 0.00171       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.4          |\n",
      "|    explained_variance   | 0.0307        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.0842        |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.000738     |\n",
      "|    reward               | -0.5395301    |\n",
      "|    std                  | 0.983         |\n",
      "|    value_loss           | 0.182         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2880        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003918729 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -0.206      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2830         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042855996 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | -0.0235      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0965       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 0.21         |\n",
      "------------------------------------------\n",
      "day: 583, episode: 30\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 105784.11\n",
      "total_reward: 5784.11\n",
      "total_cost: 0.00\n",
      "total_trades: 479\n",
      "Sharpe: 0.223\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2827        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002845658 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.000507   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2819         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025851815 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.00141      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0865       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 0.21         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2817         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054461686 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.0156      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0266       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 0.117        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 40\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102921.93\n",
      "total_reward: 2921.93\n",
      "total_cost: 0.00\n",
      "total_trades: 458\n",
      "Sharpe: 0.169\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2815        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004395839 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.00514     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0798      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    reward               | -0.51114595 |\n",
      "|    std                  | 0.976       |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2794         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035474664 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0555       |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    reward               | -0.24281405  |\n",
      "|    std                  | 0.967        |\n",
      "|    value_loss           | 0.168        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 50\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 89105.91\n",
      "total_reward: -10894.09\n",
      "total_cost: 0.00\n",
      "total_trades: 459\n",
      "Sharpe: -0.062\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2774       |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00428857 |\n",
      "|    clip_fraction        | 0.0195     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.39      |\n",
      "|    explained_variance   | 0.0135     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.126      |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.00221   |\n",
      "|    reward               | 0.0        |\n",
      "|    std                  | 0.968      |\n",
      "|    value_loss           | 0.227      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2771         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038382392 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.0054      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0442       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 0.168        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2756         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023662024 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -0.0073      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0705       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    reward               | 0.22552203   |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 0.158        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 60\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 117704.87\n",
      "total_reward: 17704.87\n",
      "total_cost: 0.00\n",
      "total_trades: 417\n",
      "Sharpe: 0.425\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2725        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006784043 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.00448    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0759      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    reward               | 0.32264072  |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2716       |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00531985 |\n",
      "|    clip_fraction        | 0.0343     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.38      |\n",
      "|    explained_variance   | 0.0109     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0498     |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.00417   |\n",
      "|    reward               | 0.239      |\n",
      "|    std                  | 0.958      |\n",
      "|    value_loss           | 0.151      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2689         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022245112 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.0328       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0865       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 0.164        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 70\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 80150.81\n",
      "total_reward: -19849.19\n",
      "total_cost: 0.00\n",
      "total_trades: 423\n",
      "Sharpe: -0.357\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2663         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034066678 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.0299       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.102        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.187        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2658         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032983152 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.00659      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0778       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.122        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2651         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026856635 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0251       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0638       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 0.148        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 80\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 90109.95\n",
      "total_reward: -9890.05\n",
      "total_cost: 0.00\n",
      "total_trades: 446\n",
      "Sharpe: -0.040\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2644        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004057639 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.0155      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0721      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2638         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059023034 |\n",
      "|    clip_fraction        | 0.0598       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0527       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 0.246        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2638        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005965214 |\n",
      "|    clip_fraction        | 0.0337      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.0456      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0864      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 90\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 141693.92\n",
      "total_reward: 41693.92\n",
      "total_cost: 0.00\n",
      "total_trades: 525\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2642         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 20           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024216634 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0313       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0613       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    reward               | -0.10566018  |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 0.184        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2643        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004049338 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0979      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    reward               | 0.02262085  |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2645         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025710252 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0528       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    reward               | -0.1609896   |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 0.253        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 121118.28\n",
      "total_reward: 21118.28\n",
      "total_cost: 0.00\n",
      "total_trades: 523\n",
      "Sharpe: 0.441\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2647         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036829012 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0736       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.138        |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    reward               | 0.06365392   |\n",
      "|    std                  | 0.972        |\n",
      "|    value_loss           | 0.284        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2638         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036741872 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.074        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0575       |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    reward               | -0.03456006  |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.196        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2625         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030875127 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0991       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.131        |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    reward               | -0.045760255 |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 0.246        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 134238.68\n",
      "total_reward: 34238.68\n",
      "total_cost: 0.00\n",
      "total_trades: 527\n",
      "Sharpe: 0.595\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2621        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008689068 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.0911      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.963       |\n",
      "|    value_loss           | 0.262       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2618         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00468008   |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.113        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0857       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    reward               | -0.043348882 |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 0.242        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 218866.30\n",
      "total_reward: 118866.30\n",
      "total_cost: 0.00\n",
      "total_trades: 556\n",
      "Sharpe: 1.186\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2612        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004560278 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.0929      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    reward               | -0.29765385 |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 0.335       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2613        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006138647 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    reward               | -0.10275    |\n",
      "|    std                  | 0.97        |\n",
      "|    value_loss           | 0.328       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2616         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072619426 |\n",
      "|    clip_fraction        | 0.0569       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.0739       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.102        |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    reward               | -0.15808015  |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.217        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 149016.20\n",
      "total_reward: 49016.20\n",
      "total_cost: 0.00\n",
      "total_trades: 563\n",
      "Sharpe: 0.679\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2621        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004416031 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | -0.18088172 |\n",
      "|    std                  | 0.963       |\n",
      "|    value_loss           | 0.328       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2620         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065288497 |\n",
      "|    clip_fraction        | 0.0498       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0981       |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    reward               | -0.097207665 |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.256        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2625         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037910945 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.128        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.137        |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    reward               | -0.17911805  |\n",
      "|    std                  | 0.967        |\n",
      "|    value_loss           | 0.284        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 168293.38\n",
      "total_reward: 68293.38\n",
      "total_cost: 0.00\n",
      "total_trades: 556\n",
      "Sharpe: 0.865\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2615         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066043027 |\n",
      "|    clip_fraction        | 0.0547       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.0985       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.14         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    reward               | 0.014383856  |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 0.295        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2614         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033294219 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.122        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.105        |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    reward               | 0.094668075  |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 0.293        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2611        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006320145 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0826      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    reward               | 0.28204778  |\n",
      "|    std                  | 0.951       |\n",
      "|    value_loss           | 0.239       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 134092.45\n",
      "total_reward: 34092.45\n",
      "total_cost: 0.00\n",
      "total_trades: 568\n",
      "Sharpe: 0.554\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2609         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053731883 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.167        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.144        |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    reward               | 0.0062277466 |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 0.329        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2612         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038856696 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.11         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    reward               | 0.5538404    |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 0.261        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2610        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00396366  |\n",
      "|    clip_fraction        | 0.0303      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    reward               | -0.06724927 |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 0.342       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 160\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 184486.87\n",
      "total_reward: 84486.87\n",
      "total_cost: 0.00\n",
      "total_trades: 575\n",
      "Sharpe: 0.964\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2606        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00370806  |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0951      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    reward               | -0.17932974 |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2604       |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00602459 |\n",
      "|    clip_fraction        | 0.0446     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.2        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.155      |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    reward               | 0.0        |\n",
      "|    std                  | 0.943      |\n",
      "|    value_loss           | 0.31       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2604        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008340058 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.0886      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    reward               | -0.10787015 |\n",
      "|    std                  | 0.94        |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 170\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 155606.19\n",
      "total_reward: 55606.19\n",
      "total_cost: 0.00\n",
      "total_trades: 560\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2600       |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 100352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00623135 |\n",
      "|    clip_fraction        | 0.0627     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.174      |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00386   |\n",
      "|    reward               | 0.20759948 |\n",
      "|    std                  | 0.943      |\n",
      "|    value_loss           | 0.347      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2601        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007467133 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    reward               | -0.2522552  |\n",
      "|    std                  | 0.931       |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2589        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005742608 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    reward               | 0.025141468 |\n",
      "|    std                  | 0.937       |\n",
      "|    value_loss           | 0.286       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 180\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 165490.77\n",
      "total_reward: 65490.77\n",
      "total_cost: 0.00\n",
      "total_trades: 563\n",
      "Sharpe: 0.823\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2586         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062219296 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.138        |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    reward               | 0.007840821  |\n",
      "|    std                  | 0.932        |\n",
      "|    value_loss           | 0.308        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2583         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074160006 |\n",
      "|    clip_fraction        | 0.076        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.128        |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | 0.00661      |\n",
      "|    reward               | -0.1339736   |\n",
      "|    std                  | 0.922        |\n",
      "|    value_loss           | 0.288        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 190\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 153287.68\n",
      "total_reward: 53287.68\n",
      "total_cost: 0.00\n",
      "total_trades: 561\n",
      "Sharpe: 0.719\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2583         |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066295266 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.118        |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    reward               | -0.30568817  |\n",
      "|    std                  | 0.918        |\n",
      "|    value_loss           | 0.322        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2584        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008212617 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    reward               | 0.10618331  |\n",
      "|    std                  | 0.912       |\n",
      "|    value_loss           | 0.307       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2585         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078223515 |\n",
      "|    clip_fraction        | 0.0553       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.277        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.125        |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    reward               | 0.10200043   |\n",
      "|    std                  | 0.907        |\n",
      "|    value_loss           | 0.337        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 200\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 86037.42\n",
      "total_reward: -13962.58\n",
      "total_cost: 0.00\n",
      "total_trades: 558\n",
      "Sharpe: -0.069\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2584        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007560075 |\n",
      "|    clip_fraction        | 0.053       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    reward               | 0.52222466  |\n",
      "|    std                  | 0.912       |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2584       |\n",
      "|    iterations           | 58         |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 118784     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00735075 |\n",
      "|    clip_fraction        | 0.0854     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 570        |\n",
      "|    policy_gradient_loss | -0.00769   |\n",
      "|    reward               | 0.0        |\n",
      "|    std                  | 0.906      |\n",
      "|    value_loss           | 0.309      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2576         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044042426 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.134        |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    reward               | 0.09446416   |\n",
      "|    std                  | 0.907        |\n",
      "|    value_loss           | 0.322        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 210\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 155180.23\n",
      "total_reward: 55180.23\n",
      "total_cost: 0.00\n",
      "total_trades: 576\n",
      "Sharpe: 0.748\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2571         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046607163 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.118        |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | 0.33289608   |\n",
      "|    std                  | 0.902        |\n",
      "|    value_loss           | 0.248        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2572         |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061057247 |\n",
      "|    clip_fraction        | 0.0639       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.15         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.903        |\n",
      "|    value_loss           | 0.259        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2571         |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056444677 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.111        |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    reward               | 0.04825615   |\n",
      "|    std                  | 0.908        |\n",
      "|    value_loss           | 0.264        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 220\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 158888.70\n",
      "total_reward: 58888.70\n",
      "total_cost: 0.00\n",
      "total_trades: 567\n",
      "Sharpe: 0.785\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2567         |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 50           |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.006803195  |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.108        |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    reward               | -0.050580513 |\n",
      "|    std                  | 0.91         |\n",
      "|    value_loss           | 0.269        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2556        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005679597 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    reward               | -0.01491163 |\n",
      "|    std                  | 0.902       |\n",
      "|    value_loss           | 0.286       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2550        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013607467 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.097       |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    reward               | -0.1731217  |\n",
      "|    std                  | 0.899       |\n",
      "|    value_loss           | 0.317       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 230\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 171292.03\n",
      "total_reward: 71292.03\n",
      "total_cost: 0.00\n",
      "total_trades: 579\n",
      "Sharpe: 0.863\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2532         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065251454 |\n",
      "|    clip_fraction        | 0.0756       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    reward               | 0.26188296   |\n",
      "|    std                  | 0.896        |\n",
      "|    value_loss           | 0.325        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2489         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057623126 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.362        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0757       |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    reward               | 0.009680054  |\n",
      "|    std                  | 0.904        |\n",
      "|    value_loss           | 0.3          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2485         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049668327 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.155        |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    reward               | 0.21769267   |\n",
      "|    std                  | 0.911        |\n",
      "|    value_loss           | 0.335        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 240\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 172188.93\n",
      "total_reward: 72188.93\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.891\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2482        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010321101 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    reward               | -0.05484795 |\n",
      "|    std                  | 0.914       |\n",
      "|    value_loss           | 0.307       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2474         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042745494 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.146        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | -0.08181018  |\n",
      "|    std                  | 0.906        |\n",
      "|    value_loss           | 0.296        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2473       |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 58         |\n",
      "|    total_timesteps      | 145408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00550545 |\n",
      "|    clip_fraction        | 0.0437     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.154      |\n",
      "|    n_updates            | 700        |\n",
      "|    policy_gradient_loss | -0.00358   |\n",
      "|    reward               | -0.5188298 |\n",
      "|    std                  | 0.907      |\n",
      "|    value_loss           | 0.324      |\n",
      "----------------------------------------\n",
      "day: 583, episode: 250\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 112680.36\n",
      "total_reward: 12680.36\n",
      "total_cost: 0.00\n",
      "total_trades: 574\n",
      "Sharpe: 0.321\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2472        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005536465 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    reward               | 0.10931189  |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2473        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007596888 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    reward               | 0.054824304 |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 260\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 171814.23\n",
      "total_reward: 71814.23\n",
      "total_cost: 0.00\n",
      "total_trades: 580\n",
      "Sharpe: 0.834\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2474        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005503354 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.244       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | 0.18022622  |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.285       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2474         |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062466785 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0679       |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | -0.15761508  |\n",
      "|    std                  | 0.906        |\n",
      "|    value_loss           | 0.29         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2475        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004859873 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | 0.000113    |\n",
      "|    reward               | -0.16138588 |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 270\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 174331.52\n",
      "total_reward: 74331.52\n",
      "total_cost: 0.00\n",
      "total_trades: 579\n",
      "Sharpe: 0.849\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2476         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058955075 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.908        |\n",
      "|    value_loss           | 0.282        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2477        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009555103 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    reward               | 0.06145973  |\n",
      "|    std                  | 0.912       |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2478         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038780675 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.111        |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    reward               | -0.5444201   |\n",
      "|    std                  | 0.92         |\n",
      "|    value_loss           | 0.261        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 280\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 162720.20\n",
      "total_reward: 62720.20\n",
      "total_cost: 0.00\n",
      "total_trades: 578\n",
      "Sharpe: 0.805\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2479        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007866967 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    reward               | 0.36330158  |\n",
      "|    std                  | 0.916       |\n",
      "|    value_loss           | 0.334       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2467        |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006706293 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    reward               | -0.1450047  |\n",
      "|    std                  | 0.914       |\n",
      "|    value_loss           | 0.306       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2464        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006528572 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    reward               | -0.0935     |\n",
      "|    std                  | 0.912       |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 290\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 161019.95\n",
      "total_reward: 61019.95\n",
      "total_cost: 0.00\n",
      "total_trades: 578\n",
      "Sharpe: 0.796\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2457         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 169984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040991427 |\n",
      "|    clip_fraction        | 0.0559       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.115        |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.914        |\n",
      "|    value_loss           | 0.289        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2453         |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073011676 |\n",
      "|    clip_fraction        | 0.0498       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.117        |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    reward               | 0.4875218    |\n",
      "|    std                  | 0.918        |\n",
      "|    value_loss           | 0.305        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2449         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059973076 |\n",
      "|    clip_fraction        | 0.0611       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.102        |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.915        |\n",
      "|    value_loss           | 0.292        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 300\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 171957.11\n",
      "total_reward: 71957.11\n",
      "total_cost: 0.00\n",
      "total_trades: 580\n",
      "Sharpe: 0.853\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2451        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009813144 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    reward               | -0.23966806 |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 0.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2453        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007210136 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    reward               | 0.22791994  |\n",
      "|    std                  | 0.906       |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2455        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007006846 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    reward               | 0.11514878  |\n",
      "|    std                  | 0.905       |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 310\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 162761.67\n",
      "total_reward: 62761.67\n",
      "total_cost: 0.00\n",
      "total_trades: 578\n",
      "Sharpe: 0.774\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2457         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071424344 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | 0.45384905   |\n",
      "|    std                  | 0.915        |\n",
      "|    value_loss           | 0.275        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2455         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052756714 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.126        |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | 0.23709653   |\n",
      "|    std                  | 0.903        |\n",
      "|    value_loss           | 0.258        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 320\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 173616.68\n",
      "total_reward: 73616.68\n",
      "total_cost: 0.00\n",
      "total_trades: 580\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2450        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008247919 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0959      |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    reward               | 0.198       |\n",
      "|    std                  | 0.908       |\n",
      "|    value_loss           | 0.263       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2451         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009406083  |\n",
      "|    clip_fraction        | 0.0693       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.132        |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    reward               | -0.013649445 |\n",
      "|    std                  | 0.913        |\n",
      "|    value_loss           | 0.254        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2451         |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074852086 |\n",
      "|    clip_fraction        | 0.066        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0684       |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | 0.33015016   |\n",
      "|    std                  | 0.903        |\n",
      "|    value_loss           | 0.254        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 330\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 131562.46\n",
      "total_reward: 31562.46\n",
      "total_cost: 0.00\n",
      "total_trades: 577\n",
      "Sharpe: 0.511\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2450        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005054892 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.09        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    reward               | -0.07553185 |\n",
      "|    std                  | 0.893       |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2448         |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061606886 |\n",
      "|    clip_fraction        | 0.0556       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0983       |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00112     |\n",
      "|    reward               | -0.1884      |\n",
      "|    std                  | 0.89         |\n",
      "|    value_loss           | 0.248        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2448         |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076745637 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0814       |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    reward               | 0.21991433   |\n",
      "|    std                  | 0.891        |\n",
      "|    value_loss           | 0.243        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 340\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 145495.25\n",
      "total_reward: 45495.25\n",
      "total_cost: 0.00\n",
      "total_trades: 579\n",
      "Sharpe: 0.638\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2446         |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050693583 |\n",
      "|    clip_fraction        | 0.0471       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.11         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    reward               | -0.06808549  |\n",
      "|    std                  | 0.886        |\n",
      "|    value_loss           | 0.247        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2445        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014701374 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    reward               | 0.25346506  |\n",
      "|    std                  | 0.877       |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2446        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008664146 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    reward               | -0.13968024 |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 350\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 156361.13\n",
      "total_reward: 56361.13\n",
      "total_cost: 0.00\n",
      "total_trades: 579\n",
      "Sharpe: 0.716\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2445        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008406354 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0999      |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    reward               | 0.022568848 |\n",
      "|    std                  | 0.876       |\n",
      "|    value_loss           | 0.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2440        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010730557 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0877      |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    reward               | -0.2156828  |\n",
      "|    std                  | 0.883       |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2438         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066535277 |\n",
      "|    clip_fraction        | 0.0659       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.114        |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    reward               | 0.13966784   |\n",
      "|    std                  | 0.88         |\n",
      "|    value_loss           | 0.263        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 360\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 163344.24\n",
      "total_reward: 63344.24\n",
      "total_cost: 0.00\n",
      "total_trades: 579\n",
      "Sharpe: 0.788\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2436        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009756235 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    reward               | -0.08348414 |\n",
      "|    std                  | 0.876       |\n",
      "|    value_loss           | 0.262       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2429        |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011549114 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    reward               | -0.04180023 |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2429        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012550782 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0841      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    reward               | -0.1071578  |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 370\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 172723.78\n",
      "total_reward: 72723.78\n",
      "total_cost: 0.00\n",
      "total_trades: 576\n",
      "Sharpe: 0.844\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2430        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 89          |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010812915 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0998      |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | -0.04013289 |\n",
      "|    std                  | 0.866       |\n",
      "|    value_loss           | 0.242       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2424        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008129521 |\n",
      "|    clip_fraction        | 0.0573      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0959      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    reward               | -0.33635682 |\n",
      "|    std                  | 0.873       |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2422         |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101540135 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    reward               | -0.10005     |\n",
      "|    std                  | 0.868        |\n",
      "|    value_loss           | 0.217        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 380\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 117371.27\n",
      "total_reward: 17371.27\n",
      "total_cost: 0.00\n",
      "total_trades: 575\n",
      "Sharpe: 0.374\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2418         |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063843494 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.118        |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    reward               | -0.17347215  |\n",
      "|    std                  | 0.871        |\n",
      "|    value_loss           | 0.275        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2418        |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004241663 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0895      |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    reward               | -0.20474967 |\n",
      "|    std                  | 0.881       |\n",
      "|    value_loss           | 0.283       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 390\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159809.51\n",
      "total_reward: 59809.51\n",
      "total_cost: 0.00\n",
      "total_trades: 580\n",
      "Sharpe: 0.745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2414        |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008973248 |\n",
      "|    clip_fraction        | 0.07        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0742      |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    reward               | -0.09036369 |\n",
      "|    std                  | 0.876       |\n",
      "|    value_loss           | 0.278       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2413        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813188 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    reward               | -0.13559404 |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2410       |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 96         |\n",
      "|    total_timesteps      | 231424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00864624 |\n",
      "|    clip_fraction        | 0.0563     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.3       |\n",
      "|    explained_variance   | 0.286      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0809     |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | -0.00133   |\n",
      "|    reward               | 0.02685373 |\n",
      "|    std                  | 0.889      |\n",
      "|    value_loss           | 0.233      |\n",
      "----------------------------------------\n",
      "day: 583, episode: 400\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 115977.27\n",
      "total_reward: 15977.27\n",
      "total_cost: 0.00\n",
      "total_trades: 574\n",
      "Sharpe: 0.359\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2408        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007371249 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    reward               | 0.122598104 |\n",
      "|    std                  | 0.887       |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2409        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006063211 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.089       |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | 0.4113197   |\n",
      "|    std                  | 0.87        |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2410         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062576374 |\n",
      "|    clip_fraction        | 0.0857       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.105        |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    reward               | 0.0082796635 |\n",
      "|    std                  | 0.88         |\n",
      "|    value_loss           | 0.26         |\n",
      "------------------------------------------\n",
      "day: 583, episode: 410\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 154723.66\n",
      "total_reward: 54723.66\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 0.710\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2411        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008008279 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    reward               | 0.5357804   |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2409         |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008430587  |\n",
      "|    clip_fraction        | 0.07         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.132        |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    reward               | -0.053781215 |\n",
      "|    std                  | 0.877        |\n",
      "|    value_loss           | 0.261        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2409        |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009173313 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0545      |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    reward               | -0.15617576 |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 420\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 154006.63\n",
      "total_reward: 54006.63\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.709\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2410        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006879909 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    reward               | 0.2756384   |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2411         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069975583 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.137        |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    reward               | -0.0761301   |\n",
      "|    std                  | 0.874        |\n",
      "|    value_loss           | 0.285        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2411        |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009758776 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.142       |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    reward               | 0.15143962  |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 0.257       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 430\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 128108.25\n",
      "total_reward: 28108.25\n",
      "total_cost: 0.00\n",
      "total_trades: 579\n",
      "Sharpe: 0.485\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2406        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007117536 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    reward               | -0.22815919 |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2406        |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008530894 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0916      |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    reward               | 0.019525588 |\n",
      "|    std                  | 0.869       |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2398         |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00866011   |\n",
      "|    clip_fraction        | 0.063        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.132        |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    reward               | 0.0061606443 |\n",
      "|    std                  | 0.868        |\n",
      "|    value_loss           | 0.24         |\n",
      "------------------------------------------\n",
      "day: 583, episode: 440\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 176522.10\n",
      "total_reward: 76522.10\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.861\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2395        |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006001004 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0891      |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    reward               | -0.13996758 |\n",
      "|    std                  | 0.862       |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2393        |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008112048 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0733      |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    reward               | -0.27335215 |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2387        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00859839  |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0778      |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    reward               | 0.068431556 |\n",
      "|    std                  | 0.878       |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 450\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 122249.15\n",
      "total_reward: 22249.15\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 0.430\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2381         |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066662002 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.113        |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    reward               | 0.08149834   |\n",
      "|    std                  | 0.874        |\n",
      "|    value_loss           | 0.226        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2370        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007760923 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0925      |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    reward               | 0.28561482  |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 460\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 113142.33\n",
      "total_reward: 13142.33\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.327\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2372        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01082921  |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0716      |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    reward               | -0.08475037 |\n",
      "|    std                  | 0.859       |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2366        |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009608102 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0991      |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    reward               | 0.07848013  |\n",
      "|    std                  | 0.861       |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2364        |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 115         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010559624 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0531      |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    reward               | 0.31996807  |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 470\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 148046.76\n",
      "total_reward: 48046.76\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.670\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2364         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068940036 |\n",
      "|    clip_fraction        | 0.0697       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.122        |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    reward               | -0.0603838   |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 0.292        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2357        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007982489 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    reward               | 0.052548166 |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 0.257       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2353       |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 118        |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02125749 |\n",
      "|    clip_fraction        | 0.0814     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0771     |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.00538   |\n",
      "|    reward               | 0.0        |\n",
      "|    std                  | 0.855      |\n",
      "|    value_loss           | 0.301      |\n",
      "----------------------------------------\n",
      "day: 583, episode: 480\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 176648.71\n",
      "total_reward: 76648.71\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.868\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2353         |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008674972  |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.105        |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    reward               | -0.011599712 |\n",
      "|    std                  | 0.856        |\n",
      "|    value_loss           | 0.285        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2352        |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011943908 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.142       |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    reward               | -0.22581093 |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 0.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2346        |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011092149 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0944      |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    reward               | 0.25314498  |\n",
      "|    std                  | 0.862       |\n",
      "|    value_loss           | 0.267       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 490\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 202905.72\n",
      "total_reward: 102905.72\n",
      "total_cost: 0.00\n",
      "total_trades: 580\n",
      "Sharpe: 1.062\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2337         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075793797 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.106        |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    reward               | 0.0112640625 |\n",
      "|    std                  | 0.859        |\n",
      "|    value_loss           | 0.256        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2326         |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 288768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074954173 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.535        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.093        |\n",
      "|    n_updates            | 1400         |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    reward               | 0.19839771   |\n",
      "|    std                  | 0.854        |\n",
      "|    value_loss           | 0.253        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2323         |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 290816       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010132367  |\n",
      "|    clip_fraction        | 0.067        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.1          |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    reward               | -0.058239944 |\n",
      "|    std                  | 0.852        |\n",
      "|    value_loss           | 0.269        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 500\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 179123.60\n",
      "total_reward: 79123.60\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.891\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2323         |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 126          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010388901  |\n",
      "|    clip_fraction        | 0.0883       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.105        |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    reward               | -0.069084145 |\n",
      "|    std                  | 0.857        |\n",
      "|    value_loss           | 0.242        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2324        |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005106397 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    reward               | -0.6041748  |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 0.265       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2320        |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009127125 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0827      |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    reward               | 0.1077759   |\n",
      "|    std                  | 0.861       |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 510\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 140621.22\n",
      "total_reward: 40621.22\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.591\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2319        |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009603748 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | 0.08703248  |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 0.283       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2313        |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007481455 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    reward               | 0.16509421  |\n",
      "|    std                  | 0.869       |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 520\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 148332.55\n",
      "total_reward: 48332.55\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2313        |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008280148 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    reward               | -0.22301248 |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 0.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2312        |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009742796 |\n",
      "|    clip_fraction        | 0.0871      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    reward               | -0.22358383 |\n",
      "|    std                  | 0.869       |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2312        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011916027 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 530\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 145754.70\n",
      "total_reward: 45754.70\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.643\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2313        |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008742123 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    reward               | 0.047599792 |\n",
      "|    std                  | 0.846       |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2309        |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012480663 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0966      |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    reward               | -0.57620513 |\n",
      "|    std                  | 0.848       |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2306        |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008419687 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0862      |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    reward               | 0.32301763  |\n",
      "|    std                  | 0.83        |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 540\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 155570.92\n",
      "total_reward: 55570.92\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 0.711\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2304        |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.01210247  |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    reward               | -0.14702377 |\n",
      "|    std                  | 0.822       |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2295        |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011506654 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0925      |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    reward               | -0.0745     |\n",
      "|    std                  | 0.818       |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2291        |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010601578 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.000812   |\n",
      "|    reward               | 0.24023962  |\n",
      "|    std                  | 0.815       |\n",
      "|    value_loss           | 0.286       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 550\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 172166.90\n",
      "total_reward: 72166.90\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 0.841\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2292        |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006829731 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0931      |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    reward               | 0.9302296   |\n",
      "|    std                  | 0.81        |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2292        |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008794451 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    reward               | -0.526914   |\n",
      "|    std                  | 0.815       |\n",
      "|    value_loss           | 0.314       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2295        |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006345301 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | -0.23852405 |\n",
      "|    std                  | 0.825       |\n",
      "|    value_loss           | 0.262       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 560\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 142231.44\n",
      "total_reward: 42231.44\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 0.621\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2296        |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013704258 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 0.324       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2298       |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01318847 |\n",
      "|    clip_fraction        | 0.0837     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.6        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.121      |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.005     |\n",
      "|    reward               | 0.12510477 |\n",
      "|    std                  | 0.834      |\n",
      "|    value_loss           | 0.279      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2300        |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007946606 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0911      |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    reward               | 0.44823906  |\n",
      "|    std                  | 0.836       |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 570\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 214624.40\n",
      "total_reward: 114624.40\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 1.111\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2303       |\n",
      "|    iterations           | 163        |\n",
      "|    time_elapsed         | 144        |\n",
      "|    total_timesteps      | 333824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00820942 |\n",
      "|    clip_fraction        | 0.047      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.477      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0893     |\n",
      "|    n_updates            | 1620       |\n",
      "|    policy_gradient_loss | -0.00103   |\n",
      "|    reward               | 0.24923256 |\n",
      "|    std                  | 0.827      |\n",
      "|    value_loss           | 0.24       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2305        |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007826737 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    reward               | 0.1785      |\n",
      "|    std                  | 0.825       |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2307         |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 337920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015476942  |\n",
      "|    clip_fraction        | 0.0882       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    reward               | -0.012314499 |\n",
      "|    std                  | 0.825        |\n",
      "|    value_loss           | 0.283        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 580\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 160410.42\n",
      "total_reward: 60410.42\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.762\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2310        |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015231282 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.156       |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    reward               | 0.31140617  |\n",
      "|    std                  | 0.827       |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2312        |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007132874 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    reward               | -0.07783184 |\n",
      "|    std                  | 0.818       |\n",
      "|    value_loss           | 0.258       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 590\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 170332.08\n",
      "total_reward: 70332.08\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 0.830\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2314        |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009675898 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0731      |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    reward               | -0.326      |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 0.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2317        |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009259373 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    reward               | 0.25733623  |\n",
      "|    std                  | 0.815       |\n",
      "|    value_loss           | 0.245       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2319         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065403404 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.084        |\n",
      "|    n_updates            | 1690         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    reward               | -0.07769056  |\n",
      "|    std                  | 0.825        |\n",
      "|    value_loss           | 0.261        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 600\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 141713.20\n",
      "total_reward: 41713.20\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.603\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2322        |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006585032 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0007     |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.833       |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2324        |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012519387 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2326        |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014166186 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0666      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    reward               | 0.022750854 |\n",
      "|    std                  | 0.831       |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 610\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 212872.54\n",
      "total_reward: 112872.54\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.090\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2328        |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008942992 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | 0.00625     |\n",
      "|    reward               | -0.15480958 |\n",
      "|    std                  | 0.83        |\n",
      "|    value_loss           | 0.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012502257 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0829      |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    reward               | 0.20908976  |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 0.252       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2333        |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007588187 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0999      |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.82        |\n",
      "|    value_loss           | 0.274       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 620\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 142346.56\n",
      "total_reward: 42346.56\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.618\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008946281  |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0876       |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    reward               | -0.046420258 |\n",
      "|    std                  | 0.822        |\n",
      "|    value_loss           | 0.226        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2334        |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008384006 |\n",
      "|    clip_fraction        | 0.0673      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0758      |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | 5.63e-05    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.821       |\n",
      "|    value_loss           | 0.265       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2334        |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016212668 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    reward               | -0.06646382 |\n",
      "|    std                  | 0.818       |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 630\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 194140.76\n",
      "total_reward: 94140.76\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.997\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2335        |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011554474 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0834      |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    reward               | -0.3503218  |\n",
      "|    std                  | 0.812       |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2336        |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009391524 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    reward               | -0.14175    |\n",
      "|    std                  | 0.81        |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2336        |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007891476 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0935      |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    reward               | -0.12604812 |\n",
      "|    std                  | 0.821       |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 640\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 127997.62\n",
      "total_reward: 27997.62\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.477\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2336        |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010093575 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0766      |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    reward               | -0.1860297  |\n",
      "|    std                  | 0.812       |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2335        |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018486988 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0906      |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.802       |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2336        |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013240663 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.000119   |\n",
      "|    reward               | -0.13782604 |\n",
      "|    std                  | 0.794       |\n",
      "|    value_loss           | 0.247       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 650\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 145786.87\n",
      "total_reward: 45786.87\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.648\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2334        |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010197919 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0947      |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.796       |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2325        |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010969501 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.000419   |\n",
      "|    reward               | 0.13494611  |\n",
      "|    std                  | 0.795       |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 660\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 145772.35\n",
      "total_reward: 45772.35\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.634\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2323        |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014952508 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | 0.000723    |\n",
      "|    reward               | 0.34442374  |\n",
      "|    std                  | 0.793       |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2319        |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008946197 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.128       |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | 0.000192    |\n",
      "|    reward               | 0.006587732 |\n",
      "|    std                  | 0.789       |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2319        |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013138436 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0529      |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.000819   |\n",
      "|    reward               | 0.5712984   |\n",
      "|    std                  | 0.781       |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 670\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 180324.33\n",
      "total_reward: 80324.33\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.896\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2317         |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 391168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069968095 |\n",
      "|    clip_fraction        | 0.0941       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0903       |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | 0.00465      |\n",
      "|    reward               | -0.075439304 |\n",
      "|    std                  | 0.784        |\n",
      "|    value_loss           | 0.24         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2317         |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071090767 |\n",
      "|    clip_fraction        | 0.0633       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.664        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0898       |\n",
      "|    n_updates            | 1910         |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    reward               | -0.18046473  |\n",
      "|    std                  | 0.781        |\n",
      "|    value_loss           | 0.212        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2316         |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 395264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104226675 |\n",
      "|    clip_fraction        | 0.0583       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.108        |\n",
      "|    n_updates            | 1920         |\n",
      "|    policy_gradient_loss | 0.000656     |\n",
      "|    reward               | 0.28237042   |\n",
      "|    std                  | 0.774        |\n",
      "|    value_loss           | 0.228        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 680\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 165833.56\n",
      "total_reward: 65833.56\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.783\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2318        |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009639196 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0973      |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    reward               | -0.21252029 |\n",
      "|    std                  | 0.772       |\n",
      "|    value_loss           | 0.241       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2318        |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015049469 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.000662   |\n",
      "|    reward               | 0.20687947  |\n",
      "|    std                  | 0.786       |\n",
      "|    value_loss           | 0.239       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2319        |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011243876 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0869      |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    reward               | -0.20983618 |\n",
      "|    std                  | 0.78        |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=400000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.00025, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=50000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preparation for backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, we load the delayed data if we have restarted the process (not needed)\n",
    "train = pd.read_csv(DATA_DIR + '/train_data.csv')\n",
    "trade = pd.read_csv(DATA_DIR + '/trade_data.csv')\n",
    "\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names = ['']\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, we load the delayed training data if we have restarted the process (not needed)\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False\n",
    "\n",
    "trained_a2c = A2C.load(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None\n",
    "trained_ddpg = DDPG.load(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n",
    "trained_ppo = PPO.load(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None\n",
    "trained_td3 = TD3.load(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None\n",
    "trained_sac = SAC.load(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trading (data outside the training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we now use the trade dataset for trading, which has never been used for training. Additionally, with a similar approach, we could fine-tune the existing saved model.\n",
    "\n",
    "Numerous hyperparameters, such as the learning rate and the total number of training samples, affect the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 11\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 1000,\n",
    "    \"initial_amount\": 100000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section relates to the use of deep reinforcement learning (DRL) for simulating real-time trading using a previously trained model (in this case, A2C). StockTradingEnv is an environment that simulates the stock market based on historical data, a turbulence threshold (which is used to determine market volatility), and 'VIX' as a risk indicator. After initializing the environment, the get_sb_env() method is used to retrieve the environment and initial observations that are compatible with the Stable Baselines library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the trading environment with the defined DataFrame 'trade', turbulence threshold, and risk indicator 'vix',\n",
    "# along with other environment parameters ('env_kwargs').\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "\n",
    "# Retrieving the environment compatible with Stable Baselines and initial observations.\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DRL agent is then used to predict trading actions and changes in account value based on the trained model. This allows for the evaluation of the model's performance in an out-of-sample scenario, providing insight into how the model might perform in real trading conditions. If the use of the A2C algorithm is selected (as indicated by the variable if_using_a2c), predictions are made; otherwise, the result is set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the DRL agent for prediction using the trained model 'trained_a2c' and the defined trading environment 'e_trade_gym'.\n",
    "# The results are two DataFrames: 'df_account_value_a2c' with account values and 'df_actions_a2c' with the actions taken,\n",
    "# if 'if_using_a2c' is set to True; otherwise, it returns (None, None).\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym) if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym) if if_using_sac else (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. B&H for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (144, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_aapl = YahooDownloader(start_date = TRADE_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = ['AMZN']).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aapl = df_aapl[['date','close']]\n",
    "fst_day = df_aapl['close'].iloc[0]\n",
    "buy_and_hold = pd.merge(df_aapl['date'], df_aapl['close'].div(fst_day).mul(100000), \n",
    "                        how='outer', left_index=True, right_index=True).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Backtesting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the index of the account value DataFrames for each of the DRL strategies, if selected.\n",
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0]) if if_using_a2c else None\n",
    "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0]) if if_using_ddpg else None\n",
    "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0]) if if_using_ppo else None\n",
    "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0]) if if_using_td3 else None\n",
    "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0]) if if_using_sac else None\n",
    "\n",
    "# Creating an empty DataFrame for results.\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# Merging the results of all DRL strategies into one DataFrame, if selected.\n",
    "if if_using_a2c: result = pd.merge(result, df_result_a2c, how='outer', left_index=True, right_index=True)\n",
    "if if_using_ddpg: result = pd.merge(result, df_result_ddpg, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_ppo: result = pd.merge(result, df_result_ppo, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_td3: result = pd.merge(result, df_result_td3, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_sac: result = pd.merge(result, df_result_sac, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "# Merging the results of the mean variance optimization and the DJIA index with the main results.\n",
    "result = pd.merge(result, buy_and_hold, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column names based on the selected strategies.\n",
    "col_name = []\n",
    "col_name.append('A2C') if if_using_a2c else None\n",
    "col_name.append('DDPG') if if_using_ddpg else None\n",
    "col_name.append('PPO') if if_using_ppo else None\n",
    "col_name.append('TD3') if if_using_td3 else None\n",
    "col_name.append('SAC') if if_using_sac else None\n",
    "col_name.append('B&H')\n",
    "result.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPO</th>\n",
       "      <th>B&amp;H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-02</th>\n",
       "      <td>88098.883545</td>\n",
       "      <td>88092.348203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>88098.883545</td>\n",
       "      <td>81467.595849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-06</th>\n",
       "      <td>92381.383545</td>\n",
       "      <td>85429.770431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-07</th>\n",
       "      <td>92381.383545</td>\n",
       "      <td>87986.691827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PPO            B&H\n",
       "date                                    \n",
       "2024-08-01  100000.000000  100000.000000\n",
       "2024-08-02   88098.883545   88092.348203\n",
       "2024-08-05   88098.883545   81467.595849\n",
       "2024-08-06   92381.383545   85429.770431\n",
       "2024-08-07   92381.383545   87986.691827"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the results\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we plot a graph that shows the total portfolio value over time for each strategy and the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the figure size for the plots and drawing the performance charts of the trading strategies.\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the portfolio values, we calculate daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/pyfolio/pos.py:25: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n",
      "/var/folders/28/0nrxt8bn57bdz8wy1xv7fb6m0000gn/T/ipykernel_28281/597744444.py:11: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  result[f'{strategy}_returns'] = result[column_name].pct_change()\n"
     ]
    }
   ],
   "source": [
    "from pyfolio import timeseries\n",
    "import pandas as pd\n",
    "\n",
    "# List of strategies for which you want to generate statistics\n",
    "strategies = ['A2C', 'DDPG', 'PPO', 'TD3', 'SAC', \"B&H\"]\n",
    "\n",
    "for strategy in strategies:\n",
    "    column_name = f'{strategy}'\n",
    "    if column_name in result.columns:\n",
    "        # Calculating daily returns from portfolio values\n",
    "        result[f'{strategy}_returns'] = result[column_name].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPO</th>\n",
       "      <th>B&amp;H</th>\n",
       "      <th>PPO_returns</th>\n",
       "      <th>B&amp;H_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-02</th>\n",
       "      <td>88098.883545</td>\n",
       "      <td>88092.348203</td>\n",
       "      <td>-0.119011</td>\n",
       "      <td>-0.119077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>88098.883545</td>\n",
       "      <td>81467.595849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.075202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-06</th>\n",
       "      <td>92381.383545</td>\n",
       "      <td>85429.770431</td>\n",
       "      <td>0.048610</td>\n",
       "      <td>0.048635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-07</th>\n",
       "      <td>92381.383545</td>\n",
       "      <td>87986.691827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PPO            B&H  PPO_returns  B&H_returns\n",
       "date                                                              \n",
       "2024-08-01  100000.000000  100000.000000          NaN          NaN\n",
       "2024-08-02   88098.883545   88092.348203    -0.119011    -0.119077\n",
       "2024-08-05   88098.883545   81467.595849     0.000000    -0.075202\n",
       "2024-08-06   92381.383545   85429.770431     0.048610     0.048635\n",
       "2024-08-07   92381.383545   87986.691827     0.000000     0.029930"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating returns for the selected strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy A2C was not found in the results.\n",
      "\n",
      "Strategy DDPG was not found in the results.\n",
      "\n",
      "==============Strategy Stats (PPO)==============\n",
      "Annual return           0.385130\n",
      "Cumulative returns      0.203068\n",
      "Annual volatility       0.266494\n",
      "Sharpe ratio            1.359215\n",
      "Calmar ratio            3.236081\n",
      "Stability               0.908452\n",
      "Max drawdown           -0.119011\n",
      "Omega ratio             1.363546\n",
      "Sortino ratio           1.813801\n",
      "Skew                   -2.290197\n",
      "Kurtosis               17.774265\n",
      "Tail ratio              1.127778\n",
      "Daily value at risk    -0.032138\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Strategy TD3 was not found in the results.\n",
      "\n",
      "Strategy SAC was not found in the results.\n",
      "\n",
      "==============Strategy Stats (B&H)==============\n",
      "Annual return          0.286186\n",
      "Cumulative returns     0.153521\n",
      "Annual volatility      0.314588\n",
      "Sharpe ratio           0.960509\n",
      "Calmar ratio           1.544246\n",
      "Stability              0.885049\n",
      "Max drawdown          -0.185324\n",
      "Omega ratio            1.188256\n",
      "Sortino ratio          1.255033\n",
      "Skew                  -1.790806\n",
      "Kurtosis               9.442469\n",
      "Tail ratio             1.087854\n",
      "Daily value at risk   -0.038435\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We assume that the result DataFrame already contains portfolio values for each strategy\n",
    "for strategy in strategies:\n",
    "    # Check if the strategy exists in the DataFrame\n",
    "    if f'{strategy}_returns' in result.columns:\n",
    "        # Extract daily returns for the current strategy\n",
    "        returns = result[f'{strategy}_returns'].dropna()\n",
    "        returns.index = pd.to_datetime(returns.index)\n",
    "\n",
    "        # Calculate performance statistics for the current strategy\n",
    "        perf_stats = timeseries.perf_stats(returns=returns, factor_returns=None, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "        # Print performance statistics\n",
    "        print(f\"==============Strategy Stats ({strategy})==============\")\n",
    "        print(perf_stats)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Strategy {strategy} was not found in the results.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting cumulative returns for each strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3QWYlOXaB/D/dncXbNHd3UopiIKoGIgKdutRzvFTj3HsDizEREVFRFo6pLtjF9hguztm5rue55nZgI2Z3dn+/65rrvfdifd9dnZYdu65w0Kn0+lARERERERERETUiCwb82REREREREREREQCg1JERERERERERNToGJQiIiIiIiIiIqJGx6AUERERERERERE1OgaliIiIiIiIiIio0TEoRUREREREREREjY5BKSIiIiIiIiIianQMShERERERERERUaOzbvxTtkxarRaXLl2Ci4sLLCwsmno5RERERERERETNkk6nQ05ODgIDA2FpWX0+FINSRhIBqZCQkKZeBhERERERERFRixAbG4vg4OBqb2dQykgiQ8rwhLq6uqKlRCazsrLg5ubG7C4yC76mqL74GiJz42uK6oOvHzI3vqbI3Piaopb6usjOzpaJPYZYSnUYlDKS4QctAlItKSglLmK9zfWFSi0LX1NUX3wNkbnxNUX1wdcPmRtfU2RufE1RS39d1LY+NjonIiIiIiIiIqJGx6AUERERERERERE1OgaliIiIiIiIiIio0bGnFBERERERERG1WRqNBiUlJWgpdDodiouLUVhY2GQ9pWxsbGBlZVXv4zAoRURERERERERtjgjuJCYmIjMzEy2NVqtFWlpak67B3d0d/v7+9QqMMShFRERERERERG2OISDl6+sLR0fHZj/JrmIwTWR3iUylplizOH9+fj6Sk5Pl1wEBAXU+FoNSRERERERERNSmiKCOISDl5eWFlkTXxEEpwcHBQW5FYEo8h3Ut5WOjcyIiIiIiIiJqUww9pESGFNWN4bmrTz8uBqWIiIiIiIiIqE1qKSV7rfW5Y1CKiIiIiIiIiIgaHYNSRERERERERETU6BiUIiIiIiIiIiJqIebMmQMbGxtYWlrC1tYWkZGReOmll1BaWorNmzfLsjrDxc/PD9OnT0d0dHSlY/zzzz+YPHkyPDw8YG9vjx49euDdd9+VDdQbE4NSREREREREREQtyIQJE3Dp0iWcPXsWTz75JF588UW89dZbZbefPn1a3v7rr7/i+PHjmDJlSlnA6Y8//sCoUaMQHByMTZs24dSpU3j00Ufxyiuv4Oabb5bT/RqLdaOdiYiIiIiIiIiI6s3Ozg7+/v4yG+r++++Xgably5djyJAh8nZfX1+4u7sjICAAzz//PG699VacO3dOBqLmzp2LqVOn4osvvig73j333COzqsT1S5YswU033dQo3weDUkRERERERETU5okMoYKSxi1fM3CwsarXNDsHBwekpaVVe5tQXFyMdevWyfs99dRTV9xPZFN17NgRP/30E4NSRERERERERESNRQSkuj6/tknOfeKlCXC0ta5TIG3Dhg1Yu3YtHn744StuT0hIwNtvv42goCB06tQJq1atktd36dKlyuN17twZZ86cQWNhUIqIiIiIiIiIqAVZuXIlXFxcUFJSAq1Wi1mzZsm+Unv37pW3izI9EbDKz89Hr1698Pvvv8um6AaN2TeqJgxKEREREREREVGbJ0roRMZSU53bFKNHj8aCBQtkb6nAwEBYW1cO72zbtg2urq6yt5QIXhmI8jzh5MmTGDp06BXHFdd37doVjYVBKSIiIiIiIqKGcvZvYNcC4Jp3AM+wxjnnkSVA9GZg0puAnXPjnLMVED2d6lJC1xScnJwQGRlZbR+qsLAw2ej8cuPHj4enpyfeeeedK4JSolG6mOb38ssvo7FYNtqZiIiIiIiIiNqa7e8DURuAv59vvHOKcx36EdhTPl2NyBDM+vzzz/Hnn39i3rx5OHLkCC5cuICFCxfizjvvxIwZMzBz5kw0FgaliIiIiIiIiBqCVgskHlH7J5cDyScb/px5qUBOgjr9rs+AksKGPye1KDNmzMCmTZsQExODESNGyAbo7733Hv7zn//g559/rtcUQFO1jLw0IiIiIiIiopYm4zxQlF3+9da3gRkLG/aciUfLdi3zkoAjvwD9ZjfsOalRLVq0CBqNptpeU8Y0MRfBqDVr1qCpMVOKiIiIiIiIqCHos6RSdG5yqzu+FEg916CnzIs5KLdFOhu51e74UGVsETVDDEoRERERERERNYDS+ENy+7emH/7W9IWFTgtse6dBz5l7UZ3za81EZOscYZl+Dji96so7ajXAvq+B2L0Nuh6imjAoRURERERERNQACi4ekNtjujB8VHq93NeJcrr08w12TuuU43J72KIzvtdcpc4pmq1XLOkS+yseA1Y8Diyd22BrIaoNg1JERERERERE5qbTwSblmNzV+PVAsks3bNH0hIVOA2x/r2HOWVII9zwV8Oo9YASW2lyLIp01LOL3AjG7yu+3/kXgwHcV+l7lNMx6iGrBoBQRERERERGRuWVfgn1xOkp1lvAO741Hr+qAj0qnyZt0hxYDmbHmP2fKKVhBgwydMzp16IxrhvTG75oR6pw73lf32fEBoN8XASv1uNPmXwuRERiUIiIiIiIiIjK3hMNyc1YXhE4hfrixXzDSvfphp6YrLLQlKjhkZiWXVGP1k9p26BLohtlDQ/EtpkCrs4DFmTXA3y8Afz8v7/O/kluwV9tJ7hdcUiV/RI2NQSkiIiIiIiIiM9NcUkGpE7pQdAt0hbWVJZ4c3wkfavS9pUT53OnVZj1n1nnVwyraOhx+rnbwcrbDwP6DsFbbX91BnyG1oHQKvtBMQZRFiPw6O+aoWddBZCwGpYiIiIiIqFZRKbkY985mfL294Ro0E7UmBTEqQHTGIhxhXk5yf1J3f+T4D1a9pTRFwE83A8sfAYpyzXJObYIKLuW6d4aFhYXcnzsiXAagDBaXjsEbpTfjv1O7QePZUT0u6YRZzk9kKgaliIiIiIioVp9uikJUSh5eX30Ksen5Tb0combPMlGV0uV7d4elpQoQie2/JnbBvJInsFBzDXSwAA58C3w2HIjdU78T6nRwyTold60Ce5Zd3c7LEUHdR+CNkptlT6vnSu/GE1d3kqV98Osi7+OQFVW/cxPVEYNSRERERERUo/S8Yvx15JLcL9Zo8dZaNkUmqlFeKhwLE+WuQ0jvSjeN6OCNEV1C8HLJrZhV/G+kW/uqCXhfTwA2vQZotXU7Z1YsHDS5KNZZwSe8R6Wb7h0ZgQWaqXindCbuHBaBh8dGyuvdQtT93IsTOYGvBZkzZw5sbGxgaWkpM+K8vLwwceJEHDmiAqEG77zzDkJDQ+Hg4IBOnTrhiy++uOJYmzdvlsfIzMy84jbx2Pff1zfIbyAMShERERERUY2W7ItFcakWQe4OEBVByw9fwqHYK9/AEFHlJufRWn90bBdY6SYRAFhwW188Oq4D9qA7Rue+ijWWIwGdFtjyOvDHPKC0yORTahNUQOKcLhidg7wr3dYj2A0vTumKf03shOeu6VJW2hcaEoRknbu6U8qZun631AQmTJiAS5cuISEhARs2bIC1tTWuvfbastu3bt2Kp556Ck8++SROnjyJhQsXwsfHB80Ng1JERERERFQtjVaHH3ZdlPviTfQNfYLl/qsrT0Cn0zXx6oiaJ62+yflxfZPzy9lYWeLxqzvi9/uHwsvbF/fl34enS+ZBY2EFHP0V+GE6UJhl0jmzLxyS29Nojwgf5ytuv3NYGB4YHVlWSihE+rrgjDZI7hdcOmby90lNx87ODv7+/vLSu3dvPPvss4iNjUVKSoq8XWRRWVlZ4e6775YZT8OHD8f116sm+80Jg1JERERERFStzaeTEZdRADcHG0zpFYinJnSEvY0l9l7IwNrjSU29PKJm3eT8JMIR6XtlgMigd4g7Vj4yHLcPbo9fNaMxp+gpFFo4ABe2AV9PArJV2awxCmNVUCrVqYMMehlD/LuOt2kv97MucgJfS5Wbm4sffvgBkZGRspRPEIGqoKAgPPDAA9DWtSS0ETAoRURERERE1fpenyU1s38wHGytEODmIKd5Ca+vPinL+oio6vK9XI+utQaIHG2t8fK07lhwa1/ssuyD6YXPId3SA0g+Diy8GpZpxpXV2aerCXoa3+4mLTXPTfWX0iafNOlxrZLI/izOa5qLzrTM05UrV8LFxQXOzs5yu3z5cvzyyy8yQ0oEoaZNm4ZevXrJXlGzZs1CcXFx2WN79OiBt99+u9LxgoOD5bEqXmJiYtDQrBv8DERERERE1CJdTMvDljMpso/UbYNVNoVw76gI/LQnFhfS8vHj7ouYMyysSddJ1KwUZsEpT72Zt72syXlNJvUIgI+LHe75zgpTC17EYvs30S47Hi6/TAduWQyEjajhnNlwL4yXuy7t+5i0XAvfrkAG4Jh1zqTHtUol+cD/KvcAazT/vgTYOhl999GjR2PBggWyP1hGRgY+/fRTTJo0CXv27MHx48exY8cOxMfHw8nJSfaamjJlCpYuXSpL+s6dO4cRIyq/nrZt2yaDW5efo6ExU4qIiIiIiKokekmJD+9HdfRBe6/yN0vOdtZ44uqOcv+DDWeRVVDShKskamYSVRlcnM4b4e3Kg7nG6B/qid/uGwq4t8PUgudxCJ1gUZwN/HADcOz36h+YdFxuLuk8ERHazqRzuoWozCpO4GtZnJycZLmeuAwYMABfffUV8vLy8OWXX8opfO3atYOnp6fsPbVs2TJZ4jdu3Dg5TS88PByDBg2qdLywsLCy4xkuonl6Q2OmFBERERERXaGgWIMl++Lk/h1DrnxjLcr5Fu04j7PJuVi8Owb3j45oglUSNT+6hMMQrcRPaNtX2eS8NqIH1dIHhuKub/bipvj5+MjuE4zX7AV+uwvITgCGPnTFYwpiD8FB9LDStkd/f9PO2V4/gc/XIlNN4AvuhzbLxlFlLDXVuetBZEyJ0r2CggJ06tQJ58+fR1xcnCzLEwGsVatWYcyYMZg/f77MmGoumClFRERERERX+OvwJZkBFezhgFEdfa+43drKEjP6qUl8JxKym2CFRM27yflxXRg6+VcuhzKWr4s9fp43BIM7BuG+okfxrWa8umHdf4A184HLGldnXzgot7G2EXBztDHpXJzAV4GoVRYldE1xsSifimiMoqIiJCYmysvJkyfx8MMPy2woUaY3ffp0mSl1zTXXYP369bJcb/Xq1UhPT5cBqkWLFjWb5ucMShERERERUSU6nQ7f7bog90UvKasKI+QrCtePnY9Kzm3U9RE1Z9p41eQ8w60L7G2s6nwcUSb75R39MKWHP14omY3XSm5RN+z6FPhtDlBSWHZfy2QVTCr06mryedQEvlC5zwl8LcfatWsRGBiIgIAAWYq3d+9e/Prrr7IPlKOjI/755x9Z1jdnzhx0794db731Fl5++WV5v82bN+Oxxx5Dc8DyPSIiIiIiKpOQVYBnfj+KY/HZsLW2xMz+IdXeN8JH9Zk6n5oHrVYHy2qCV0TNmqYUKM4FHNzrf6zifDhmR8ld6yDTGo5XRUzue3FyJEJ9XfHBhilI0HniXdvPYX1iGZCXAtz8I2DrAvecs/L+tsG96nSePLcI2eycE/hahkWLFskeUqJpuSjbq4qvr6+8T1Wys8uzW0UQS3wQUZULF9SHEw2JmVJERERERK2AeFNxNC4LxaXaOj/+9/1xGP/eVmw9kwI7a0u8Mq07PJ1sq31MiKcjrC0tUFCiQWJ2edYGUYuQnw5sfw/4oBfwZjhw8Z/6HzP5BCyhRYrOFSHtzDOVUgQdHruqI96Y3gMrMRy3Fz+DfAtH4OIOYOEE4Pxm2OiKkaezQ2BY17qdQ0zgAyfwUeNjphQRERERUSuw9ngi7vvhAMZ29sXC2f2r/fS8Ksk5hfj30mNYfzJJft0rxB3v3NhLNlyuLYujnZcjolPyEJWSi0B30WqZqJlLOQ3sWgAc/hkoLSi/ft8ioP3Q+h074ZDcHNeGoXuwGTKvKrhpQDv4utrjwR8tcUPh8/jB/i14p56GbvFNsrH6aV0IugbW7ZxyAt/pChP47OrWC4vIVMyUIiIiIiJqBdYcS5TbjaeS8deRBJMamovsKBGQsrGywNMTOuH3+4bUGpAyiND3lRKBKaJm7/gy4JNBwP5FKiDl3wMY8aS67fTqSn2a6iI/UZXRndMFokuA6ZP3ajOmky9+mTcEqU4dMKXgRURbhMBCWypvO2sRJgcT1EX7kGA5gU8SE/iIGgmDUkRERERELZwovdsRlVb29Ut/HUdWfkmNj0nPK8aDiw/g4Z8OIjO/RI6u/+vh4XhwTKScrGescH1fKZEpRdSsiWljG18R/2KAiLHAnauAe7cBY54DXAKB4hwgamO9TpGbfFFui5wCZaPyhtAj2A1/PDAUDt7tMK3geezUqNK7WI+Bde7r1sHPuWwCX358G5/AR42KQSkiIiIiohbubHIuUnKKYG9jKZuPp+YW47XV1TcsXnc8EePf24KVRxLkZL1Hx3XAsgeHobO/6ZkdzJSiFuPceiDtLGDnCsz8DggdJho2AZaWQNfr1H1EA/F60GbFya2dVzs0JNHP7ff7h6JD+2DMKvk3hhe9j5zQSXU+nqu9DeJt1QS+7FhO4KPGw6AUEREREVELt+NcqtwOCPXE69N7yv2f98Zid3R59pQgsqee+OUQ5n2/XwauOvo5Y9kDw/D41R1lf6i6MEzgi2amFDV3uz5R2753VOqZJP5dXPS/uryEr7SozqdwKFBltA4NHJQSPJxs8eM9gzCpRyDi4YvRXfzqdbw81wi51SaZZwJfYlYhxr2zGdd/uuOK30XNSXWT56hxnjs2OiciIiIiauF2nFNv+IZFesvA1C0D2+GnPTGY/8dRrH50BOysrbD5dDKe+f0IkrKLICp85o2MwGNXdYC9jVW9zh3urTKlLmUVIr+4FI62fItBzVDScSB6M2BhCQycJ686k5SDRTsu4I+DcSgqKcVJDz/YFySpEr5Odcg60pTCpUT9W3Twbo/GIP79fnprP+QUlsDF3qZex7IUE/gyzDOBTwQr5i89gih9BuVNX+zCxG7+eHZSZ4R6q0B2U7OxUc9Xfn4+HBw4pKEuxHNX8bmsC/6PQURERETUgpVqtGVZCMMivOX22Ymd8feJJFlS9+66M8guLMFPe2LlbWHeTnj7xl7o197DbNkank62skeVOF/3IDc0Bxl5xbCxtmywvj7Uwuz6VG50XaZgY6I9Fv2+G9v1GYaKJbZaD8F4LFPN0OsSlMpJgCW0KNZZwcNP9WdqLPUNSAlu7cw3ge/3A/HYdDoFtlaWuLZXAJYdjMea44nYcCoJs4eE4tGrOphlzfVhZWUFd3d3JCcny68dHR1NmlralHQ6HTQajfwemmLN4vwiICWeO/EcinXUFX9DExERERG1YEfis5BTVAp3Rxt0DVQ9odwcbfDi1K54aPFBfL41uuy+c4aF4l8TOsPBtn7ZUZcL93ZSQanU5hGUEj2zHv35EPzd7LH+iVGybxa1YbkpwJFf5e5Kx+vx0Lf75L54WYzv6o/x3fzwxJLD+Cq9F8bbLANOr1IlfNZ2pp0nO15uknSeCHRvHtlAdZnA52uRqSbwBferc9nef/86LvdFafD9oyNw36gIvLryJLacScFX28/jTHIuvp0zoMmDQP7+/nJrCEy1JFqtFpaiH1oTEgEpw3NYVwxKERERERG1YDvOqmyPIeFelYIv1/QIwNLO8dh4Khkhng54a0YvDA73apA1iAl8+y5mICq56ftKfb39PF5eeQKi1cn51DwcjMlA/1DPpl4WNaV9CwFNEbSBffHCAREsKsEtA0PwwOhI2TBc+HbnReyN7YA8Zx84FaUAUZuAThNNOk1RWgxEGOsSvNDF3R4tTQdfZxzWBsHXKlNO4HOsQ1DKULaXU1iKXiHumDsiTF7f0c8F3941EJtOJ+Pe7/Zj65kUuT+2c/36YNWXCIoFBATA19cXJSU1TyxtTnQ6HXJycuDi4tJkgT1RslefDCkDBqWIiIiIiFqwHVGpZf2kKhJvVD6Z1VdmJgzv4G2eMraSAsDaXk0sq2oCX2rTTeDTaHV4ecUJfPPPBfm1h6MNMvJLZBkjg1JtWEkhsPcrubvNaybSoksQ7OGAl6/rDusKzf2v7x2Iw7GZ2GQxGNfiLzWFz8SgVE7yRRmUSrHwxqAmLk2rCxfDBD7NceSe3wPHQbPrVbb39oyelZ5jYUwnX5mxKTI4RebUiA4+dR6yYE4iuGKOAEtjBqWKiopgb2/f5Nlm9dX0P30iIiIiIqqTgmINDlzMrDIoJYgyvYnd/c0TkIrZBbwWAqx6+oqbwvVBqabKlBIN1u/9fl9ZQGr+pM54ZVoPub/2eGKrna4lmtcPfHW9bGpP1Tj2G5CXAp1LIJ47HS6vundUxBXBkmt7BcpMw2+z+qgrTulL+ExQnHZRbnPtmzb7pz7S3NX0Tt9TPwDLHwaKcutcttfBr+qeVA+OjZR96EQTdL52iZlSREREREQt1N4L6SjWaBHoZo9QL1WG1GC2vQNoS4C9XwK9bwGCykt7InxU/xxRLqfV6mDZiD2ckrMLcfe3+3A0Pgu21pZ4b2ZvXNMzALlFpTJb40JaPs4l51b7BrmlikrJxcOLD8p+Yr/vj5MTF+kyIhi5UzU4Pxp0M2IPlcLb2Q439gu+4q7i+pEdvLH5dEfk2njDuShVTevrOMHo02mz4uS2yDEQLVV66LX4LOkY5lmvgOWB7xB/aD3ecXkaZ6071vrY1NyiK8r2quJqbyODVv+37Bje+/sMrusVJPvgUdvETCkiIiIiohZqh356mMiSatASjrQo4Ozf5V+v+bd6w68n+vJYW1qgoESDxOxCNJYzSTm4/tN/ZEBKZF78NHeQDEgJIjtsWKTqobXuRBJaEzFNce53+2RASjiZkC2DgXSZi/8Aycehs3HEc3EqiCqCJfY2VZdpXd83GDpYYo12oLpCTOEzgU1ugtpxa9zJe+bUP8wbr5fegluL/41LOk8EaS/hjcynMDLxWxyPz5D/1qq7JGQVws66QtmephTY/Dpw7PcrznPLgBDZw0qU2H686WyTfK/UPDBTioiIiIioGTkWn4UjcVmY2T/4ihIjY/tJmd3ehSLtBAjqDyQdB2J3qZ473a6XN4ueMO28HBGdkiczeALdHRp2PQC2n03F/T/sl4EZMf1v0ZwBaO9VeeLZ1V39ZX8bEZR6cEwkWgMRfHril0PyuQ5ws0dGfjHyijW4kJZXVkZJeqdWyk184HgcOW0BV3tr3Dq4fbV3v7qLH5xsrbAkvx9m2K1Sjy8tBqxtjTqdU2Gi3Np4hKClmtDND388MBSZBQMQVXw9rPY+D7+YVXjaZgnmBkbj5OC3UOh8ZaaZQZiXE0K99f8O//kA2PwaYGEFeHcC/LuX3U/8bvvPNV1w56K9suz21kHtyx9HbQozpYiIiIiImoniUi3u/nYv/v3HUby59nSN983IK8bxS9lyf6g+I6hBiJ4yB39Q+6OfBYY9qvb/fl41kb682XlKwzc7X7IvFncu2iMDUgNDPfH7/UOvCEgJV3X1lT3ZRQPrpEbM4GpI7284i/Unk2Wp4ue390Nnf1d5veG1QBWcXSs336d1lts7h4XV2F9N9WALwD5dJ2RbewFFWUD0JuPOVVIIZ43q7+bkU33gq7kTGZd92nnIhuQjenSA35zFwLTPAFsXuKfsw5B112FM0WZ5e1WXssBS0glg02tqX6cB/noU0GoqnWt0J1+M7OiDEo0Or68+1QTfLTUHDEoRERERETUTK49eQlK2aq78xdZoLDsYX+19d0anyQq6jn7O8HVpwPHzR35Rb849w4GIccCwRwCXACAzBti9oOxu4fq+UtEpDdvs/Nt/LuBfvx1BqVaH63oH4vt7BsLDqepMFvG89Alxl/tiCl9Lt+ZYIj7coEqdXru+B3oGu6NbIINS1Zacpp2D1sIaP6ZGwtHWCnOGhtb6sOv7BEELS6wsHWBaCV+2+rdaoLOFt48/Wg0R1RU95O7fDoQMAoqygaVzgd/uBgpUEO4KmhJg2f2qB13oCBnQQvw+YN/XV9z1P5O7QLSgW3M8Edd9vB3TPtlRdpn52U48uPiAnKr5xdYo/HkoHruj03AhNQ+FJZUDXNRysXyPiIiIiKgZEBPiFm4/XxbgERlHz/x+BJG+zuge5HbF/bdX6CfVgIsC9nyp9gfMBSwtAVsnYNwLwLL7gK3vAL1vBZx9yzKlxESthpJTWIK316kMsvtHR+BfEzrV2ktLlPAdiMmUJXy31VC61dyJN+JPLjkk9+8aFobp+mbd3QLVa+P4pawmXV+zc0ZlSR236Y7cAkfcM7BdtcHLioZEeMHXxQ5/5A7ALXZrgNPGlfDpsuIgXomXdF4I9GjgoQNNwSMUuHOVGniw5Q011TB2N3D950DosMr33f4+kHAIsHcHbvgSOLUCWPUUsP6/QOdrANfyRvCd/F3kv8vvdl7E4TjTXsNuDjbwd7WHr6ud3Pq7iX17te9qDz9XO3g528mpitR8MShFRERERNQM7L2QgWPx2bJR8JJ7h+DpXw/LfkjzvtuH5Q8Pl9PBKvrHEJSKaMCg1IVtQMpJwMYJ6D2r/PqeNwF7PgcuHQQ2vQpM+aBsAl9DZkot3h0jp3uJcz09vvaAlDC+mx/eWHMKO6NSZVDLxd6mRQYs/7PsqOwdNTDME/+erMrRBEOm1IlL2fJ+DdrwvgWW7i3L6wYbKwvcMyLcqIeJAIbIwFu4rQBZVp5wK0zXT+EbX+PjClJjIUJRCTpP9HdrwMzFpmRlDYx+BogYq7KlMs4D31wDDH8cGD1fBe4Sj6mglTD5LcA1AOh/F3D4Z5UttfpfwE36cmC9567piqu6+KGoVFvp+qJSjcwcFaW34pKYpd9mF6KwRIusghJ5OZ2UU/2SLS1kkNHHxU4OY6jI08kOz0zs1Oomc7Y0DEoRERERETUDC7dHy+0NfYNlAOr9m/vIEpbzqXl48McD+OGeQcguKMGGk8lYdyIRF9Ly5RuuQeGeDbeo3Z+rba+bAAdVBieJjKkJ/wMWTQIOfAcMnIdw7w7ypktZhcgvLoWjrXnfaog3qIZMsntHRcDSyOwHkcFlyDzbfDoFU3qVZ2m0FEsPxGPHuTQZsHzLMNmsQqaJeB2k5RXLN/AiW6TNK8oBLuyQuxu1fTGpZ4BJz8u0PkH4ctt5/FXSH7dZrlNN/WsJSuUmX5BBqXRr32qn+7UaIQOA+7YBq58FDv0AbH8XiNoIXP9Zedlep2uAHjeq+1taycA1vhgFnPwLOLUK6Dy57HCiP5roLWUsEXzNLiytFKgyBKsMQSxxfWpuETRanZwKKC5V2RWdho9u6YMxnX3r/7xQnTAoRURERETUxGLS8mV5mXDXsNCy0pQv7+iHaZ/8g93n03HVu1sQm54Pra78cdf2DGi4zB/RM+r0KrU/cN6Vt7cfCnS+VpXmHFoMjwmvwtPJFul5xTIAVFXJYX38cSAeyTlFsixnWu8gkx47vqs/PtsSJZ/jlhaUSsstwisrT8j9x67qeEVDdxEAifRxltkiooSPQSlRQ7pJBkbiLQNwXheAJ7r6mfTwrgGuslfbX8mDcJvdOvUaL32/xhK+4oxYuc2zM+1cLZadCzDtExWsW/6IKtf7dIia0ungAVz7nupHZSAm7w15CNjxvirlCxuhjlEHIhtQ/H4Ul441ZDmVarRIzS2WwarUnCJoRDmyntj9evt57LmQjru+3Yv5kzpj7ohwZho2ATY6JyIiIiJqYov+OS/fJIlsgYqlJJG+Lnh3Zi+5fzFNBaREudbjV3XE6kdH4P2bejfcokRTYp0WCBsJ+Hap+j6ijEdIPSM34frJW9Gp5u0rJbIdRON34Z4RYTKzwhRX64MSm08lywmHLcmrK08iI78Enf1d5PdeFTY7r7p0b21xL5lFZkoWjiACEyJbaq+uEzItPYDCLOD8FqManRc7t6ygZ711vQ54YCcQNkoFpITJbwMuVQTnRj0DuLdXz5VhMl8DEhmFIkjbO8QdV3X1w4Ru/mWXid39ZfbpzQNC5O/e/606hSd/PcwG6k2AmVJERERERE0ou7AES/aqLIu7h18ZdBjfzR9f3dEfCVkFssQkuDGaKIvJZfu/VfsD763+ft4dKwelfJyw72IGopLN21dq3fFEGegSmRE3D2xn8uPFBD5REinKeUS5jqlBiqay9UwKlh6Mlwknr0/vCZsKZXsVdQ10lfdjs3MAWi1wZp3c3aDtg/7tPeTrxlTX9Q7Cm2tOY3lxf9xh/beawtfh6mrvb5uXILcWbqoBfZsiGpffvgw4/BOgLQW6T6/6fraOwLXvAj9MVz3p+s8B9GW/TUEEt1+7oYcsgRUT/kSZ7O7odLg7Vn69jO7kg6cnlPdxI/NiphQRERERURMSASnRwLqDrzNGdqi6abn4lP/2IaENH5DSaoB/PgYWDAUK0gHPCKDjxNqDUhkXgZLCsgl85syUEv1jFmyJkvuzh7SHs53pn6uL/lOGbCnRj6slKCjWyObmwuwhoTLbozrlE/iYKSXLyPKSUWDhgD3aLhhbx15BQe4OGBTmiVXaQeoKUcKnKan2/s6F6nVl52V60LRVEH3m+twK9JtduWzvcpFXAR0nqeDVuufQ1ERW3JxhYfj2roFwtbdGfGaB/HdU8fLJpigci2fAt6EwKEVERERE1EREWdo3/1yQ+3cND6tfP5P8dODPB4GYXXV7fOpZ1bh83X+A0kIgfDRwx59q4lZ1nH0BexEQ0QHpUQg3BKXMOIFvZ1QajsRlwd7GErOHqn5bdSHKdYQ/D16SE7uau/c3nEFsegEC3Ozx1IRONd5XZEoJcRkFyMpv/t9bgzqrsqS2abqjBNYY16XuDayv7xOEPdrOSLdwBwozgehqSviKcuCoVa95Z5/2dT5fmzH+FcDSGjizBji3Ac3BiA4+2Pz0GHwzZ0Clyzh9UPNzffkwmR+DUkRERERETUSUpYlAgoejjXwDXC97vwIO/gD8fKsKUJmUHfUR8NlwIHY3YOuiJmWJchz3kJofK4JoFUr4Inz0PaVS8qCt2JG9HgxZUjf1D4GXs12djzMi0ls2r84pKsW3+kBgcyXK8L7apiYNvnxd91qzw0R5WrCHg3psQhvP6BCBDgB/a/qgnadjWfZeXUzqEQBra2usLOmvrjjxR9V3zFL9pLJ1jvD1qTrbkSrwjiwfnrD2P4CmFM2BGNQwupNvpcsT49Xvt1VHE+SgCTI/BqWIiIiIiJrIwu0q8HDroPb1HyMvJo4J+anqjZ4xUs4AX09QZTQiO0o0LhdNi/vdWXMJTkVlQamzCPF0hLWlBQpKNHLiVX2JkpltZ1Nls+p7RoTX61iihO/BMZFy/+sd55Fb1DzeCFeVPTd/6VG5ndzDX5ZuGsPQ7PxEWy7hy0kCLh2Uu5s1vWXpXn2yD0Ww76ouvhVK+FZWWcKnzYyT20s6L5nZRkYY9S81pS/lJHDgGzRXojR2RAdv+e/R8PuazItBKSIiIiKiJnA4NlM2BbexssAdQ+pZ8lOUC8TtqXDwxUDUxpqzo3Z8oLKj4vYCdq7A1I+A25bWnh11OUOj4tQzshF3Oy/V9yrKDCV8H2w4K7fX9gyQAa/6urZnoJwQmJlfgu93XkRzJLK4RLmii701XpzSzejHsa8UgHN/y81JiwikwL3O/aQqmtY7CLu1XZAON6Ago8opfLkpKvMuQecJP1cGpYwiAlJj9MHzja8CBZmVb084rDI/z6xV+7kpqol9E5g3UgXEf9kbi4y84iZZQ2vG6XtERERERE3A8Kn7lJ6B8K3vG9mLO1TjYDFuvdMkYPdnwF+PAg/sAmxVSV2ZlNPAsgeA+H3q64hxwNQPgbpODTNkSonjArJhuyjfO5OUK/u01NXBmAz8fSIJlhbAw2PNM6FLZFw9MCYST/16GF9ti8adQ0PhYFvPDDUzEk2W316nnsf5k7qY9LowZEq16Ql8+tK9tSW94GhrhUHhnvU+pCjhcnW0w6ri/rjNeoOawieadVeQnxoD8exn2vhWOyGRqtBvjio7TjkFbH0LGPEkcGQJcOgHIFE1+a/E0gZw8ddfAtTUP7mv3xq+tnMx6zKHR3qja4ArTiRk4/tdF/HIuKabGNgaMShFRERERNTIErIKZI8SQ4PzejOU7kWMAcb+nyozyowBNv0PmPCquk30bdn5EbDpNUBTpLKjJvwP6HOb8aV6NQWl0s7JTIZO/q5YezwJpxLql7FjCM5M7xuMSN+69wW63HW9A/GBvon44j0xuNscz7+Zpgz+37JjyC/WYECoB24eYFrGmiFTKiolD4UlmvqXg7bE0r2ozXJ3o6YPhnf0hp11/Z8DW2tLXNMjACv3DsZt2KCm8F37HmBlU3af0oxYuc13UM30yUhiiIL4/fTDdGDXAmDPF4BGn4lkZQuEDAKKsoHsBCBPZEqVAFmx6lIT0RdPBqkCVPBKXNzbAT1n1ilgJUpA7x0Vjkd/PiQzGUXmVJv799WAGJQiIiIiImpk3+28iFKtDgPDPNE9SAUT6iVaH5QSE/PsnNWb5h9nALs+BbrfANg4AcvuBy4dUPeLvFo1M3erZ3N1wSNUTdIqyQey49HFX73pO52UU+dD7jiXih3n0mRp46NXmTcrQWSyPDA6UvZt+nxLFG4d1K5ZvMFcdTQRG08ly+/5tRt6yB5YpvBztYOXky3S8opxKjEHvUPc0WaI8q6fbgGKc5Bg6Y+jujDcWo+pe5cTQwhu2t0ZaTpXeMkSvq1A5Liy2y2yVaNzjXOg2c7ZZoisM/H7SJReajSAf0+gz+1AjxmAY4VMN9HLKzcJyEkEsi+pbc6ly75OUEGs4hwgTVxU+W+ZzIvA1S/VaZmTewTgzTWnZTbj7wfiZB9AMg8GpYiIiIiIGlF+cSkW746R+2bJ0hFZBKL8BRZA2Ch1XYergR4zgaNLgF9uV1kGIgPBzg2Y+BrQe1b9sqMqEhkjnuGyp5S4dPJXTaFPJ+bI5sCiZM7UjKG31qosKfHGL9jDsW49tjb8V5UkDnv0iptF9tVHG87iUlYhft0Xi9uHhKIpZeWX4IXlx+W+CJhF+tYtm6NroKtsDC9K+NpMUOrEcuCPe2VQtNSzA25OuB86WGJMJ/MFpfq190CAhzPW5AzAraKE78SySkEpu3yV9WjhZmI/NlJu+AI48gvQfhgQ0LP63zPi33NtZcbi374hQGW4xB9QPzPRn6qOQSkRzBa/r19acQJfbo3GzQPamfy7jarGglciIiIiokb0+4F4ZBWUyHH1V3UxbrJajaJVyRICe1fOLBDBJwdPmb0kA1IdJgAP7gL63Gq+gFQVE/jaeznB3sYSRaVaXEzLM/lQ608m41BspjzGA2MiTF9LVjywaKIqBfr7eRW0q6Ik677R6tgLNkehuLRpGigbvL7mFFJzixDu41S377ktNjvX6VQfoiW3qyy9iHFYMeBbXNT5o0eQW/37tF0W8BPZUisNU/hOriifwqfTwaUoWe7aebcz2znbFPF7a/D91QekTCEyRb0jgbARqlxPBKVF5qiFpQreZ6lJiXVx04AQOZHxQlo+/j6RWP+1ksSgFBERERFRI9FqdVikb3A+Z1ioeT5pLyvdG1P5eidvYPqXQMhgYNoCYNYvqhFwQygLSp2R31NHP5XpI8rITH1+3tH3kpozLAy+LiYGFi4dBL4aV7lJ8umVVd51Zv8Q+LrYyWyppQfq/ka1vvacT8dPe1Tm3GvX96hXH6TyZuetPChVUggsnQdsfEV9Peg+YNYSrI0qlF+OMcPUvctdp5/Cl6ZzAQrSgQvb1A0FGbDTqfO6+bKkq9kGvYL6qf1zG+p8GCc7a9w+WP2MP9sSLbM6qf5YvkdERERE1Eg2n0lGdGoeXOyscWN/M5T6iDdFhkwp0U+qyn4tlSeFNXRQSujs74IjcVkyKCV6sRjrryOX5GNc7K1xr34Mu9FE9srSuSprxqeLypQQ2VLi+gH3XHF30UdKNCx+ZeVJfLo5CjP6BcO6kSenFZVqMH/pEbl/y8AQDAr3Mu0A+enA7s9V/x3vDmVBKdFkvlSjbfTvx1Qxafl47JeDyCzQZx0ZwUObgZcL/oeu2jMohRU+tJuHFScmAie2IzY9X95nXAMEpUSz/W7BnlibOACzrDeqKXwRY1Umonjp61zh59VGSiZbIjFlNG4vELUB6De7zoeZPTQUX2yLltmcey9kyL6AVD/N7rfUa6+9hgEDBsDFxQW+vr6YNm0aTp9Wn5YYFBYW4sEHH4SXlxecnZ0xffp0JCUlld2enp6OKVOmyNv69OmDgwcPVnq8eOw777zTaN8TEREREZGwUJ8lJcpAnO3M8Plw8knV/NfaAWg3GE2mQvmeICbwCaZM4CvRaPHe3yqoJQJS7o62xgfmdnwI/HKbvoxrLHD3WpU9I4iMFtGcugqiZ5VoDh6Tno8/D11CYxOlg2Jano+LHZ6d1MW0B5cWAz/PAra8Dqx/UV4V6uUEJ1srWTopgp/Nmcgy+dfvh3EgJhPRKXlGXRxSj+Oj3CdkQCpT54Tbi5/Fh1kjym4v0egQ6uUoy/cawrTeFUr4xBQ+TSk0+sl7CTpPBLqbr2SQzMzQA0wE8cUk0joS/1ZFTzpBDEqo77+BD9afxZxFe664vPDnMbQVzS5TasuWLTJoJAJTpaWl+Pe//43x48fjxIkTcHJykvd5/PHHsXLlSvz6669wc3PDQw89hBtuuAE7duyQt7/66qvIycnBgQMHsGDBAsydOxf79u2Tt+3atQu7d+/Ghx9+2KTfJxERERG1LacSs+VEOVGxJz5tNwtD6V77oYC1HZqM6OEi5CYChVl1msD32/442atFBIlE6Z5RRF+flU8AB75TX4uMqIlvqFHz9m4qYyrlJHBmHdDrpise7mBrhXtGhOONNafwyaZzmNYnqNGaF59LzsGnm9Sb2hendJO9aowmAnGrngJidqqvLx2SGzGxr0uAK/ZdzMDNX+yCnbVlrQ2835rRSz4PjW3Jvljsik6XvcM+mdW31iCtx8U1iNjxMqxKC1DgGo4LY7/EY65heOyy+3XydzF5cqGxpvQKxOuruskSPq/8NBnwzEm+AJEflQhvdHNqwn+DVLPAvup3QmGWmkIaMrDOh5o7Igw/743BhlPJOJuUgw76cmVTRaXk4r31KhB/ua4BKrDfFjS7oNSaNWsqff3NN9/IjKn9+/dj5MiRyMrKwsKFC7F48WKMHTtW3mfRokXo0qWLDDgNHjwYJ0+exM0334yOHTti3rx5+OKLL+T9SkpKcN999+Grr76ClVXTj30lIiIiorbja32W1MTu/gjxrMNEuapEbaq+dK8xiTd7zv4qKJV6Dp38u8urL6blI6+oVPZiqUlhiUZmDAgPjoms9f6SyH5aMhs4v0U1MZ7wGjDo3spN3Ltcq4JSp/6qMigl3D6kPT7bEiUzi1YeTcDUXoFGZTh8uS0amfkluHNYqMm9r0TvrPlLj6JYo5WlZpN7+Jv0eOz9CjjwrZq4CB2QHQfkpco+YiM7+sigVHpeca2HWXEkAbZWlnhnZi/ZzLuxJGcX4tWVJ+X+k1d3wriaGv6LANy2t4Et+v5REWPhMGMRejs0fqmcyJIZEumHtdH9Mct6k5zoVlDsIINS2ba+DRYMIzMQgWrRd09M4RN9peoRlAr3ccb4rn5YezxJ/h54c0avOh1n+9lUuRVlt3de9kGF0ZmirUCzC0pdTgShBE9PVaspglMiuHTVVeW18Z07d0a7du2wc+dOGZTq1asXNm7ciHvuuQdr165Fz56qi/+bb76J0aNHo3///rWet6ioSF4MsrOzy/4DaikNzQxrbSnrpeaPrymqL76GyNz4mqKW8voRk9WW6cvD7hoWVvM51/4bOL0auHkx4FtDSZeYqHdxhwpLiKBUU/878O4Ai9xE6FJPwzOor3wDn5JThNOJOejTruYAwg+7LiIxuxCBbvaYNTCk9p9J+nlg8UxYpJ2FztYZmL4Q6DhB3VbxsZ2vgcXWt6ATb0KL8wEbhysOJcrd7hoWivfWn8XHG8/imu7+tQYXRNbb/1adkvuLdlzAnUPby/5UItvJmNfUT3tjZD8aR1sr/Pe6bvplG/nzE0G41c+on7sYb3/gW1iknYMu4bAM2Dw0JgITuvnJEr6aiMmIj/1yGEsPxqNnsJv5sveM8MLy48guLEWPIPFmvH3133tpIbD8EVgcXSK/1A2cB0z4H2Bp3WSv92m9A/H7ucGYhU3QnfwLGg9VzlfgENAgv0v4/5wZRYyFxYll0J1bD4x+tl6HmjciXAal/jgYjyeu7gi/Okx73BGVJrciKC162l2upp95S3hdGLu2Zh2U0mq1eOyxxzBs2DB0764+bUlMTIStrS3c3Sv/x+bn5ydvE5599lncf//9iIiIQGhoqMysOnv2LL799lsZuBLZUuvWrZPBqS+//FKWAFbV2+q///1vlUGy5vyDr0isMzc3V+435icf1HrxNUX1xdcQmRtfU9RSXj8Lt8eguFSL7gHOiHCzKPvg9XIW2XFw3f0ZLHRaaBbfhNybl0Pn4FHlfa3idsGlJB9aR29k2weLP1TRlBxc28MO21AUdxSFoZMR6e0gg1IHzych3K3651dkUn2yUWVJzR0ajML8XKhZZlWzSjwEp2V3wrIwA1rnAORe9zW0Pl2r/v4dQuHqEgzLnDjkHl2B0ojxVR7z+u6e+HKbFc4k5WLZvvMY16nmhuMrDqg+QrZWFigo0WDBlmh8v+si7hgYiOs6u9b4mkrJLcZrq1SW0IMj2sHZohhZWbVnNQmWWTFwXjIbljoNijtfj/yut8Px4l7Ypp1D4fndKPJWE8b8jHh/3M7ZCY+Nbo93Nl6Qzd7buVqib0jD9GKqaOOZNKw+lggrC+A/48OQl1t1iadFXjKc/poH68SD0Flao2D0SyjueSuQ07S9sgYHO+D/rLojXecMz/w0+BaqbMViB99q/13XB/+fMx8L34GQr/BLB5CddBE6+7pn20W4W6JPsCsOxmXj802n8eho04K6pVoddkapTKle/vYmv3ZawuvCkNjTooNSorfUsWPHsH37dpMeJ4JMoryvIlHq99Zbb+HHH39EdHS0bJ4uek299NJLVTY9nz9/Pp544olKT2hISIg8tqtry6jvNATPxJqb6wuVWha+pqi++Boic+NrilrC66eoRINfD6mhPHNHRl7x4Wole9+TASnBKisGruseAW79HbCqot/Q/r1yYxE+Gm7uVQeuGlVgd+AIYJd7EXZubugW7IGd5zMRk1Va5YfABt9uOIuMglLZoPq2YZE1T4zTaoDvn4JFYQZ0gX1gcfNPcHGppfSt67XA7s/gFLMR6HtjlXcRyxOZQp9sisLXuy/h+gFhNb4mtkWrJsT/va47vJ1t8fa6MzIj7NNtsVi8z1qWIIrR8XY25S1DxDS8X/fH4cMN55BbpEHPIDfcO7az8T2sivOAH+fBojATuqB+sJm+AG7W9kC7/sCZ5bDPOA37Gp7nqjx4lSvOpBbhryMJ+NefZ7Di4eF1yvgwVnZhCd5Yr3r9isyyQR2Dqr6jyPr6ZRYssuNV4GDmd3AIG4kr89wan3iGr+4ejLVHB+AW602w1RbI6+28Q2t8ndcV/58zIzc36Hw6wyLlFFxTDwDdrq/X4e4f0wHzvt+P3w4m4fEJXeFib3xfODG9T/wecLW3xuCOpveyawmvC2PX1WyDUqJ5+YoVK7B161YEB5ensvn7+6O4uBiZmZmV/kMX0/fEbVURPafEfa+77jrZEF1M9LOxscGNN96I559/vsrH2NnZyUtVT2xz/aFXxbDelrRmat74mqL64muIzI2vKWrur5/lRxKQlluMADd7TO4ZUP25Sgr0fYLEJ6rPAdveg8X5rcC654DJb155fzFFSnwPEWMq91FqKj6d5MZCTOCzsEAX/QQ+0ey8uu85I68YX21TvbaeGN8JNta19H09vRJIOyt7WFnc8afqZVWbLlNkUMrizBoV1BK9Zapw9/BwWYp3/FI2Np1OqbbPUUJWAY7EZ8mn/KoufrJMcVxnP6w4moB3152WzdpfXXUKC7dfwCPjOsiynPUnk/D22tNlE/GC3B1kH6caA3CX2/Sq6o/l7A+Lm34sL0UMUK1KLEQgx8TXgfi5vDGjp8wQEz+nB348gJ/nDYFtLQ3SjSHKA4/EVc7+WHM8EUnZRTIA+ehVHat+XZxYDvxxr5qk6NUBFrN+Abwi0Jxc3ycIXx4ehFuwqTwpz6d9g/0e4f9zZhQxDkg5BYuoDUD3G+p1KPHvP8LHSU7Q/GVvHOaODDf6sf/oS/cGh3uZ9nugBb0ujF1X/X/bmJmI+ImA1B9//CH7QoWFVZ680a9fPxlQ2rBhQ9l1IuspJiYGQ4YMueJ4KSkpMhvqo48+kl9rNBrZk0oQW/E1EREREVFD/W1raHB+x5BQ2NT05uPor6p5t3s7YPgTwA1qWA/2fA7s/6b8fvnpwL6v1QSp5tDk3MC7o9qmR8upeGIKmnAqMafa9hefbY1CTlEpOvu74NoeATUfXza81lc4DLzXuICU0G4I4OilntuLalp3VTydbGV2k/DhxnPVrnn9CZX11redhwxICaIHlWiQ/vfjI/HCpEjZG0v0yPr3H0fR56V1MtgjAlLiHM9f2xUbnxpl2sSuuH3ArgVq/7pPANcKz1WAvslyxnmgIBOmcrS1xue395MZGwdiMvHyihOoL9G4/oZP/8HDPx2sdFl5JEHe/toNPWFfIYtMEs/31reAJbergFTEWOCe9c0uICUMjfDCWcc+yNA5y681Ogu4+4Y09bLIGJHj1Pbcxnr3JRP/7kXGn7Bw+3lZom2sf/Sle8MivdHWWTbHkr0ffvhBlt+5uLjIPlHiUlBQUJaedvfdd8vSuk2bNsnG53PmzJEBKdHk/HKiJ9WTTz6JoCCVGir6U33//fdyQp+Yyie+JiIiIiJqCDuj0mRQxsHGCrMGtqv+juLN0W59EGrAPYCllZocN+Y5dd3Kp4Dt7wE/3gi83QFY8Tggyvz8ewBuVzbIbRIugYCNE6AtBTIuINLXWZakiAl1yTnlA4QqTmD79p8Lcv/pCZ1qn1wmMhtENpCNIzDoPuPXJZ7LTpPU/qkVNd71nhHhsLexxOHYTGzTT8a63Dp9UOrqrldmUomMh+t7+WHjk6PwwpSusrQvr1gjm6k/Oq4Dtjw9GncND4NdbRlhFZUWA8sfVlP2et4EdCgf+CQ5egJu+tdW4lHURai3Ez64uY9MtBK9sX7dp3pm1dXa44lIyyuGi701hoR7Vbo8d00XDIm4rGdXSSGwdB6w8ZXyoOOsX4EmmLBnDPFzvqZ3O6zVqAFayfCAv0fLaPHS5rUfCoiy15xLMmOqvqb1CZLBaRGE/uuwGmZhTNB234UMuT8ssub+dW1BswtKLViwQDb5ElPyAgICyi6//PJL2X3ee+89XHvttZg+fTpGjhwpy/aWLl16xbHE5L1z587hgQceKLtOZGGFh4dj0KBBsgzwhRdeaLTvjYiIiIjaFvHpuSBKuNwca+g3ErMTSDoKWDsAfW4vv37kU0DXaYC2BFj/InB2nQr6+PcExOS12/5As2FpCXhHqv3UMzITJszbSX55MuHKhrcfbzqHwhIt+rZzx9jOvrUff9t7attvDuBk4hu5zlPU9tTKGrMjxJvLW/TBw483nquyJ9Ku6LRqg1IGopfUnGFh2PL0GHx2W19s+dcYPH51R5N6zpQRwcjkEyrba8JrVd9HX8Ing3Z1NKazLx4bp7Ld/rPsGI7F171p92/74+R2ztBQ/DRvcKWLCPxVkpMEfHMNICbsWVgB17yrylWrKbNsTiV8v2tGQquzwFFtGALdG64XF5mRKHttr09MEVP46kkEmOcMU03Ov9gabdRQtAMXM+R0TF8XO0T4qGy7tqzZBaUqjjaseLnzzjvL7mNvb49PPvkE6enpyMvLkwGpqvpJTZgwAbt374al+A9Sz9HREUuWLJGNy9evXw9fXyP+AyQiIiIiMlF0Si42nEqW+3fq37RUa/fnatvzRpX5YiBSV6Z9CoSPAXw6A6OeAR7cC9y3DRj2KODsg2bFUMKXekZuRFmeIJqAVxSbno+f9sTI/acndK6990jMLuDidsDSBhj6kOnrEiWOts5Adnx52WM17h0ZAVsrS+y5kF4WgDLYfDoFJRqd7CNjzJtJJztrTOweAG/nK3vVGiX5lCppEya9WX0wLqC32iYeQX08PDYS4zr7yjKke7/fj/Q846YCVnQpswDbz6kssxn9ailpy7gIfDkGiN8HiIbmt/8BDLgbLUG3QFdk+PTHpOLX8H94AG4OdQg4UhOX8JW3BKqPWwe1l9mQoi/b5jMptd5/R4XSPYtm2g+qTQeliIiIiIhaA9E0WxBZQDUGMLLigZN/lZctXc7WCbhjGfDgbmDMvwEffeCnOSoLSp2tFJQSJYwVvb/+rAzujOjgfWUpV1W2vau2vWcBroGmr8vGHojUl72drLmEz9/NHjMHqJLIjzaq78Ng3fFEub26ay0T/8xBNGUXZXsiS67jRKD79Orva+grVY9MKUGUUL57U2/ZiDw+swCP/HQQGq1pfXeWHoiTyWiDwjzRzsux+juKO/31iAoUekUCczcC4aPQUohggsiWOq1rByd3BhdaXLNz4eI/QHF+vQ8nApKGDMsvtkTXev/t59LKepMRg1JERERERGaXlV9SVsJ09/DKg3uuIJqW6zRA++GAf3e0aN4dLsuUcr0iKHU2KQd/HFTPzVPj1cS+GiUcAc6uBSwsVXZYXYkpfMLhn4HSK3tcVXTfqAhYW1pgx7k07L+oer+I7KEtp1NqLd0zm71fAXF7AFsXVdJWU9DDEJQSz3uxmvBXnzfYn9/eX/ZBExlPb687bfRjRYWL4XUvSlZrdOhHNUFS9PeZtaRZNjSvjQhEiMBqrf/GqXkRk0JdgwFNkRqeUM+G54LoFSd+Z+yMTsORuOoHDmQVlOCo/nY2OVcYlCIiIiIiMrPVxxJQUKJBRz/nmj8NFw2e9y9S+4PmocWrWL6n05VN4DuXnIMSjZpM9e7fZyCSbyZ080OvEHfjeioJ3a6vX+Ci87WqGbtocHzw+xrvGuzhiOl9K2dLiVI+MSlQlOL1MWbd9ZEZA6z/r9q/+kXATQ1tqpaLH+Dsr5rfJx2v9+nFz+3NGapP1YLNUVh9VE3Nq82+ixm4kJYPR1srTK5pmmJOIrD232pfZP+1wICUIKYpfn/3IFm+RS2ICPAO1g9L2PY2sOQOoCi3XocMdHeQEziFz7dWny21OzpN/v4T/fbEY4hBKSIiIiIis1upfxN/Xe+gmst6ji8F8tPUp/adrkGL5xmhMpoKs4DcZAR7OMDZzlqW6p1PzZMZBKuPJcr3hE8akyWVFgWcWKb2hz9Rv7WJEr7hj5eXA9aSLfXAmAg5PVD0kRLrXnfCULrnW/ukwPqQZW2PASV5QLuhQL+7jHucmUr4DKb0CsTcESoD6KlfD8sMt9oYpvZd0yNA9tOq1qqn1WtE9MIa/KBZ1ktkkqEPA1M+VH3qTi4HFl4NpNdeeleTuSNVE38RxI1Jq7os8J8olu5djkEpIiIiIiIzysgrLnvjMam7f83BB0OD8wF3NftpY0YHftz1WSOpp2VAzpAtJSbwvb1OlfVN6x2Ejn7q+hqJJt8i+0f0VDJHaWPfOwCXANXH6OAPNd61vZcTrtNnPny44RzWn0hunNK9I78AURsAKztgqnjTbORbtrIJfIfMtpRnJnbG4HBP5BVrZONzMX2wOvnFpVh5JKH20r0Ty1UQwNIauO7j1vG6p5ap32xgzirA2U9NuPxiDBC1sc6H6xLgilEdfWQm1Ffbqw5w7dAPAWDpXjkGpYiIiIiIzOjvE0myObRo8h1eU4PzuL0qgCCCD33LJ023in4tQsrpSs3Of9wVg61nUmTflceu0veeqknSCdX/SRj1L/MFzYY9Vl4WWFrzdLkHxkTKrK71J5OQmF0oy9KGRjTgm8ncFGDNs+Xfs6FHVxNkSgnWVpb4eFZfBLjZIzo1D08uOQxtNY3PVx9NlMGr9l6OGBhWYYJkRQUZwKqn1L7oD+bfw2xrJaqTkIHAvM1AUD+gMBP48UbVx66O7tVnSy3ZF3vF9Mrk7EKcTc6Vv1OGhDNTyoBBKSIiIiKiBijdEyVMNTJkSfWYATi1ojcoft3UNvFopaDUngvpcnvTgBCZhVSrDS+JdDKg63XqDaM5syNE/6WsWNVsuwaRvs6Vfo4iC8LexgoNZs0zKnDj18P0pu6GoFTyyVpLE00hemgtuK0fbK0sZcB1wZaoKu/3635Vujejb3D1JavrngNykwCvDsBIMwUaiepLTPS8cxXQYQKgLQVWPgFoVQ88U4lpoj2C3FBYosV3O9UEVgNDBm3XAFd4ONmaZemtAYNSRERERERmnLpnKM+YVFujZ0OvpIGtoMF5RX76Mjt9w+3OAWoCn2BnbYmHxxqR/ROzCzizGrCwAsb+n3nXZ+MADH+sQm+pmrOlHhobWbbfoKV7p9cAx35XPbmu+wiwsjHt8W4hgIOHelMtSpHMqHeIO166TgUbxTS+LWfUFEKD2PR87IpOlxkgN1RXundxZ3nJ5NSPVNYaUXMhXo9T3gdsnVUW68Hv6nQYEZCdp8+W+m7nRTmN8nfD5YCaTMnSvcpYwEtEREREZCaiGXapVodOfi4yy6Za+xap4EHIYCCwN1plUEoERrTaSr2jZg8Nhb9bLcEI0Wtr/Ytqv89tppWwGavfnap8LysGOLxYfV2Nzv6ueGRsJA7HZWFCtxp6hNVHYbbKzhCGPAQE9jH9GCIiJLKlojer8qO6HKMGNw9sh8NxmfhpTywe+ekgxlcI0Ikm9sKwCG8EVTVRTKsBVuszo/rOBtoPMevaiMyWMTXmP8Da+cDfL6iJnU6mB5BEL8EQTwfEphfIIQGXY5PzyhiUIiIiIiIyEzFZTphcU5aUyMzZ97XaH9TKsqQEz3DA2h4oyQcyzsPNKwLjOvvKnkT3jYqo/fFn1wExO9UxRuv7K5mbyJYSvaXEm89t7wC9b60xM+kJYyYF1ocIwonm6x5hwOj5dT9OWVDKfH2lKnpxajecSMjB4dhM/LpfZX1UNHNASNUPFGWSiUcAOzdg3PMNsjYisxCZq4cWA0lHgb+fB6Z9WqdebG/c0BNfbT8vP6SoKNzbCSM6+JhxwS0fg1JERERERGaQVVCCbWdVWdM1PWvIqBFle3nJagpcl6lodcQ0Nd8uwKWDQNIxwCsCC+8cAJ1OV32vIQPRx2X9f9X+oHtV5kJD6T9HZUtlimypn9RkvqZwYQewb6HaF9P2bB3rfqwGaHZekZ21Fb6/eyD+PBiP3CJNpdu8nW0xpWdA1Vlgsj+Yvnl7HTJPiBr199e17wILr1bBVJGt2X6oyYcZGuktL1Q7BqWIiIiIiMxg/YkklGh06ODrjEjf8pK1ahuc97/L9L5BLanZuQhKJR5Tjcr1vVZqdfRXIPm4yqgxTMlrKDJb6lFg3X+ArW8DvW5p/J9HSSHw1yNqXwTFwkbW73gB+lJQEQzUlKo32Gbmam+D24eEGv+ArW8BeSmAV2Tr659GrXcinygzPfAtsPJJ4N6trfd3dTPARudERERERGaw+lhC7aV78fuB+H2AlW2NfYxaW7Nzo4iyxk2vqP3hjwKOnmhwIjDo5ANkXgQO/4xGt+UNIO2cmgZ49cv1P54o/7N1AUoLgdQzaHJpUcCuBWp/wmuANSeOUQtx1YuAo5fqjbfL9BI+Mh6DUkRERERE9ZRdWIKtZ9TUvWuqKmEy2P2F2na7HnD2ResPSh0z/jH7v1GldCJAM+h+NApRKieypYRtbwOaEjQa0Yx8xwdq/5p3AAf3+h/T0hLw76H2ozagya39D6AtASKvBjqOb+rVEBlPBMWv1pedbnkTKMho6hW1WgxKERERERHV04aTSSjWaBHh4yTL96qUmwIcX1reL6k1E+V7gshAEj2FalOUC2x9s7zvUH36KtUlW8rRG8i4ABxZYtxjDBMClz8CpJ4z/ZyitG75Q4BOo8obu1wLs+lwtdqKJs0Hf0CTObcBOLMasLQGJvyv6dZBVFe9ZqkAe3EusOfLpl5Nq8WgFBERERFRPa06qqbuXdMjoPreSSITSFMMBPUHgvqh1WcZuOiblIvyl9qI8hjRd0hM7mvshuO2TsCwR8r7H4mAUW1EvyzRJF30nPlkALDsARXUMtauT1Qzcnt3YNJbMCuR+SWeQ50W+PPB8vK5xiSCduueU/sD7wV8Ojb+GojMkXk4/HG1L/4dFec19YpaJQaliIiIiIjq6ExSDh5afADrTybJrydXV7onysIME9Zae5aUgb+RJXx5acCOD9X+2OeapqHwgHtU/5iM88BRI7KlTq1QWxFUEsEfMaXro37AX4/BIudSzY9NPQts0mcOTXgVcPGDWVlaAVM+BIY8pL5e86wqPxKBosZy8R8VjLR1VplvRC1V12mARyhQkA4c+K6pV9MqMShFRERERFTHYNSE97dixZEE+X7/9sHt0cmvmql7J5cDOQmAk696k9MWGEr4xAS+mmx7ByjOAfx7Al2vR5MQ2VJDTciWOqkPSk1+C7hnIxAxDtCWwuLAN3D9ZhSw6mkgR2XPlclPVyV/n41QjcjDRwO9b22Y70dk641/BRjzH/X1pldV5lJjBaYOfq+23W8wT68soqYiJlga+s7985EayEBmxaAUEREREZEJ3l13ulIwalJ3f6x+dARenta9+tI9Q4Pz/nPazgQyYybwZcYCe/W9Wq56QZXLNBVDtlR6NHDst5oznVJPq15JHcYDwf2A25cCc9ZAFzoCFppiWIjv6YNeqtF3+nkV6Pqgtyr5Ky0AggcA132qgkcNRRxbZClNfF19vfNj4K9HAa0GDUr0EDu+TO33ub1hz0XUWL2lnP2A7Hjg6K9NvZpWh0EpIiIiIiIj6XQ6fLfrogxGXd3VTwajFtzWD10CXKt/kOgdFLtLBTH6zUGbYQhKiTIurbbq+2x+XfXZCh2hso2akp1zecmbCCJVF7wxlO6FjaycBdR+CDD7L+ROXwxdyCCVDSUCQR/2Bja+AhRlAb5dgZt/Au7+G3ALaoRvCsDg+4GpHwMWlqoH1u/3NOyUwWO/q8CbdycVfCNq6WzsgSEPqv0d71f/+4zqhEEpIiIiIiIjpecVIzO/RCahfHRLn5qDUZdnSYkpa67V9JxqjbwiASs7Nbkqs4om4MmngMOL1f5VLzZs1pCxBs4FHDyAtHMquFJT6V7nqifmlYYMk1lTuPV3ILCPulI0cJ++ELhvB9B5cuN/r31vB2Z8DVjaqAmQP98KlBQ0zLkME//63NY8fqZE5prSae8GpJ4pD0yTWTAoRURERERkpHPJuXIb7OEAexur2h8gmngbyj0G3Yc214vFt3P1JXwbX1ZNwkVwJ7g/mgU7F2Dow2pfNAe/PFsq+xIQv0/td5pc/XFEMKbDVcDcTcCDe4EH9wA9ZjRteWK364FbfgKs7YGza4EfbwSKcsx7juST6vkRWYG9bjbvsYma+nfDwHlqf/u7jTs4oJVjUIqIiIiIyEhRKWokeISPs3EPEOVSmiIgoHfbLGWqrq9U7F6VbSBKysY9j2ZFvPGU2VJngWNLK992epXaip+lMVlvIjjl07FpJgpWpcPVwG1LAVsX4MI24LtpQHG++bOkOk4EnH3Nd1yi5kB8sGDtAFw6CERvburVtBoMShERERERmZgpFWlMUEpMcNu7UO0PurdtljKVTeA7Wn6dyDAQU+iE3rMAn05odhkRhv4xWy/LlqqldK9FCB0GzF6uAm8iq2n5Q+bJ+hBTyQ7/pPbZ4JxaIydvoO8d5dlSZBYMShERERERGSkqRQWlInyNCEqdXglkx6mJbt1uQJtUVabUuQ3Axe2q39To+WiWBt4L2Lur/jHH/1DXFWSo7CKhyxS0aEF9gZt+VGV2onfWjg/qf8wza4D8NMDZH4i8yhyrJGp+RHmv+HdzfisQt7+pV9MqMChFRERERGRippRR5XuGBuf97lTTm9oiQ6ZUxnmgKFdNrTJkSYmm4m7BaJbsXcsn8Rl6S51ZB2hLAZ/OgFcEWjyRMTXpDbUvfiZn19fveAe/V9vet6h+YkStkXsI0GOm2me2lFkwKEVEREREZISCYg3iM9XEssjaMqVEw2eRDWRhBfS/G2263EVkzgjJJ9Tkt6SjgJ0rMOJJNGuD5umnbZ0GTiwrn7jVkkv3Lidem31ni5pK4Le7gNRzdTuOaAB/Th/U6n2bWZdI1OwMf0w0jFO/E8QUUaoXBqWIiIiIiEwo3fNwtIGnk23NdxYlUULHCYBbENo0f30Jn2gOLCbuCUMfARw90ayJgNRgfW+pza+XB126tKKglOhzNvltIGQwUJQF/HwLUJht+nEOLVaTFNsNBbwjG2KlRM2H6IPX+Rq1v+P9pl5Ni8egFBERERGRCUGpWrOkRNNow9S2ttpLqqoSvq1vARkXACdfYPD9aBFEg3o7kS11BijJB1yD1STF1sTaFpj5HeASqL7PpfNUmaWxxOvdMHWvD7OkqI0Y8YTaHv0VyIxp6tW0aAxKEREREREZISolz7h+UmLSXHoUYG0PdJrYOItrCc3O81LUdtS/ADsjenI1Bw7uwJAHyr8W2RGtcYqiix9w84+q+fyZ1cDm/xn/2Is7VM8wW2eg27SGXCVR8xHUDwgbpfrM/fNRU6+mRWNQioiIiIjICFHJRmZKib5JQoerATuXRlhZCwlKCR6h+h5GLcig+1S2lNB1KlotMZFv6oflWW3Hlxn3OEOWVPcbAFunhlsfUXPNljrwHZCrD7qTyRiUIiIiIiIyoXyvxkwpUcp0/A+13+36RlpZM+fdQWXgCGOeU+ViLYnIlrp9KXD950DocLRqvW4unzq47H4g8VjN9y/MKg9e9bmj4ddH1JyITKnAvkBpIbB7QVOvpsViUIqIiIiIqBYarQ7RqXm1Z0olHFJ9k6wdgI4s3ZOsbIDrPgbGPgd0n44WKbi/Cti0BVf9Fwgfo3poicbneWnV31f0TistALw7qeeIqC0RpbyGbKk9X9VtSAAxKEVEREREVJu4jHwUl2phZ22JQHeH6u9oaHAupu6xlKlcz5nAyKcBS779aPasrIEZX6tSS9HA+bc7AU1p1fc9+L3a9r29dfbaIqpNp2tUUFZMr9y3sKlX0yLxfwUiIiIiolqc0/eTCvdxhpWlRQ2le/pSJpbuUUvm6Anc/BNg4wSc3wqse+7K+ySdAOL3A5bWQM82kkVGdDkRaB/+mNrf+SlQUtDUK2pxGJQiIiIiIjK6n1QN2U/xB4CsGPVGvsP4xlscUUPw6wrc8LnaF/1yDv5YdYNzUabq7NP46yNqLnrcCLiFAHnJwKHFTb2aFodBKSIiIiIiIzOlauwnZZi612kiYOvYSCsjakBdpgCjnlH7Kx4D4vap/dJi4MjPar/P7U23PqLm0jdv6MNqf8cH1Ze7UpUYlCIiIiIiqkVUSl7Nk/e02gqlezc04sqIGtioZ1XfHE0x8POtQHYCcGY1kJ8GOPsDkVc19QqJmp4Izjp6A5kXyyewklEYlCIiIiIiqoFOpyvLlKo2KBW3F8iOA2yd+SadWl/PHFHG59MZyE0EfrkN2Pe1uq33LNUYnaitE9mxg+9T+9vfUz0G6yI/HfhxpupPJT7saAMYlCIiIiIiqkFaXjGyCkrkcLHw6npKGT4Z7zQZsLFv1PURNTg7F+DmxYC9GxC/D4jerK7vc1tTr4yo+RgwF7B1AZKPA2fW1u0Y57cCZ9cC+79pM9NK28Z3SURERERUR4YsqWAPB9jbWF15B60GOKEv3evO0j1qpbwigBlfAxb6t5Dth6nriEhxcAcG3KX2t79bt2ypaH3AN2IM2goGpYiIiIiIjJi8F1ld6d7pVUBOAuDgAUSMbdzFETUmUZo66U31Wh/xRFOvhqj5GfwAYGUHxO4GLv5j+uOjN6ltOINSRERERERUIVOq2n5SOz9R2/53AdZ2jbgyoiYwcC7wzAX2TiOqiou/6rVmyJYyRfp5IOMCYGkNhA5DW8GgFBERERFRDQyT9yJ9qwhKxe8HYnYCljaqnwgREbVtwx5RZa7n1gOJR03PkgoeqPq4tREMShERERER1SDKkClVVVBKTEgSuk8HXAMaeWVERNTseIYDHSeq/Sh9oMkYUZvaXD8pgUEpIiIiIqJq5BeXIj6zoOqeUllx5Q3OhzzQBKsjIqJmKaCX2qaeMe7+Wo2avNfG+kkJDEoREREREVUjWl+65+lkCw8n28o37vkC0JYCoSPK34AQERF5dzAtKHXpEFCYCdi5AYF90JYwKEVEREREZOrkvaJcYP835dOWiIiIDLw7qW3KaUCnq/3+0RvVNmwEYGWNtqRtfbdERERERDWU6v26Lw75xZqy63ZGp8lthK9T5TsfWgwUZlXuHUJERCR4RQCwUNlP+WmAk3fN94/a3Cb7SQkMShERERERAfi/Zcfx+4G4Km/r4FthEpJWC+xeUJ4lZcniAyIiqsDGAXBvB2ReVNlSNQWlinKB2N1tsp+UwKAUEREREbV5W8+kyICUhQUwrXcQrCwtym5zd7DB9H7B5Xc+swZIjwbs3YHes5pmwURE1Lz5dFJBKdFXKnRY9fe7+A+gLVFBLJF928YwKEVEREREbVpeUSnmLz0q92cPCcWLU7vV/IA9n6tt/zmA7WVlfURERIJ3R+DsutqbnUdvKs+SEp+MtDHMNSYiIiKiNu3tdWcQn1mAIHcHPD1B35y2OqJ0L3aP2u95c6Osj4iIWvEEvqhNbbaflMCgFBERERG1WYfjs/Htzgty/7UbesDJrpZCgqxYoCQfsLQBvCIbZ5FERNRyJ/DVFJTKTgBSTqqm6GGj0BYxKEVERETUwhyNy8K+C+lNvYwWr6hUg/+uOiendU/vG4yRHX1qf5DhzYUISLWxsd1ERGRi+Z6QGQsU51d9n/Nb1DawN+DoibaIQSkiIiKiFkKr1eHDDWcx9ZPtmPXlbmTllzT1klq0TzZFITqtAF7Otvi/a7sY96CUU+UNbImIiKrj5AU4iECTDkg7V3PpXnjbLN0TGJQiIiIiagGyCkow97t9ePfvMzKzp1ijxcX0vKZeVot1MiEbCzZHyf2XpnaDu6OtcQ8Uo70Fn84NuDoiImoVfGoo4RP/mUdvbtP9pAQGpYiIiIjqYdnBeDzxyyHsOJcKnfgDs4ECKFM/3o4Np5Jha20JLycVQInLKGiQ87V2pRotnvn9CEq1Oozt6IlJ3f2Nf3BZUEpflkFERFSXZufJJ4DcRMDaAQgZhLaKhfBEREREdZScXSiDG0WlWiw9GI+uAa6YOzIM1/YMhI2VeT77W3MsAY/9cgiFJVo5He7z2/vh863R+OvwJcRlVNOjgmq0aMcFHInLgou9NeaPj4CFsSO4RdAxlZlSRERkYl+pqoJS5zaobehwwNoObRUzpYiIiIjq6LMt0TIg5e9qDwcbK5xIyMbjvxzGyDc34YutUcgurF/Pp3/OpeLhnw7KgNSIDt5Y8fBwdA9yQ7CHg7w9nplSJruYlod3/laBpf9M7gIfZyPL9oTcJKAwC7Cw5OQ9IiIyfgJfShVBqSh9UCpyHNoyBqWIiIiI6pgl9ePui3L/zRk9sXP+WDw9oRO8ne2QkFWI/606haGvbcSrK0/gUqbpwaMzSTm494f9KNHocE3PAHwzZyA89GV7I/PW4S6r1SzfM5Eor3z296MyyDc0wgsz+webdgBDk3OPsDb9qTYREZlYvicanWs15deLaXwXd6r9CAaliIiIiMhEooROZEn1becus5hEo+wHx0Ri+zNj8Ob0noj0dUZuUSm+3HZeZk499vNBHIvPMjrgNWfRXuQUlmJAqAfeubEXrCz1JWZFuRh87EU8b/M9CtLjGvabbGV+2RuLndFpsLexxOs39DS+bM/A8Ek3J+8REZEx3NsB1vaApgjIjCm//uIOdZ1bSHngqo1iUIqIiIjIRMk5hfhhl8qSevSqjpWCG/Y2Vpg5IATrHhuJRXcOwJBwL9lQe9mhS7j2o+249atd2Hw6udqm6HlFpbjr272IzyxAuLcTvri9vzxmmaRjsNCpT1utsmIarLl6a5OYVYhXV56U+0+N74R2Xo6mH8SQKcWgFBERGcPSqrzcu2JfKUM/qYixgKkfkLQybHROREREZKIv9L2k+rRzx8gO3lXex9LSAmM6+8qLyJD6cls0VhxJwI5zafLSyc8Fdw8PQ+cAF1hbWsLW2kJuX15xAsfis+WEvUVzBpSV7JVJOFy261WSiKyCEpmlRdUTgbv/+/MYcopK0SvEHXOGhdXtQIY3FGxyTkRExhKZUEnH1P8hHSeo69hPqgyDUkREREQmSMkpwg/6XlKPjutgVAmYaE7+wc198K+JnbFo+3n8tCcGp5Ny8K/fj1R5fztrS3w5uz/aezldeWNC+WOCLFJlXykGpWq26mgi/j6RBBsrC1laWVYKWddMKcM0JSIiImObnRs+2BBlfGLfwgoIG4W2jkEpIiIiIhOIqXqiUXbvEHeM6uhj0mOD3B3w3LVd8fC4Dvh5TwyWHohHTmEJSrQ6lGq0KNXo4GJvjf9e1x1923lUfZDE8kypYIsUGZQSQS+qWkZeMV5YfkzuPzA6Ep38Xep2oPx0IC9F7TMoRURExjL0jDL0JTSU7gX3Bxzc0dYxKEVERERkQpbU92W9pIzLkqqKm4MN7h0VIS8mKS0CklVfJENQ6kwdJvu1JS+vPIHU3GJ09HPGA2NMfL4rSjmttqIprZ2z2dZHREStnOGDDEOmlKF0r41P3TNgo3MiIiIiI32384LMkhJ9iUabmCVlFiIgpS29LFMqv/HX0UJsOZMis9FE7PCN6T1hZ12hYbyp2OSciIjqQjY6twAK0oGcRCB6q7qe/aQkBqWIiIiIjHQ4Lktubx4QUucsqXpJ1PeT8lCNugMt0hCfntf462gBcotK8e+lR+X+nKFh6FNdOaSx2OSciIjqwtYRcA9R+4cWA0VZgIMHENinqVfWLDAoRURERGSkeH1WUjtPx6ZZgGHyXqdJ0FpYwc6iFPnpl5pmLc3c22tPIz6zAMEeDnhqghl6QLHJORER1ZXh/469X6lt+GjAsh7Zu60Ie0oRERERGUGn08kghxDo7tA0izBM3gvsC41zACxz4mCRFYO25EJqnsyCqklMej6+3XlB7r9+Q0842prhT15DTylmShERUV0m8J1bD2THq6/ZT6oMg1JERERERsjIL5H9pIQAN/vGX4BWAySpKXII6AlLj/ZAThw8ihORXVgCV3sbtHa/7Y/DU7+WTx+szcz+wRjewbv+Jy7MLn8j4cNMKSIiquMEPoOIsU21ktYVlCoqKoKdnZ35VkNERETUTMVnqCwpHxc72Ns0Qcp92jmgJB+wcZRNU61EUCpmh2x2LtbmGtD6g1Lbz6bIrYu9NZxqyX4SJZb/mdzVPCdOPau2zn6qDwgREZEpKpZ++3QB3IKacjUtNyi1evVq/Pzzz9i2bRtiY2Oh1Wrh5OSEPn36YPz48ZgzZw4CAwMbbrVERERETSQ+U/WTCmrq0j2/7qoPhb5parBFKuIyCtAlwBWt3anEHLl9b2ZvXNXVr/FOnGoo3ePkPSIiqoOK/38wS8r0Rud//PEHOnbsiLvuugvW1tZ45plnsHTpUqxduxZfffUVRo0ahfXr1yM8PBz33XcfUlLUp1hERERErYUI/AhBHk0UlErUl60F9FRb93ZyozKlVMCsNSvRaBGVkiv3O/m7NO7Jy5qcMyhFRER14OgFOOrLySMZlDI5U+rNN9/Ee++9h0mTJsHS8so41syZM+U2Pj4eH330EX744Qc8/vjjxhyaiIiIqEUwNDkPbrJMKUNQqleloFSQRSq26gNmrdn51DyUaHRwtrOWE/UaVVmTcwaliIioDiwsgKkfAcnHgXAGpUwOSu3cudOYuyEoKAivv/66UfclIiIiaok9pZpk8p5OV16+5395plQqLmXkoa2U7nX0c4aF+OO+MTEoRURE9dV5srqQ6eV7NcnLy0N2dnZ9D0NERETUrF3K0pfvNUVQKjMGKMwELK0B3y7qOtcg6CwsYWdRgpz0BLR2pxPV35ud/Bu5d1ZJAZBxQe37dG7ccxMREbVydQ5KnThxAv3794eLiws8PDzQo0cP7Nu3z7yrIyIiImpmmVJN0lMqUZ8lJQJS1vrJx1Y2KHX0l7sWImjVyp1KUJlSnRu7n5SYeggdYO8OOPk07rmJiIhauToHpe6991489NBDyM3NRVpaGm644QbMnj3bvKsjIiIiagbyi0uRkV/SdEGpstI9fT8pPQsPVcLnVpSAvKJStIXyvcZvcm4o3euseoIQERFR4welrrvuOtnI3EBM2Js6dSocHR3h7u6OyZMnIykpyXwrIyIiImpmWVIu9tZwtbdpwibn+n5SetaeoWV9pQyN2FujnMKSsu+vUTOlRC+vOH0lAPtJERERNU2jc+G2227D2LFj8eCDD+Lhhx+WWVLdunXDqFGjUFJSgo0bN+LJJ580/wqJiIiImlhcZhP2k6pYvmeYvGfgHiI3QRYpMnDW0a+Rs4gayZkklSXl72oPd0fbhj9hdgJw+Cfg0I/68j1ROtm14c9LRETUxhgdlLrxxhsxfvx4PPPMMxg8eDA+++wzrFu3Dps3b4ZGo8Gzzz6LAQMGNOxqiYiIiJrApaYMSuUmAzmikbkF4Ne98m0VJvDFZuSjtWq00r2seGDlE8DZdYBOq66zcQK63wD0urlhz01ERNQGGR2UEtzc3GQwavv27bJ/1NVXX42XX35ZlvARERERtckm51lxQNIJIHxUeRPyhugn5RUB2DlXE5RKwU79Gluj0/qgVIOW7mm1wO/3ADH/qK/bDQH63AZ0nXbl805ERESN3+g8PT0d+/fvl5P2xNbV1RV9+vTBqlWrzLMaIiIiomYovrpMKRHI+P56YPGNwPs9gC1vAXlp5j154uGqS/cqBKWCLFIR15ozpRIaIVNqzxcqICUyo+7bDty1RgWlGJAiIiJq+qDU4sWLERwcjGuuuQbt27fH6tWr8cILL+DPP//Em2++iZkzZ7LROREREbWtTKnzW4DUM2o/NwnY9ArwXlfgr0fLp7bV16VDautfucm55BoMHSzgYFGMnPREtEY6nQ6nErMbNiiVHg2sf1Htj38J8O/RMOchIiKiugWl5s+fj6+//hqJiYnYsGED/u///k9e37lzZ9lXSpTyDRkyxNjDEREREbX8TKn9i9S272zghi+BgN5AaSGw/xvgk4HADzOAqI1qiltdHP8DOPmX2g8ZdOXt1rYodfKTuxaZMWiNErMLkV1YCitLC0T6NkDWkugd9eeDQGkBEDoC6HeX+c9BRERE9QtK5ebmolMnNQo3IiIC+fmVU8Tnzp2LXbt2GXs4IiIiohahRKNFUnbhlZlSOUnAqZVqf+A8oOdMYN5mYM5qoPO1qjH5ub9Ved+CocCB74ESdRyjXNgOLJ0noibAgHuAdoOrvJuFvoTPueASCks0aK1NzsO9nWBnbWX249se+hYWMTtV2d51HwOWJnW3ICIionow+n9d0dhclO7NmjULAwcOxO23337FfXx9fVFfW7duxZQpUxAYGAgLCwssW7bsihTu559/HgEBAXBwcMBVV12Fs2fPlt1eVFQk1yb6XXXs2BHr16+v9Pi33noLDz/8cL3XSURERG1DYlYhtDrA1soS3k4VGpkf+gHQlgLBAwB//VQ8Cwug/VDg5h+BRw4AA+9VwY7kE8Dyh4D3uwObXwdyU2o+qWic/tMsQFOsAlyT3lTHroKVZ2hZs/O4Vtjs3NDkvEFK99Kj4bDj9fKyPQ/1XBIREVEzC0q9++67+Pzzz2Vj848//lgGhhpCXl4eevXqhU8++aTK20X/qg8//FBOAdy9ezecnJwwYcIEFBaqTx6/+OIL2YR9586dmDdvngyiiUCWcP78eXz55Zd49dVXG2TtRERE1HpL9wLd7WFpaVHe4Hz/t2q/35yqH+gZDkx+E3jiBHD1y7L/E/JSgM2vAe91A/58SAWfLpcVD/w4AyjKAkIGA9O/AiyrzxCycA8pC0oZ1tqanErIbpjJe+Jn+OeDsCgthI5le0RERE3C2pQ7iwwmcWlIkyZNkpeqiODS+++/j+eeew7XXXedvO67776Dn5+fzKi6+eabcfLkSUydOhXdunVDeHg4nn76aaSmpsLHxwf3338/3njjDZlFRURERFTnJufRG4HMi4CdG9Dt+poP4OAODHsEGHw/cHI5sPNTIH4fcPB7dXH2AzwjVBDLMww49juQHQ94dwRu+QmwuayPVRubwGco3+vkb+a/3/Z8Icv2dDaOwNSPWLZHRETUBIz63/fnn382+oCxsbHYsWMHGoLIdBKN1kXJnoGbmxsGDRokM6MEkWW1fft2FBQUYO3atbLMz9vbGz/++CPs7e1x/fW1/OFIREREVFuT8336Bue9bgZsHY07kJUN0H06MHcDcPffQNfrAAtLNbUv5h9VDrjxZVXq5xIA3PY74OhZ+3H1QanWWL4n+nlFpeSaP1MqLaps2l7B8H+zbI+IiKg5Z0otWLAA//3vfzFnzhyZKdWlS5dKt2dlZclA1A8//IC///4bCxcubJDFioCUIDKjKhJfG2676667cOTIEXTt2lUGo5YsWYKMjAxZbiimBIosKxFkE83axTTBoKCgKs8lelOJi0F2dnZZtpahHLC5M6y1payXmj++pqi++BqilviaMmQfiaCUPE9OAnB6tWhjDl2/O+s2WU/0obrxW6AwS/Y1kkESsc2IBgoygHEvAG4hxh3brZ1cS7BFKuLT81rVv6/olFyUaHRwsrVCoJu9eb43/bQ9i9IC6EJHoqjHLNi3oueMmhb/nyNz42uKWurrwti1GRWU2rJlC5YvX46PPvoI8+fPl32cRCBIZB6JgI8ICIkA0J133oljx45dETRqTDY2Nlf0oxLBtEceeQQHDx6UZX6HDx+WvanEdb///nuVx3nttddkIO5yIgDXnH/wFYl1iqmJgmgaT1RffE1RffE1RC3xNXUxVZWPudvq5N8Bdru/hINOg9LAAci1CxR/HNTvBE7h6qISnsoZfVxnuANwtChC1IULeG9NhWbsRvJyssGUHr6wbGb/Lg9Gq4bwEd6OyMlRHxDWl+3BRXDUl+1lj34VuXn5MmONv5PIHPj/HJkbX1PUUl8XhsQes/WUEn2axEX0ZxLlcRcvXpQlciIYJZqfi4tlA9fi+/v7y21SUpIsyzMQX/fu3bvKx2zatAnHjx/HV199JftLTZ48WQbVZs6cKRu2V0cE35544olKT2hISIgsF2wpPakMwTOx5ub6QqWWha8pqi++hqglvqaSc0vltkOgF9xcnIHjS+TXVoPukedtem4ocfSFTX4yLHMu4cMt9nU6SrCPO8Z2rv8kZXOKyVaZ8N2C3c3zXItstB1vqP2rX4ZLu+7QZmXxdxKZDf+fI3Pja4pa6uvC2HWZ1OhcEEGoadOmoSmEhYXJwNSGDRvKglAiWCSm8Ikm5pcTE/kefPBB2U/KysoKGo2m7IdXUlIiv66OnZ2dvFT1xDbXH3pVDOttSWum5o2vKaovvoaoJb2mxN8Nl/Q9pYI9HGERtQHIjgMcPGDRdZo4OZoDa89QID8ZMyO16OIWbNJjD8Vm4kxSLg7HZmJcl6bLdq/KaX2T887+rvX/+cppew8BpQVA2EhY9L9L/vz4O4nMja8pMje+pqglvi4aLCjV0EQK2rlz5yo1Nz906BA8PT3Rrl07PPbYY3jllVfQoUMHGaT6v//7PwQGBlYZKHv55ZdlZpTI4hKGDRsms6VEOZ/IkhJfExEREVUnNbcYRaVaGXvyd7MHti5TN/S6BbCpW0ZSQ7AQzc7j9uD2zhbAsF4mPfabHefx4l8ncCLBPOVxDTN5zwxNzvd8oRrK2ziVT9trIS0ZiIiIWqtmF5Tat28fxowZU/a1oYRu9uzZ+Oabb/Cvf/0LeXl5mDdvHjIzMzF8+HCsWbNG9reqSPS2Ek3ORUDLYMaMGbLZ+YgRI9CpUycsXry4Eb8zIiIiMqecwhL8tj8Og4IdGqyMzjB5z8/FHrbWlqr8y9CovDlxD1HbzBiTH9o1UD13Jy5lN7ufr+H5rzR5T2Q8mdoyosK0PYx/idP2iIiImolmF5QaPXp0jY3ERQrYSy+9JC816d69O86ePVvpOtHz6tNPP5UXIiIiatl+2hOD/606BVd7a3w8qw9GdjR/P6T4DBUUCfJwUFdkxaqte3s0KyJTquL6TNA5QAV8LmUVIiOvGB5OtmhMiVmF+P1AnLwkZRWWXa/V/zno52oHd0f9mk6vAX6dDXS9Dhj/KuDsY3LZHvrd1VDfChEREbX0oBQRERGRMS6k5cttdmEp7ly0F89M7Ix5I8PN2lshPlOdI9DdASgtBrIvVc5Mam5BqZRTQGkRYG38BD5Xexu083RETHo+TiZkY2ikNxpaiUaLjaeSsWRvLDadTi4LQFVlbOcKfa5O/gWUFgJHfgHOrAXGvwz0vq3mzKlKZXsfm55lRURERM03KCWahR89ehTt27eHh4eHeVZFREREVIvkbJVVE+Jhj9iMQry2+hSOXcrGG9N7wNHWPJ+7XcpU5wgSQSnR4Bw6wNoecDIiQ6cx+fdS68q4APw8C5j5PWDraPTDuwa4yqDUiQYOSkWl5GLJvlj8vj8eqblFZdcPDPXEzAEhGBDqAQuUBxVF/Eg+9wZJx9TW0RvITwWWPwwc+gmY8j7g08mIsr1mluFGRETUxpn8F5toNN6jRw/cfffdMiA1atQo/PPPP3B0dMSKFStk+R0RERFRQ0vUB6WeHheGzGJLvLTiBP46fAnnknPxxe39EOJpfFCmOnEVy/cyL5RnJTW3STeijO3mxcDPtwLn1gM/zgBu+RmwdzXq4V0DXbHmeGKD9JXKLy7FqqOJ+GVvDPZeyCi73tvZDtP7BWFm/xBE+DjXfiBNqcoEE+asBs6uAza9qrKgFgwDhj8OjHiyvAE9y/aIiIiaPZPzl3/77Tf06qWmuvz1119yOt6pU6fw+OOP4z//+U9DrJGIiIjoColZKtPG19kWtw9pj8VzB8Pb2VaWoE35eDu2n02t9zkMjbaDRbaOoYm4WzMr3TOIHAfc/gdg5wpc3AF8dx2Qn250ppRgrgl8oj/oodhMzF96FANf3YCnfj0sA1KWFsC4zr4yaLhz/ljMn9TFuICUkB6lSvdEGZ5XJDD0IeDB3UCHCYC2BNj6JrBgKBC9Rd2fZXtEREStL1MqNTUV/v7+cn/VqlW48cYb0bFjR9x111344IMPGmKNRERERFf0JErLU0EpHxfVBHtgmCeWPzQc9/+wH4fjsnDH17vx7KTOmDui7n2m4jPyyzOlLsVU7t/UHLUfAsxeDnx/A3DpAPDNNcDtywCXCn2ZqsmUEkSWWWGJBvY2VrWeqlSjxbazqcgqKKl0fUpOkWxafioxp3xZXo4yI2pGv2D4uVaemGw0Q+meX9fyAJP4Wcz6BTi5HFj1LxW4+m4q0O0G4PRqdR+W7REREbWeoJSfnx9OnDiBgIAArFmzBgsWLJDX5+fnw8qq9j9giIiIiOpLBD7EsF4bKwt4ONqUXS8akv9y7xA8t+wYftsfJ6fzHYsXfaZ6wsHWtL9TcgpLZBN1w3HLJ+8146CUENgHmLNKZUolnwAWTQTu+LPGdQe42cPd0QaZ+SUyMNU9yK3GU2w5k4JXV57AmaTcau9jZ22JyT0CZDBqUJgnLEWaVH0kHVdbv26VrxcBRzGNL3w0sOElYO9C4PhSdRvL9oiIiFpXUGrOnDmYOXOmDEqJTx2vuuoqef3u3bvRuXPnhlgjERERUZX9pHxc7GB5WRaUyPJ5a0ZP9Ahyw8srTmC5vs/U5yb2mTKU7rk52MDZzrq8fK+5B6UE3y6q79J304D0aODrSSqDyiuiyruLv+lECd8/UWmyr1R1QanTiTl4ddVJbD2TIr8WgSzxPFdkY2WJMZ18MLV3kHzuzKYsKNW96tvt3YBr3gF63gysegrIT2PZHhERUWsLSr344ovo3r07YmNjZemenZ0aOSyypJ599tmGWCMRERFRlZP3/Fzsqw2yzB4ais7+LnjgxwOyV9LUj7fj41l9MczI6XKX9EGpsulvmS0kU8pABKDuWqMyptLOAl+LjKllV2Ya6ZUFparoKyV6RL268iS+3nEeWn2G2uwhoXh4bAe4VchUa1CJhvK9qtdfJmQAcO8Wsejm15CeiIiIKqnTvOQZM2Zccd3s2bPrcigiIiIikyVm6YNSbjX3JxoU7oW/Hh6O+37YjyNxWbh94W78e3IX3D08rMY+UyIIs/ZYUnk/KTH5LTu+ZQWlBLcglTH1/fVA0lFg0WTgtqVAcL9q+0pVNYFv+7lUfLX9vNyf2M1f9uoK9XZCoynIALLjjAtKGTAgRURE1DqDUhs2bJCX5ORkaMW43Qq+/vprc62NiIiIqEpJOarJuZ+LytiuiegHteTeIfjPH8dkA+5XVp7EsfgsvHZD1X2mRAPvZ5celT2phGm9g1RASqcBrGwBJ1+0KM4+wJ1/AT/MAOL3qUbgojl46PAqg1JieqEIylUM2v2ufy5mDWqH/13fowl+4CfU1q2dKtMjIiKiVsHkIvv//ve/GD9+vAxKiUl8GRkZlS5EREREDS1JnynlX0umVMU+U2/f2BMvTOkKK0sLLDt0Cdd8tE0GnopLyz9gE5PnRLmfuF7cT/SmuqZnQHmTc7eQltmjyMFDle6FjgCKc4EfpgNn11e6S4SPM2ytLJFTVIq4DFW6KGQXlmDN8US5f1P/EDSJ6pqcExERUdvKlPrss8/wzTff4Pbbb2+YFREREREZ2ejcz9W4oJQgMn/mDAtDlwBXPPjjAUSn5OGpXw/jnXWnZTnf1F6BePTnQ9gZnQZba0t8fEsfjO/mrx5c1uS8iYIy5mDnAtz6K7BkNnB2LfDTzcCMhWpynb5BeUd/Zzmt8Pil7LKm8KuOJKCwRItIX2f0DG6iLCVReigwKEVERNSqmPxRX3FxMYYOHdowqyEiIiIyQlJZUKr28r3LDQ73wqanR+OZiZ3l9L6ErEJZ0jfotQ0yICUm7X07Z2B5QEpoSZP3amLjANz0A9DtekBbAvx6J3BocaVm50LFZueGMsYZ/YJr7MPVKJlS/tVM3iMiIqK2EZS65557sHhx+R8vRERERI0tKbvI5EypilztbXD/6Ahs+9cYvHZDD4R5O8lhbZ5Otvhp7mAMifCq/ICWNnmvJta2wPSFQJ/bAJ0WWHY/sOdLeZPIIqvY7Px8ah72XcyApQVwfZ+gplmvVgMkn1T7fgxKERERtenyvcLCQnzxxRdYv349evbsCRubymOA3333XXOuj4iIiKiS3KJSeTEEpTSFeXU+lug1dcvAdpjZPwS7o9MQ4etcdaAr82J5o+3WwNIKmPIRYOsC7F4ArHoKCOyLrgGhZc3OhaUHVJbUyI4+dQ4A1lv6eaAkH7B2ADzDm2YNRERE1DyCUkeOHEHv3r3l/rFjxyrd1mQp3URERNTmSvdEmZ246Hue14toaj400rv6O7SW8r2KRMP2ia8B6dGqx9SFrejSv6e8KT6zAOl5xWVT90TpXpNJ0v+96dtFBdOIiIiobQalNBqNnL7Xo0cPeHh4NNyqiIiIiGqZvFeXflJ1Lh/Ljm99QSlBfKDYfogKSiUckWWNIZ4OiE0vwNfbz+NSViFc7a1xVRe/plsjJ+8RERG1Wib1lLKyssL48eORmZnZcCsiIiIiMvPkvXrJSQC0pYClNeBSofl5a+GvsqOQeKRSs/Mvt0XL7ZRegbLM8QrRm4GfbgFOrWykoBT7SREREaGtNzrv3r07oqPVHylERERETdXk3L+xglKGJuduwa2zfMwQlEqLAopy0TXATX5ZVKqtunRPNB3/8Ubgu+uA06uArW817PqSjqotM6WIiIhaHZODUq+88gqeeuoprFixAgkJCcjOzq50ISIiImqMnlJ+bo0VlGqF/aQqcvYBXAIA6GRWUtdAlSklRPg4oXeIu/oiJwn461FgwVDg7DrAQv9nZPIpVeLYEAqzyp9/BqWIiIhaHZMbnU+ePFlup06dWqmxuU6nk1+LvlNEREREDSXR0FPKpZF6ShmCIq1l8l512VKiTDHxCLp21GdOySypEPX3XkEm8MUodR+hyxRg3AvAZ8OB0gIg4wLgFWH+dYmsLME1CHD0NP/xiYiIqGUFpTZt2tQwKyEiIiIyQlKOCkr5N1amVFYrz5QSAnrqm50fRuCAe2SGVHJ2EW7oG1TeP0oEpERG1YxFqjm64NNJPkb2fWqIoJRh8h6zpIiIiFolk4NSo0aNapiVEBEREZk0fY/le2bj30NtE4/IzKjf7hsqe0qVPccXtqltl6nlASnBt5sKSiWfALpONf+6EhmUIiIias1MDkpt3bq1xttHjhxZn/UQERERVUur1SE5p6iJglIhaLUMzc5FuZymBB5OtpVvv7BdbcNGVL7er2vlCXnmxsl7RERErZrJQanRo0dfcV3F3lLsKUVEREQNJS2vGKVa0ccS8GmMnlJaLZAV1/ozpTxCATtXoCgbSDkN+FcIAuWmACmn1H77YZUf56sPSolMqYZ47g3HZVCKiIioVTJ5+l5GRkalS3JyMtasWYMBAwZg3bp1DbNKIiIiogqT97yd7WBjZfKfMabLTQI0xYCFFeASiFZLRPkqlPBVYijdE4Ghy5uNG8rq0qOBkgLzrinzIlCcC1jZAV6R5j02ERERtcxMKTc3tyuuu/rqq2Fra4snnngC+/fvN9faiIiIiKoMSvm5NtLkvazY8ulvVib/2dTySvgu7gASjgC9Z11Zuhd6Weme4OwHOHgCBekqwyqwt/nWE7dXbX07t/7nnoiIqI0y20eMfn5+OH36tLkOR0RERHSFRH1Qyp9NzhtmAp+QeLTqTKnQ4VVnWBmypcxdwndsqdpGXm3e4xIREVGzYfLHTkeOVE7p1ul0SEhIwOuvv47evc346RgRERFRNZP3fBstKHWx9Tc5v7zZuQhK6XQq4JSTBKSeEdEnoP3Qqh/n20UFrszZ7Dw/HTi3Xu33uNF8xyUiIqKWHZQSgSfR2FwEoyoaPHgwvv76a3OujYiIiKiSpOyiRs6Uim07mVI+nQArW6AoC8i4AHiGARf1pXv+VfSTashm5yeXA9oS1cdKlO8RERFRq2RyUOr8+fOVvra0tISPjw/s7Rvpj0MiIiJqs1i+14CsbFTWU8Jh1excBKXOb6u+n5SBoXwvyYxBqaO/qW2PGeY7JhEREbX8nlJbtmyBv78/2rdvLy8hISEyIFVcXIzvvvuuYVZJREREVKHRuW9jNTo3BKXc2kD5XsUSPtHsvLYm5wYikCXkJqqyu/rKvlR+3u7T6388IiIiaj1BqTlz5iArK+uK63NycuRtRERERA0dlPJ3a4RMKdGqwDB9ry1kSgkBvcr7SmUnAGln9f2khlT/GDuX8ufHHCV8ssG5DggZ3HaedyIiojbK5KCU6CUlekpdLi4uDm5ubuZaFxEREVElhSUaZOSXNF75Xl4KUFoIWFgCrkFoE/x7qK0o37u4o/w6B4+aH+drxhK+o7+qLUv3iIiIWj2je0r16dNHBqPEZdy4cbC2Ln+oRqORvaYmTpzYUOskIiKiNi5Z3+Tc1toSbg42jdfk3CUAsLZFmyAai4vMqJwE4Pgf6rqwkbU/TpTwnVkNJNdzAl/qOSDhEGBhBXS7vn7HIiIiotYTlJo2bZrcHjp0CBMmTICzs3PZbba2tggNDcX06az7JyIiooaRlFPe5LyqrG2zy7yotm2phMzOGfCKANLOAadWqutCh9f+OHM1Oz+mb3AeMRZw8q7fsYiIiKj1BKVeeOEFuRXBp5tuuonT9oiIiKhRJWY18uS9tKi2F5QyNDsXQSnR10mULraroZ+UgW9XtU0+qXpx1SVoKB7H0j0iIqI2xeSeUrNnz0ZhYSG++uorzJ8/H+npasrKgQMHEB8f3xBrJCIiImr8yXuxu9U2sC/aFENfKbnfE3Bwr/0x3h0ASxugOKe8ObypRNmeCIZZ2wOdr6nbMYiIiKh1ZkoZHDlyBFdddZVsan7hwgXMnTsXnp6eWLp0KWJiYvDdd981zEqJiIioTSubvNcYmVJaLRC7R+23G4Q2JaBn+b4xpXuClQ3g3VH1lBIlfHXJLjuqL93rNElN9CMiIqJWz+RMqccffxx33nknzp49W6mEb/Lkydi6dau510dEREQkJeobnfs1RlAq5SRQlAXYOAF+FTKH2gL/XuX7xjQ5N/AzlPCZ2OxcqwGiNlYo3bvRtMcTERFR28mU2rdvH7744osrrg8KCkJiYqK51kVERERUZaaUn5t9eQ8i0cPIxs/8J4vZpbbB/QErk/9catmcfYDwMarRe/thxj/O0FfK2GbnqWeBQ4uBwz8DOZf05/YHIq+qw6KJiIioJTL5ryw7OztkZ2dfcf2ZM2fg4+NjrnURERER1Vy+d/gnWCy7H07BQ4DblgD2rubvJ9VuMNqkO5aZ/piyZuc1BKUKMoHjS4FDPwFx+vJIwd5dNTcf/ABg3Ug9w4iIiKjlBaWmTp2Kl156CUuWLJFfi5HMopfUM888g+nTpzfEGomIiKiN0+l0ZdP3/AyNzi8dkhubuJ3QfTcVuPV3wMnLPCeM2am2IW2sn1R9GMr3Us8ApcWAtW2F8rxNwOHFwMkVgEaVYcLCSmVF9Z6l+kgxGEVERNTmmByUeueddzBjxgz4+vqioKAAo0aNkmV7gwcPxquvvtowqyQiIqI2LbugFEWl2so9pQwlXyK+cekgsGgicPsfgFtwPU+WAGTGABaWQPCA+h2rLXELAexcgaJsIO0sYGmtyvOO/ALkJJTfz6eLCkT1nAm4+DfliomIiKilBaXE1L2///4b27dvl5P4cnNz0bdvXzmRj4iIiMgcolNycSYp94rSPXdHG9jbWKkrs1VQqmDYs7A/+gMsRIbOwgmq9My7Q91PHqvvJ+XXzbwlga2dhQXg20WVPv54I5AdX36bg4dqYC6CUQG91X2JiIiozatz587hw4fLi8GBAwfw/PPPY8WKFeZaGxEREbVB2YUluPaj7cgv1lxxW1k/qQpBqdJ2w4ABtwLf36AydL6eCNz2OxDYu24LiNH3kwppo/2k6kME8kRQSgSkRHleh/EqENVxAsvziIiIqH5BqbVr18osKVtbW9xzzz0IDw/HqVOn8Oyzz+Kvv/7ChAkTTDkcERER0RXOJuXIgJS9jSW6BbqVXW9lYYE7h4WqLzSlQG6S3NWKiW2idOyuNcAP04GEQ8A31wKzfgZCyz9AMzlTqq02Oa+PIQ8BhdlAUF+VGeXs29QrIiIiotYQlFq4cCHmzp0LT09PZGRk4KuvvsK7776Lhx9+GDfddBOOHTuGLl26NOxqiYiIqNU7n5ovt/3ae+DHe6oJDImAlE4LnaU1dI7e6jonb2D2X8DPs4AL21Tm1I3fAJ0nG3/yolwg4YjaZ5Nz03lFADMWNvUqiIiIqIWwNPaOH3zwAd544w2kpqbKyXti++mnn+Lo0aP47LPPGJAiIiIiszifqnpJhXk7VX8nfemebJQtGpIbiB5Qt/4GdLpGTXn75Tbg0E/Gnzx+P6DTAK5BgHtInb8HIiIiIjJjUCoqKgo33nij3L/hhhtgbW2Nt956C8HB9ZxwQ0RERFTB+dQ8uQ3zdq7+TobJeyJ4dDkbe2Dmd0DvW1WAadl9wM5PjTu56IcksHSPiIiIqPkEpQoKCuDo6Cj3LSwsYGdnh4CAgIZcGxEREbVB0SmGoJT6u6PGTCnXwKpvt7IGpn6sehwJa+cDG18BdLqaTx6j7yfFJudEREREzavRuegj5eysPrUsLS3FN998A29vfR8HvUceecS8KyQiIqI2Q6vV4WJafu2ZUmK6m+BSwwdklpbA+FcABw9g48vA1reA/HRg8tvqtitOrgFi96j9duwnRURERNRsglLt2rXDl19+Wfa1v78/vv/++0r3ERlUDEoRERFRXSXlFKKgRANrSwsEezjUPVPKwMICGPmUCkytfBLYtxAozASmfQZY21a+b/IJoDgHsHUGfLuZ4bshIiIiIrMEpS5cuGDsXYmIiIjq5Ly+dK+dpyNsrGroMpCdUH1PqaoMuBtwcAeW3gsc+x0ozAJmfg/YOl5Zuhc8QJX/EREREVHz6ClFRERE1NCi9U3OQ2uavGds+d7luk8HZv0M2DgC59YDC68Gjv8BaErV7WxyTkRERNSoGJQiIiKiZjh5r4aglGhWnpNgXPne5SKvAm5fBti7A0nHgF/vBD7qo6bzXdyp7hPCflJEREREjYFBKSIiImo2LhgTlMpPAzTFomEU4OJv+klEE/OH9gKjngEcvYDMGDWdLzsOsLAEgvvX4zsgIiIiImMxKEVERETNLlMqvKaglKF0z8kHsLqsWbmxnH2BMf8GHj8OXPs+4NVBXR86HLBzqdsxiYiIiMgk7OJJREREzUKJRouY9Hy5H+bjVP/Je8awcQD6zwH6zgYSDwPu7et/TCIiIiJquKBUVFQUFi1aJLcffPABfH19sXr1arRr1w7dunGEMhERUUWpuUU4Epd5xfU9gtzh42LXJGtqjuIyClCq1cHexhJ+LvZGBKWMnLxnDEtLILCP+Y5HREREROYPSm3ZsgWTJk3CsGHDsHXrVrz66qsyKHX48GEsXLgQv/32m6mHJCIiarVOJmTjxs92IrdIP+GtAidbKzw7uQtuHdgOlpYWaOsM/aRCvZxqfj7KglImTN4jIiIiopbfU+rZZ5/FK6+8gr///hu2tuV9HMaOHYtdu3aZe31EREQtVnJOIe7+Zq8MSAW5O6BXsFvZJdTLEXnFGvzfsmOY9dUuXExTAZm2LNrQT6qm0j1zl+8RERERUcvJlDp69CgWL158xfUiWyo1NdVc6yIiImrRCoo1mPvtPlzKKpRBlj/uHwY3R5uy27VaHb7beQFvrDmNXdHpmPD+Vjw9oTOu7uJX6ThOdlbwcm4bJX7nU3Nrn7wn5DRA+R4RERERNf+glLu7OxISEhAWFlbp+oMHDyIoiH8cEhERiYDTE0sO4XBcFjwcbfD17AGVAlKCKE+7c1gYxnb2w7NLj+CfqDS8vOKEvFRkZWmBZyd2xtyR4Wgrk/dE+R62vAU4uAMD51afKeXC8j0iIiKiNlW+d/PNN+OZZ55BYmIiLCwsoNVqsWPHDjz11FO44447GmaVRERELcjb605j9bFE2FpZ4vPb+yO0hsyfdl6O+PGeQfjf9T3g72oPR1ursouDjRU0Wh3+t/ok1h1PRGt3PkUFpTrbpQKbXgFWPQ0UZDZOo3MiIiIiav6ZUv/73//w4IMPIiQkBBqNBl27dpXbWbNm4bnnnmuYVRIRUf2cXa+mi4WPASyqaSAdtRE48isw/HHAp2Njr7DVWLIvFp9ujpL7b8zogYFhnrU+RnzIM2tQO3m53HPLjuKHXTF47JdD+P3+oegS4IrWqLBEI0sdhVBdvP5aHRC/H4gcV+GO2UCxKvNjo3MiIiKiNhaUEs3Nv/zyS/zf//0fjh07htzcXPTp0wcdOnRomBUSEVH9JBwBfpyu9kNHABP+BwT0LL89OwFYOx84/of+Ch1w/WdNstSW7p+oVPx76VG5/8jYSFzfJ7jex3xhSjdZ1rbjXBru+XYf/nxoGLxbYY+pC/pG724ONnDOPVN+Q9y+ykEpQ5aUvRtg6wTodI29VCIiIiJqqqDU9u3bMXz4cLRr105eiIiomTu6pHz/wjbg85FAn9uA0fOBE38Cm/4HFOeU3+f8NvVGv7qMKqpSVEou7v/hAEq1OkzpFYjHrzZPtpmNlSU+mdUX0z7ZgQtp+bj/h/344Z5BsLO2qvMxxTTADSeTsPJIAnZGp6FUUzmw4+Vsi5/mDkaIpyMau3RPlDpapJ0rvyFub+U7ZuuzqFi6R0RERNT2glJjx46VDc1vueUW3HbbbbJ8j4iImimtFji2VO1PfB2I3QMcXwoc/F5dDIL6A+NfAb6dAmTHARkXAM/KAy2oehl5xbjrm73IKihBn3bueGtGT1mSZy7ujrb4avYAXP/pDuy9kIEnlxzGhG7+dZoIuPFUMjadTkZRqbba+8VlFGD54Ut4cEwkGku0vsl5uOi/dXlQqmKQNCdBbdnknIiIiKjtBaUuXbqEn3/+GT/99BNef/119OzZE7feeqsMUgUH179MgYiIzCh2l8ossXMF+s0BBt+vLmvmA/H7AHt34Or/An3uUD2ngvqpx4iMKgaljFJUqsG93+/HxbR8BHs44Ivb+8Pepu5ZTNWJ9HXGx7P6Ys6iPVhxJEFe6iPM2wnX9gzA+K7+cK8wGXDZwXi88/cZ7IpOa9Sg1AV9UEqsC4dUTy6pMBNIiwK8Iy9rch7YaGsjIiIiomYSlPL29sZDDz0kL+fPn8fixYvx7bffYv78+Rg5ciQ2btzYMCslIiLTHf1VbbtMAWzs1X7IQODuv4G4PYB3R8CxQiPu0OEqKCVK+PpyomptdDod5i89ij0X0uFiZ42v7xwAH5eG6/c0qqOPLOVbvCfmipI7Y4i4Y89gdxmM6hrgWmU219Xd/GRQav/FDJRotLJ8sDGIvllCpLvIhtIHnnw6AymnVLZUWVCK5XtEREREbTYoVVFYWBieffZZ9OrVSzY+37Jli/lWRkRE9aMpAY4vU/s9ZlwZnWg3+MrHhI0Atr0NXNjOvlJG+GTTOSw9EA8rSwt8cmtfdPRzafBzTuoRIC8NpaOvi8ycyswvwdH4LPRt54HGDEp1tE5WVzh6AZFXlQelet9yWaYUy/eIiIiIWro6f/y5Y8cOPPDAAwgICMCsWbPQvXt3rFy50ryrIyKiuoveDBSkA04+QOhI4x4TMgiwslWZKunRDb3CFm3FkUt4e52aEvffqd0wsqMPWgNLSwsMClPZc6KErzFk5ZcgLa9Y7gdr9ZlQXh2A4AFXNjsX0yIFZkoRERERtb2glCjTExlSouF5TEwMPvjgAyQmJuL777/HxIkTG2aVRERU99K9btcDVkYmxto4lAcCzm9tuLW1cAdiMvDEksNy/+7hYbhtcHu0JoPDveR2d3R6o5zvfJrKkvJ1sYN91nl1pVekKjUVko4DxXmXle+xpxQRERFRmwtKbd26FU8//TTi4+OxYsUK2eDc0bHxRkYTEZERivOBU/rs1R43mvZY0VdKECV8dIXY9HzM+24fiku1uKqLL/49uQtam0FhKii170I6SjXVT+lrkCbnhsl7ooeUCDyJjCidBrh0CCgpUNl/AqfvEREREbW9nlKibI+IiJq5s2uB4lzAvV155pOxQkcAW95QE/jYV6qS7MIS3P3tXqTmFstG4R/c3Ef2k2ptOvu7wM3BBlkFJTh2KRu9Q0T38YYTrQ9Khfs4AalnyzOlhOD+wIl41Zjf0EfK2gFwaJxeV0RERETUxEGp5cuXY9KkSbCxsZH7NZk6daq51kZERHV19De17T7d9KCSCGJZ2QG5SSpA4NMRbbVELz6joNJ1v+yNxZmkXPi52mHhnf3hZFeveSHNuq/UwDBP/H0iSfaVauiglKHJeainI3A66rKg1ADgxJ9A3L7yAKvIoGKwlIiIiKjFM+qv6WnTpsm+Ub6+vnK/OmK0tEajMef6iIjIVAWZwNl1dSvdE2zsVS8fkSklLm0wKHUqMRs3fPpPlbc52FjhqzsGIMDNAa2Z6CtlCErdNyrCLMfUanX4eW8sVh9LgEarK7v+WHyW3HZyKQCKssVfFIBnuLqxYrPz7OvUPvtJEREREbWdoJRWq61yn4iImqFTKwBNMeDTBfDrVrdjiBI+Q1BqwN1oa3ZFqalz3s52iPR1KrveztoK944KR49gN7R2g8PVBL59FzJkXylrqzoP7JXOJOVg/tKj2H8xo8rbRRVkV7tk9YUoO7W2U/sBvQBLa5W5F7tbXcegFBEREVGrYHLdwXfffYebbroJdnb6Pxb1iouL8fPPP+OOO+4w5/qIiMgUuSnAvq/Vfo/pdT9O2Ahgs77ZeRvsK3UkTmXu3DqoHR6/uu1ligmd/V3ham+N7MJSHL+UjV51LOErLNHgk03n8NmWKJRodHCytcIDYyIRIkr1KgjzcoJv0jL1hXeHyhMh/XsAlw4CJ/9S1zEoRURERNQ2g1Jz5szBxIkTZSlfRTk5OfI2BqWIiJpAfjqw4wNgzxdAST5gZVu30j2DoH6qmXReCpByCvBtfRPmanI4LlNue4W0/oyo6ogG7gPDvLD+ZBJ2n0+rU1BqZ1Qa/v3H0bKeUVd18cNL13VDoHs1pY8nLmtybiBK+ERQSmRLCS4MShERERG1Bibn4ut0Otk76nJxcXFwc2u7f7wTETVZ/6hN/wPe7wnseF8FpAL7ALctBTxC635cUTrVbpDaF9lSbUhOYUnZNLiewQ3b4LullPDtik436XGZ+cX412+HccuXu2RAytfFDgtu7Ysv7+hXfUBKSLusybnB5RMkmSlFRERE1LYypfr06SODUeIybtw4WFuXP1Q0Nz9//rzMoCIiokZQlAPs/gz45yOgUJWawa8HMObfQKdJ5im3Cx0ORG8Gzm8FBs5FW3E0PktWLAa5O8ieUm2ZaHYu7D2fLhuTi+yp2j64Wn74El5ecQKpucVlJZD/mtgZbg42tZ8w7Vw1Qan+lb9mUIqIiIiobQWlDFP3Dh06hAkTJsDZ2bnsNltbW4SGhmL69Hr0LyEiotoV5wN7vwS2vw8U6LNXfDoDo+cDXaYClvVrRl1J6MjyTCkx5MKcx24B/aTacumeQZcAV7jYWyOnsBQnLmXX2OA9Nj0fzy07hi1nUuTXHXyd8doNPdA/VGVb1UpTCqSfrzoo5REGOHoB+aoBPYNSRERERG0sKPXCCy/IrQg+iUbn9vb2DbkuIiKqqKQQ2L8I2PYukKefUOYZoYJR3W8ALK3Mf86gvoCNkwp+JR9XzabbgMOxqp9UWy/dK+srFeqJDaeSsSs6rcqglJjMt2jHBbz79xkUlGhga2WJh8dG4t5REbC1NiGQmXkR0JaoXmauQZVvE5l/ooTvzBo1ic/JxwzfHRERERE1NZM/9p49ezYDUkREjaW0GNj7FfBhH2DNsyog5d4euO5T4ME9QM8bGyYgJVjZqCl8wpr5KpOlDWVK9awhK6gtlvCJoNTljsZl4bpPduDVVSdlQGpQmCdWPzYCD4/rYFpAqlLpXkTVWXmGvlIuAQ33miciIiKi5j19T/SPeu+997BkyRLExMSguFj1jDBITzetGSoREV1GNDTKigXOrQe2vQdkxajrRfbIyKeB3rcC1raNs5arX1Llexe2ARtfUl+3Yqm5RYjPLJCJOT2CGJSqGJTaGZ2Gp389XHZ9XnEp1hxL/P/27gM6ymrrw/g/PZSEUELovXepUm0ISFEsKIode7li/yzYrv0qtuu1946KShEUBUTpvffeOwktkDLfOudlQgJJSDKTzGTm+a01Tp+cCdspO3vvo3SX7Lyox3o31oC21bLdDCXfSans1D1XmvDvoKnYAwAACAb5Tko9/fTT+vDDD3X//ffr8ccf12OPPab169fr559/1hNPPFE4qwSAQLdpprT6T2nrXGnLXOnw7hPXlU6Qut4vtb5Oiii8StWUtHTNXr9PyalpmS4tqwZn/UdVx98uTXnDqVZp3E+BauFmp3WvbnxpxUTnYTB3EGhSJVZlS0Zo3+EUfT9n8ynXX9iyiob2baL4GA+Hwmckpern3E56x3SpTHXPfg4AAACKb1Lqq6++0gcffKA+ffroqaee0pVXXqm6deuqRYsWmj59uv71r3+pKLz99tv6z3/+o+3bt6tly5Z666231L59e3vdfffdp08//VSlSpXSiy++qEGDBmXc7/vvv9fnn3+uUaNGFck6AeC09qyRPuphSqROXGbm5iQ0lZoPkNoOliJLFuoSpqzerSdHLtHqnQezubaMRje4Ws02fin9dLsU31iqcNIg6gCxYBOte9nNlfrsxvaasvrU9r1W1ePUsa5TSeWx3auyH3KeWcXG3vlZAAAAKJ5JKZMEat7cKZ03O/AlJjof4Pv27auhQ4eqKHz33Xc28fTuu++qQ4cOev311+2OgCtWrNCMGTP09ddf6/fff9eqVat044032usqVKhg12oqu/74448iWScA5MmaCU5Cygwu73CbUxGS0MxrVVHHUtN173fzlZSconMaVlT3xgmqUd5Jcm3df0TPjVmmMYu22fNxJSNUvWzJLNVTy7cf0KWre2p2teWK2TlbGn6NdNMfUmQpBWqlVEtvDjk/ekD65kopPU269peia730IjP0vdAHv5vkrFEhh0opAAAABJx8J6WqVaumbdu2qUaNGrZCyiR/WrdurVmzZikqysPS/TwaNmyYbr75Zt1www32vElOjRkzRh9//LFCQ0N19tlnq23btvYwZMgQrVu3zialHnroId1+++127QDgN9b95Ry3ukrqcIvXH/7PZTsykk5/r9qtZ0YvVf2KpXVGjTiNWrDNDqgODZGu7VhL957fwM4HcnO5XDah9fP8rRqw9zaNKfWownYulUbdI13ygbMrWoAwz3WBt4ecp6VIw69zZnIZS39xhtMHq6MHpb9ekjZOk3q/IlVpdeLyA1ud0+Xq+HSJAAAA8OPd9y6++GL9+eef9vTdd99tq6Pq16+va6+91lYlFTYzWH3OnDnq3r17xmUmEWXOT5s2zbbyzZ49W/v27bO3O3LkiOrVq6d//vlHc+fOLbL2QgDIk/R0Z5C4UbtbofyIn+Ztsced65XXmXXK2XasVTsPavjszTYh1a5WWY35V1c9dWHTLAkpwwytfv6S5mpUKUbLD5bUU5EPyhUSJi36Xpr5vgLJ5n1HtPfQMYWHhqhx5VjvDKwffa+0xnnPtGa8q6C1Yqz0dgdp6pvS5lnSl5eeaNnbe7xKqmR5qWQ5ny4TAAAAflwpZWY0uV1xxRW26sgkg0xiql+/wh9+u3v3brsDYEJCQpbLzfnly5fbVr2rr75a7dq1U4kSJfTZZ5/Z2VKmQsrMmXrnnXfs/ClTOfX++++radOm2f6co0eP2oNbUlJSxl/SzaE4cK+1uKwX/i8QY2r2+r0atXCb0k96TqaSaGC7Gvnf1j6/dixWyJF9ckWWliq3chIZXrT/8DFNWrHLnn68T2M1qhSrxCMpmrxyl+Zs2KfWNcqqX8vKNvmU079riYgwvTOotS58e4q+2FZVXereqZ5b3pTrt0elyi2l6h0CIoYWHG/dMwm4qPBQz9c4+T8KmfeFXCGhUt/XpV8fUMiW2XJtnuO0aAaLpK3SuIcVssyZ5eiKqyFFxShkxxK5Pu8v3ThO2r1apubOZYac5/P37s8xBf9H/MDbiCl4GzGF4hoXeV1bvpNSJ+vYsaM9+BMzgN0cMu8YaCqpIiIi9Oyzz2rRokUaPXq0re4y1VTZeeGFF+z9TmbmUvnzP3xmZp0HDzpDiwu8RTcQ4DFltrhfv/dIttd9PnW9Hu9VV2dU80LVTA6ilv2uEpJSq7TVoYOHvf74P87frmNp6WoQX1KVS7gy5gB2q1XKHjIn3XNTNkL6d596GvLjct26poP+qnm+au4Yr/TvrtWBq8bIVSq+2MfQrDU77XHjhJIZv6eCilj6o0pNfM6ePnL20zpW9yKVbDBJkctGKGXKf3W452vya650ySTTPJGepsiFn6vE1FcUcuygXKHhOtr6ZiV3uEchKYdV+vsBCtu3RmmfXaTUml1lBgAci6muI/n83ftzTMH/ET/wNmIK3kZMobjGRV6+Y+Q5KTVy5Mg8/+ALL7xQhclUOIWFhWnHjh1ZLjfnK1WqdMrtTfXUl19+qXnz5tmZU926dVN8fLwuv/xy22544MABxcTEnHK/Rx55xA5Tz/wLrV69usqUKaPY2ML7gupN7uSZWbO/BiqKl0CLKTP4252QuvOcurZtyz0Y/LvZm7Vm92Hd8OUiXdW+uh7u1UixJ7W2ecX2WfYovP559vfqbb+vWGaPL27jvH554qK2ZbRqb4renrhGl2wdpKnl1ylq/2rFjh8iXfOzs2NgIcSQuc/Lv63Q/E1OJVN+lSsVqQd7NFStCrkPZl+xy4mFtnXiPftdmRlhfzxkT7o63aMS3e62iUd1vktaNkIRK0apTO8XpdIV5VfMv41pNfzjSWnPWunmP6WKTQr2WNsWSKOHKGTrPOehq7WX+r6mqISmNvlkXfeLXB/3sokpczAiKzdVZD5/94H2uoSiRfzA24gpeBsxheIaF3ldV56SUv3798/zDzWtdYUpMjJSbdq0sXOt3OtKT0+35++6665T/qFuvfVWOxjd7BRo1paSkmKvcx/ntF4ztD27we3mOfrrP3p23OstTmuGfwukmFqx3fnrQuUy0XqwZ6Ms193Sra6e/3WZvp+zWV/P3KTxy3bqyX5N1Ke50+rmFWmp0oap9mRI7a5eHxq+ed9hzVy31z7sRa2qemXd953fUAs3J9qB6bccG6JPIx9WiJmJNeHf0vnPFEoMLdqSqHf/WuvRuhdvSdJPd3RS+dLZb8iRlu6ytzFaVo8r+O9qx1Lpu2ul9FSp6SUK6f7UiX/Xam2kqm1tC5/mfiad5SSu/MLW+dL4J04M3TcWj5DOy77FPUdmYPnE56UZ7zjVVlFlpPOfUkjr680AyKy3jasuXfuz9HFP6fAee1FIhXoF+v8gkF6XUPSIH3gbMQVvI6ZQHOPCq0kpk/TxJ6aC6brrrrO767Vv316vv/66Dh06lLEbn9uHH35oq6Lcs646d+5s2/qmT5+usWPHqkmTJoqLK+QtrgH4rSVbnTahplVOrX4sWypS/xnQUpe0rqbHflqktbsP6a6v5+nHhpv1zEXNVL1cSc8XsH2BdDRJii4jVWohbxu5wNnN7Mza5VUlztbqeMwMSX9j4Bnq99Y/+mtvOb1X437dtvMZacobNuGiJt6vlnXvHNipbnld1SF/u6emu6T//LZcG/ce1s2fz9bXN5+p6IiwU263dtdBHTyaaudn1YsvXbCFJm2TvhogHU2UanSU+r9zaiKmw23SiJukWR9JXe6Vwgqh+i6vzHu7GTg+6wNncL0RFilVaydtmHJix8C8Wv6r9OuDUtJm53yzS6WeL0gxWWdAZlGhvnT1COnTvlLKIalScw+eEAAAAIobj2dK+YIZsL5r1y498cQT2r59u1q1aqVx48ZlGX5u2vmee+45TZ3qVCEYJoF1//33q0+fPqpYsaIdgg4geC3Z6lTGNKmSc7tQx7rlNXZIV/1v4hq9M2mNJq7YpR6vTda959fXjZ1rKzzMg7k76yY7xzW7SKGnJko8YSpFfz6+617/M6p49bFNO9w7V7fWZe9M04sbG+nMeoPUavNX0s93SBUbO4kGLz6PMQudpNQ1Z9bUBc0r5/sxmlSO1SX/m6K5G/fr/uEL9NaVZyj0eKum24LNToKyWdXYgv2bHj0gfT3ASciYYd0Dv5YiorNZzEXS749JB7dLS3+Rml92+hiZ9j+p24NOpZWn0tOkjdOkpSOlZSOlA87v1mpxhXTOY+a3Lr3RUtoyx6l8ijpNki5xizT2IWn5aOd8XE2pzzCp/oldcnNVpZV0+z/Sge1S2VoePDkAAAAEfFLqmWdyb88wiaKiYFr1Tm7Xy8wkqNavX5/t+opqjQCKR1Iqu0qpzKLCw3Tv+Q3Ur2UVWzU1Y91ePf/rcv08b6teuKS5bfcqkHXHK1FM656XLdt2QCt3HLS7B/Zqlv9Ezum0qBanZy5qqv8bsUiXr+mpWdVWqMyu2dJ31ziziCJzn9+UV6ZVcPO+IyoZGaazGxZsBlO9iqX1/rVtdc1HM2zVVbVyJfTIBY1P+jn7M55XvqWlSMOvk7YvkszA90HfSyXLZX/b8EipzQ3SXy9KM9/PPSm1e7X07SCnmm7TDOmmP6TydQuwvlSn6skkwUzi6JCzG6MVFSs16CV1vNNJDrmZHfL2b5Q2Ts85uWQSXDM/cFo3jx10Zop1ulvq9pAUmc9KQpOMIiEFAAAQdPKdlPrpp5+ynDezmdatW6fw8HDVrVuXhA+AYuFoappW7TiQp6RU5uTGt7ecqe9nb9Zzvy7T0m1J6v+/KbquYy3d36OBYqLz0YqVesypWDFqd5O3/TzfqZI6r1FFlSmMAe2SBravoXkb9+u72Zs0YM+tGltyo8J2LZNG/ku69EOvzMhyt+6d1zhBJSILXk12Zp3yevmyFrr3uwV676+1ii8dpU51K2RcP3v9Pnuc7wSjGTI55j5nQHh4Cemq76RytXO/T9sbpL9fdRJNZpZT5mSQ27FD0ndXOwkpswvekb1Oa6BJTOWU8Do5vsx8qKU/O2115v5u0XFSoz5O1Vads6XwbOZs1eomzf9SWj85+6SUefwv+jttfoYZZN7vdSkhnzOoAAAAENTynZQyu9idzOxMd/311+viiy/21roAoFCt2nFQqekum7Cpmo95S2Zg3+XtquvcxhX13Jhl+mneFn06db3GLd6upy9qqp5NT90FNFtb50oph6WS5aX4rFU7njJDu0fOd+ZJ9T+jqgqTec4mObdoi/R4zP16PuRRhSz+QareXupwq9da9/o0z+PvNRcXn1FNG/Yc1ut/rNKzY5xdCU/Wslo+d90zyaW5nzuJo8s+lqrmocUuppLUtL8zx2nyf5z7ZU4MmUTXyLslk+ArneBUXpmKqb1rnETVNT9ln0hKSZbWTHAqolaMdWZbuZk4a9TXSUSZJOjpZlmZ6j2TlHJX851s1e9OQiqytNTj31J2g8wBAACAopgpFRsbq6efftoOFL/mmmu88ZAAUCRDzs28oYLsWFGhdJReu6KVLmldVY//vNgmO279Yo7OaRivhpWyVl7FlYxQ/1ZVValM9KnzpGp19fqX+Rlr92h7UrJio8N1dsN4FSYzNPx/g1qr33//0Tc7qqtLnTvUZ+tb0m+PSpVbSTU6FPixzZynLfs9a9072T3n1dfR1HSNmLvZDkE/uZqqRn4G2C/4zmldMy54WWrUO+/3PfN2Jyll2une7SL1e0Oq2cm5bvo70uIfnXa4AZ9JlVtKVw13dqkziSBTiXbxu04lmqmoWv2Hk4ha+ZvTRudmElqN+zmJqBqdpLB8vOWbuDS2zZeSE51h/Jm5B6O3uV5qe2PeHxcAAAAojEHniYmJ9gAAgTRP6nS61o/Xb0O66a0Jq2xbmBmEbg4ne+W3FerdvLJu7FJbrUyLmDsplc08qWOp6Vq544CtQDIJlPz6bfF2e9ynRRU7D6uwmZ0IzY58138yU3euPVPNa69UjW2/Sd9fJ906WSpdsITSmIVOtVf3xgnZ7phXECYB+XCvRvZwWqZiKaeEpfn3++VO57SZo9T+5vwtxFRUXf6FNOZ+afdK6ZMLpNbXSg0ukH5/3LlNj+ekmh2d0wlNpAGfOi18C791Kp1MsmjVeCn1yInHja0qNb7QSUSZarWCDtAvU1UqV9epztowVWp4wYnrkpOkleOc0y0uL9jjAwAAAAVJSr355puntFds27ZNX3zxhS64INOHVgAoDkmpqtkkpczAalOBUuPMPD2WSZg82LORLmpV1e54Z5JKJw/rnrl+r0Yu2GoPHaqX1Fd7ZtgX4B/21lXSP+uU7nJp/Z5DWrQ50Q4pP5aW/2TUyfq38u6ue7k5q0G87uveQK+OX6mLNg3UtAprFL1/tTT6XmngVx617plkXpEzO8G908mZv3TeE06Sx52g2rlM+vZqKT1FatJf6p77BiA5anKhk5T84ylpzqdOG6A5GM0HnNr+WO88qc+r0ugh0rwvsg4lN+sza6nS2nuVd2ZtJillWvgyJ6VMdVdqslShgVSphXd+FgAAAIJSvpNSr732WpbzoaGhio+P13XXXadHHnnEm2sDgEJhZi4t2+aulDqpLengLumjHs68p4a9nbasuOp5etwGCTF66OQKHFNREzleqzv20v9WlNLoBdsUumWWwiOPaYcrTg9MPCRp6SmPZWZdNasaq9j8DE/PpFGlWLWvnYeB2F505zn1NH/Tfv25fKduOXKXPtcQafkYad/6fO+sNm/Tfm1NTFYp27pXuC2I2TItcYf3OAdT8VW1rXT+M87ud6Zaycxrqn6mdPF7niWBSpR1WvdaXCGNusepmqrY1LksuyotMyTdDC037Xp1z3OSUaa9zwtD5bNt4TPJMndVn9vC4c5x88sL5+cCAAAgaOQ7KWV22gOA4mzDnkM6fCxNUeGhqlOhVNYr537mJKSMFb9Ka/+SznlE6nB7/mbyuBNcpqLmaKLq6U0Nq9lZT1x6k1bN2yptkjbFttWFVU4MIjczp1pUK6MWVeNUvVyJAs268qXQ0BANu6KV+r31jybvrajFca3VLHmuk9jo/lS+HstdJdW9ifda9/Jl82znOKG5tHettGW29GlvJ4l0ZJ9Uvp505TdSRKY5YZ4w86Ru+0da/afTshd5Ulxm1vV+51DY3LtC7lgkHd7r7Pp3YIezq5/R/NLCXwMAAAACmtdmSgFAcWvda1Q5VuFhmapc0lKl2Z84p7s9JK3/R9o41ZnxY4Zamy3vq7XN+w/682mnoqZkBSl5vx1SHbdhitodv7rtORepbeszFEhMhde7V7fRxf+boreSuum9yLnaP+VjDVrYRSkhEYoIC9W59cvqlnNKKSaHKrD0dJd+XeTedc8HrXvGljnO8VkPOhVRf70ozfnMSUiZf89BPzhJGm8yO+rlZ1h6YTOzwOIbSbuWO/8vmHbDJT9JrnSncqxcHV+vEAAAAMGWlEpOTtZbb72liRMnaufOnUpPzzr3ZO7cud5cHwAU3ZBzM7w5abNUsrxTiXL2I9L8r6TxQ51qkQ+7OzuNmRlDJeJOn9SY96Vz2sxUMnN/Zn3oJL1M+5VCTlSiBJgmVWL14qXN9eDwFG13lVUl7VPd3RM1Mr1Txu//y1lbdUu3urq2Y02Vigo/pXVvW2KySkeFq1sDH7TuHTss7VhyYiB5TILU9zXpzDukBd84857K1VZQMC18JillWvhMUmrR8dY9BpwDAADAF0mpwYMH6/fff9dll12m9u3bF7v2EgBYsjUx+6SUSRoZZ1xzoi2r9TXOkOffh0oLvpZmf+QMeu75vNTs0uxn6phk/a8PmXHdzqwg98B0k8zq9qAzDygqNt9zloqTi8+optY1yirlr2ukhW/q39VmaGDPe7V572G9PXGVNuxN1kvjluuDv9faxFR8TFTGfScs22mPuzeu6JvWve0LJVeaVLqSs5udW4X6zr9hMDGJ01kfSOv/lvascZKtIWFS04t9vTIAAAAEY1Jq9OjR+vXXX9W5c+fCWREAFCKzq9vSrdkMOd+9Wlo70algMtVQmZWqIF38jtTqKmc3uT2rpB8HO1VUZje0k9uYFn7rzCCKLO0Mx84sooTUcqCCQc3ypaTut0uL3laZnbPUqfROueo01rl1YzRp3UG9NWG1Nuw5rNf/WJXt/X2y617meVKmSirY//BSq4vz/4Splpr+jnNZnbOd1j4AAACgqJNSVatWVUxMjKc/FwB8YkfSUe05dEyhIWaHuphTq6Qa9JLK1sz+zrW7SrdPkaa8IU1+RVozQfpfR6nrA1LnfzkzgZITpfFPOrc/6yEpppKCWmwVp9LMVJfN+cTuZhgeGqJLW1dT/1ZVNWLeFk1asdPuiJhZrfKldF7jBOdMepo04mYnOXLhW1JkyaKZJ1WtTeH+nOLAzM1KaOa0r5oqQcO0LwIAAAC+SEq9+uqrevjhh/Xuu++qZs0cvrgBgJ+37tWNL32iNezYIWn+187p9jfl/gAm8WSSTaZ1b8x90tpJ0sRnnVk7Zu7QirHSoZ3O7mxmxz5I7QY7SakF32ZpfzND5i9vW90ecrVhqrT4R+f04d3Sld86FWeFxVS5uSul4CRjTVLKDDgPj5Ya9/X1igAAABAgMm07lTdt27a1w87r1KljK6bKlSuX5QAAxW7I+cLhzi55pg2vzrl5e6DydaVrfpYu+VAqFS/tXil92kea/j/n+l4vSeGRhfEUip/aZzu/26NJ0qLjyaX8WDLixGmTBPzuaiklWYXi4C5p/0anKqtKYO2MWGCZB/KbqrcoqqUBAADgo0qpK6+8Ulu2bNHzzz+vhIQEBp0DKKZDzo/Pk3K5TrTutR0sheYjV29e/1oMkOp3l/542mlPM9UkDXs7l8FhfqdtbnB2MTQtYHUvyvt901KlpSOd090ekqb9V1r9hzT8WumKL5zKtcJo3avQQIrONHMsmNXsJIWEOrFN6x4AAAB8mZSaOnWqpk2bppYtW3pzHQDgm0qpjdOlHYul8BLSGYMK9qAlykr9XpdaDZJW/SZ1uM2LKw4QZ1wtTXhWIdsXKmzbbCkuj0m79ZOdlr2S5aWzHnZayb663Pk9f3+DNOBT71akuVv3qrX13mMWdyY5d+5Qae9aqX4PX68GAAAAwdy+16hRIx05cqRwVgMAhSjxcIo273Nev5q4k1IZw5svc5JLnqjeTjr3cWe3Ppw6MLvpxfZk6R8HSWMfkpK2nv5+i4+37jW+UAoLd1rJrvzGmW20Yoz0441SWor3K6WqtvbeYwaCrvdJF/1XCovw9UoAAAAQzEmpF198Uffff78mTZqkPXv2KCkpKcsBAPzV0m3Oa1TVuBKKKxnptO6ZHfTclTwoXN2fkqtGR4WkHVXIzPelN1pJv5rk1Lbsb596TFo2yjnd7JITl9c9Rxr4lRQW6Vz/401Om5+n0tMzJaWolAIAAAD8rn2vV69e9vi8887LcrnL5bLzpdLS0ry3OgAooGOp6Rq1YKsOJJ+oopm9YV/W1r2kLdLhPVJImFS5la+WGjxiK0vX/6qDS8aq1Ky3FLJxmjTzPWnu59LVP0i1umS9vRlqnrxfKp0g1eyc9bp63aUrvpK+vUpa+rMUGiZd/L5TTVVQpj0tOdGpwkpoWvDHAQAAAJAn+f70PnHixPzeBQCK3JfTN+iZ0Uuzva5Z1eMDrLctcI4rNpYiootwdUEsJESp1TtLTS9w5kX9+YxTnfTz7dLt06So0qfuutekv5N0OlmDHtLln0vDr5EW/yiFhkv938n+tvmZJ1W5JW1qAAAAgD8mpc4666zCWQkAeNFvS7bb4zY1y6pymRMJp9gSEbqqQ42sSSmThEDRMjsX1jlbqtpG+l8naf9G6Y+npD6vONenJEvLx5zauneyRr2dYefDr5MWfuckpi78b/52UXTLaN1rU5BnBAAAAKCwk1KTJ0/O9fpu3brl9yGBoHH4WKoWb0lSuplllEm5UpGqF19aoaEhPltboA00d7fqvX5FK1UvVzL7G2YkpWjd85moGOnCN6QvLpZmfSA17e+08a35UzqaJMVWlaq1z/0xGveTLvtI+mGwNP8rp1Kq7xv5T0xtPl4pRVIKAAAA8M+k1Nlnn33KZWaWlBszpYDspae7dP0nszRz3d5sry9TIkLtapVT+9pl1b52eTv3KCKsANUe0KSVO5WW7lKDhNI5J6QMKqX8Q91zpdbXOrOlfrlLun3qiV33zI59eUkumdulp0kjbnYex8wJ6/uaU5GVF6lHpe2LnNMkpQAAAAD/TErt2+dUH7ilpKRo3rx5Gjp0qJ577jlvrg0IKN/N3mQTUpHhoaqRKVFiNgnYlpisxCMp+mPZDnswSkSE2dYzJ1FVTmfUiFN0RAFn5QSZP5fttMfnNU7I+UYHdkgHzK5vIVKlZkW3OGSvx7PS6j+lfeuk3x6VVox1Lm+aS+veyZpf5iSmfrpVmvOJ08rX+z95S0yZhFR6ilSyvFS2VsGfBwAAAIDCS0qVKXN8QHAm559/viIjI3XfffdpzpzjMzkAZNh98KheHLvcnn64VyMN7lI7y/UpaelaujXJJq1mrt+rWev3av/hFP2zerc9GBFhIWpRLc4mqTrULqc2tcoqNpphzCczv8tJK44npRpVzPmG2xc6xxUaSJGlimh1yFF0GanfG9JXlzkJJSOuplS1df4ep+UVUnqq9MudTjugSUz1euH0ianM86TyWl0FAAAAwCMe7J2dVUJCglasWOGthwMCynNjltlKqCaVY3Vdx5qnXG/a9FpWj7OHm7vVsa1+q3cd1AyTpLKHPdqRdFRzNuyzh3f/WmO/N9evWFqlorL+b2wSVdd3qqWzG8Znaa0NFub3k5Scaud0nVGjbM433DbfOaZ1z3/UP19qeZW04OsTLXkFieEzBjmJqVH/kmYc343PVGLl9lgZ86TaFnDxAAAAAAo9KbVw4fHqgsytR9u26cUXX1SrVgwLBk42ZfVu/TRvi/0+/PwlzRWehzlRZuB5g4QYe7jmzJr2/7NNe49oxro9torKJKrW7zmslTsOZnv/v1buUrtaZfVQr0a2siqY/Hm8/dEk5cJyGxzPPCn/1Ot5ae1E6eAOqcXlBX+cNtdJrjRp9L3StP9KUbHS2Q/nfHt23gMAAAD8PyllEk+m+sJ8Sc7szDPP1Mcff+zNtQHFXnJKmh7/ebE9bZJLrarHFehxzP9zNcqXtIcBbavby3YmJWvJ1iTbrpaZSVp9Nm2DZq3fpwHvTtM5DeN1badadkZVZnXjSys+JkqB5s/l7ta9XOZJGSSl/FOJstLNE6VDO6WEpp49VtsbpbQUaexD0qTnpdjKzkD1k/31srR3jTMcPb/tggAAAACKLim1bt26LOdDQ0MVHx+v6Ojogq8CCFDvTFqjdbsPqWJMlB7o2dCrj10xNtoeTtajaSXd2KW23vxztYbP3qSJK3bZw8kiw0J1ZfvquuOcekrI5nGKI/O7XrvrkMJDQ9StQYWcb3h4r7R/o3O6UvMiWx/yyCSPzMEbOtzqVF39/ao0aohUOkFq0NO5zvxxZdIL0l8vOefPe0IqGVyVhQAAAECxSkrVrHnqPBwgmJmqQVOx9Peq3TqSkpZxuZkL9f7ktfb0E/2aFOlQ8splSuiFS5rrlm519Nafq7Rg8/4s1x9LS7ftgKai6ptZm3RV+xq64+y62Sa5imPrXoc65RST2+/bPeS8bG2pRMGq11CMnDtUStoqLfhG+v566brRTkXUn89I/wxzbnP+M1Lne3y9UgAAACCo5DkpNWHCBN11112aPn26YmNjs1yXmJioTp066d1331XXrl0LY52AX0lNS7e75P2+ZIfGL92hLfuP5Hjbbg3i1ae5l6o+8ql2hVIadkWrbBNp09bs0Wt/rLRtfp9OXa9vZm60t8+NadpNT0tTaFiYTjd+2jzvR3s3VlH6cxmte8iGGeh24VvSwZ3Smj+lrwdIjfpIcz93ru/5vNTxTl+vEgAAAAg6eU5Kvf7667r55ptPSUgZZcqU0a233qphw4aRlEKxYVrbHv9psa0a8lR0RKi61o9XpZMqjczlZjc9f9sFz6ynU70K6li3vP5ZvVuvjV+puRv3a/n2A177Geaxru1YU9XKllRRMLsbmnlaxnmNK+Z+Y5JSwScsQrr8c+nTPs7Oi+6EVO9XpPY3+3p1AAAAQFDKc1JqwYIFeuml43M3stGjRw+98sor3loXUKjS0l16449VHiWkypWKVPfGFXV+k0rqUq+CSkRmHSReHJjklEmmmfWbFkST2MmNqbA6dOiQSpUqlWui7cWxy7VoS6KdZWUGvBeFySt3KTXdpXoVS6tm+dwrvkhKBamo0tKg76WPekj71kl9X3OGoQMAAADw76TUjh07FBGR84yW8PBw7dp16jBlwB9NWrHTttzFlYzQuHu6KSIs/5VMcSUjFRbqXxVQBWUSTM2qljnt7UxSKjExwlZH5paUuqB5JScptXxnkSWl3POkzmt0miqp5CRpz2rnNEmp4FO6onT7VOnQLqksMxIBAACAYpGUqlq1qhYvXqx69eple/3ChQtVubJv5uYA+fXl9A32eECbaqpUpgiHe//xtLT4B+n6X6W46gpU5zSsqJfHrdDUNbuVnJKm6Ii8VZEdSE6xA+NTClDBNmmlkxQ/r/Fp5kntWOwcx1aTSuWyQx8CV2RJKZKEFAAAAFBsklK9e/fW0KFD1atXL0VHZ/0Sf+TIET355JPq27dvYawR8KpNew9nJDCu6lCEX0zX/X1ip69lIwN6sHKjSjGqXCZa2xKT7UD1c05XvXTcoz8t1qgFWwv8c03lW+sap9lNj9Y9AAAAACheSanHH39cI0aMUIMGDewufA0bNrSXL1++XG+//bbS0tL02GOPFeZaAa/4euZGuVxS1/oVTrvbnNekJEujh5w4v2lGQCelTGufSUR9PWOjJq7Ymaek1M4DyRq7aJs9fWadcgrN53B4c/PL21ZXeFho7jckKQUAAAAAxSsplZCQoKlTp+r222/XI488YmfLuL989uzZ0yamzG0Af3Y0NU3DZ22ypwcVZZWUqZAyc4zCIqW0Y9LGGWZAk5NJCVDnNnSSUhOW79TTF7pOuwPh97M320HlptLp21s6Ft7CSEoBAAAAQPFKShk1a9bUr7/+qn379mn16tU2MVW/fn2VLVu28FYIeNG4xdu159AxVYqNtjvnFYldK6S/j7ft9XtTGnmXdHC7tH9jQA9a7lSvvCLDQ7V53xGt3nlQ9RNicrxterpL38zcWPgtlccOS7uWO6dJSgEAAACAT52mzyV7JgnVrl07tW/fnoQUiuWA8yvb1zh9m5c3pKdLo4ZI6SlS/Z5Sy4FSpRbOdZtmKpCVjAzXmXXK29OmWio3f6/ebZNXsdHh6tuiEDdM2LlUcqVLpSpKMZUK7+cAAAAAAE6rCL6VA/5h+fYkzVq/T2GhIRrYvoh2vpv3hbRxqhRRUurzitOuV73DiblSAe7chvH22MyVys03M5wqqUtaV8vzTn0Fsm3+iSqpAG6dBAAAAIDigKQUgsZX053ER48mCUqIzbqDZKE4uFMaP9Q5fc5jUlwN53T19sGTlGrkzJmbvX6fkpJTsr3NzqRkjV+2I6OCrVBtnu0cVz5erQYAAAAAKB4zpYDiYuWOA9qy70jG+XSXSz/N22JPX31mEc1xmvSClJzoVOV0uO3E5e5KqR2LpaMHpajSClQ1ypdU3fhSWrPrkP5euVt9smnNGz57k9LSXWpTs6waVsp57pTHUo9Ky391Ttc5p/B+DgAAAAAgT0hKIeCs2XVQvV6frHRng8gs6lQopU51nTlHhV4lNe8r53TP56WwTP+rlakqlakuJW6StsyR6pylQHZOw4pas2udnSt1clLKGXDu7IZ4VWFXSa0aLx1NlGKqSDU7F+7PAgAAAACcFu17CDjT1+6xCakyJSLUolqZjEPrGnEa2q+JQopiltDM96W0o1LVttknQIKqhc/Z5fCvlTttEiqzyat2act+Z8B5dlVUXrXoe+e4+aVSKC99AAAAAOBrVEoh4CzanGiPB3WooYd6NSr6BZiWvJkfOKc7/yv7gdqmhW/xj0GRlGpbq5xKR4Vr98FjWrQlUS2rx2Vc983MIhpwnpwkrRznnG4+oPB+DgAAAAAgz0hKIeAsOJ6UalHtRPKjSM37UkreL5WrIzXqm/1tMiqlZpketoCu3IkMD1XX+hU0dvF2fTxlnW3nM46lpuuPZc6ufFd1KOTWveVjpNRkqUIDqRJDzgEAAADAH5CUQkBJTkmzQ84N07JX5NJSpWlvO6c73iWF5lD9k9BciijpzDjavUKq2FiBzCSiTFLql/lb7SGztjXLqkFCIQ44z9K6NyD7yjUAAAAAQJEjKYWAsnRbkt3JrULpKFUuE+2DBfwsJW6USlaQWl2V8+3M4POqbaT1fzstfAGelOrXsopmrt+rHUnJWS6PDAvVv86rX/hD59dOck43u7RwfxYAAAAAIM9ISiGgLNy0P6NKqkgGmmfmcklTXndOd7hViiiR++3NXCmblJoptblegaxEZJheGdDSNz98yc+SK81JApav65s1AAAAAABOEbiDbBCUFm5x5kk1r+qD1j1TjbN9kdOW1+6m09/eJKWMIBh27lOZW/cAAAAAAH6DpBQCysLjQ85bVvdBUmrKG87xGddIJcud/vbV2jrHe1ZLh3YX7tqC1d510uaZUkio1PRiX68GAAAAAJAJSSkEjINHU7Vm10F7unnVItp5L/WYtGaiNOYBae1EKSRM6nhn3u5rElcVGjqnTQsfvG/xj85x7W5STCVfrwYAAAAAkAkzpRAwlmxJtGOdqpSJVnxMVOH8EPMD9q51kkirfpdW/yEdTTpxfetrpLI18/54NTo4u++ZFr5GvQtlyUHL/FvRugcAAAAAfoukFAKuda95NS+27iUnSlvmSJtnS5tnOcdH9ma9TamKUsNeUoMLpAY98/f4Zq7U3M8Dq1IqOUkafo1UKl665AOpqAfOu+1YIu1aLoVFSY37+WYNAAAAAIAckZRCwA05b1GtgK176WnSzmUnkk9bZku7VpiSm6y3M0mOyi2lWl2kRn2kKq2l0AJ2wrqHnZuf9ftQqUZH57JS5VVsq5NG3uUMfTe6PSjFH29RzItjh5xkUtW2Bf+dui35yTmuf74U7YMZYwAAAACAXJGUQsBYuHm/PW6R10qptBRp1XhnELZNQs2VUg6deruytaRq7Y4f2koJzaXwSO8sunw9Ka6GtH+jNPVN52BUaOAkp0ySqsaZUrk6vqs4yo/p70hLfzlxfuW4/CWlRt8rLfxOajVIuvAtKTSs4GtZ8atz3OSigj8GAAAAAKDQkJRCQEg8nKINew7b082r5jEp9fvj0ox3s14WGSNVbX0iAWUqdkrHq9CYRNPNE535VBunOwczY2r3Sucw7wvndqYVziSnqp/pJKoqt5DCIuRXzNrHD3VOm9+fqThbMU7qfE/e7n9gx4nB5PO/ktJTpf7vFCwxZeZ+7VzqDJ43lVIAAAAAAL9DUgoBYdHx1r2a5UsqrmRk3mZFzf3ixBDsWl2dRIqp6vGkOqcgSlWQWl3lHIzDe53B5+4k1da50qFd0rJRzsEIL+EkzWp2kjrc5uzk50sHd0nfX+8kkppdKp33pPRGC2nTdOf55GV98z537h9bTTqwzamYMi2VF78nheXzpWr58Sop02JZomzBnhMAAAAAoFCRlEJAWHC8dS/PVVLzv3Fa9eIb+XYYd3ZMAqfhBc7BSEmWts0/kaQyiZ4j+6T1fzuHw3ukPq/6br0mcfTjjU4iybQd9ntTiiotVWwq7Vzi7FDY4vLTP8acz5zT5w2VIkpKP9wgLf7BSVRd+mH+KsOWj3GOzcwvAAAAAIBf8nCSMOAfFh3feS9P86TS06VZHzin29/sXwmp7EREO617XYZIV30rPbhWunOmdM5jzvWm5S31mO/WN/E5ad1kKaKUdPkXTkLKcO9EaOZKnY5pX0zcJJUoJzXpLzW5ULr8cyk0Qlr6s5OgyutzPLTHSdwZDXsX9FkBAAAAAAoZSSkE2JDzPOy8t26StGe1FBUrtRioYsfsSmfaDLveL5VOcKqmTDWSL5iZUX8fr9K68E2pYqMT17krvVb94QyVz82sj5zjMwY5STh3ldPAr6SwSKdt0bQHph49/ZpMEsyVLlVqIcVVL9jzAgAAAAAUOpJSKPZ2HTiqrYnJtuCpWV7a92Yer5JqeeWJqp7iyMy+MvOwDDN/qajtWy/9dItzuv0tUvPLsl5ftY1Usrx0NNFpO8ztcdxJtTY3ZL3OVFsN/EYKi5JWjJG+u8ZpZ8wNrXsAAAAAUCyQlEKxt/j4kPO68aVVOuo0Y9L2bZBWjHVOt7tJxZ57VpN5TmZ4e1FJTZaGX+v8TLNDYY/nsk+a1c9DC9+cTyW5pDrnSOXrnnp9/e5O22J4tLTqN+m7QTknpo4dltZMcE6TlAIAAAAAv0ZSCgEz5LxFXqqkZn90IgES30DFnmlRM8Pa045KS38pup879v+kbQucGVADPpXCc9jx8HRzpUw7nnsXxHaDc/55dc+Vrhru7Dpoqqq+GSilHDn1dmsnSalHpDI1pIRm+X5aAAAAAICiQ1IKATPkvPnphpybJIY7AWLazQKB6Vl0V0stHF4kPzJi6Y8KmWuqm0KcXfFym9tkkklmWLmZ4bV79anXm1lRh3dLMVWkBsdnUOWkzlnS1T84A9XXTpS+vtypjMqpdc/fB9gDAAAAQJA7Ta8T4D+OHEvTmxNW6e9Vu+Rynbh81c6DeRtyvniEdGSvU0XjruAJBM0vl/58Rlr/t7R/U+EO996xRCUnPOqcPvv/pHrn5X776FipVmengslUS1W4K/sB522uk8Ly8HJUq4uTmPpqgLPjn0lMXfmtMxssPU1aebw1sxG77gEAAACAv6NSCsXC9LV71OuNyXpn0hot3pKkJVtPHI6lpiuuZISaVonN+QFMFmvme87pdjc6844ChUlC1ezinF78Q+H9HDM/avi1CklNlqvueVK3h/J2P3cF1MktfJtmSRunSiFhUutr876Omp2kq0dIkTFOIs4kqI4ekDbNkA7vkaLjpBqd8vHEAAAAAAC+QKUUCmz0wq16cexypaSlZ7m8WtmS+vDatipbKoc5Q/lw6GiqXhq3XJ9P22DPV4qN1gM9G6pC6ayP3SAhRtERuSSaNs92ZiCZXdzOyEcCpLgwLXwb/pEWfCd1HuL91jWT1PvlToXsXaP0mCoKueR9KTSPOW1TlTbuYWnDVOnIfsmVLk168fh8r+OtdrFV8reeGh2ka3+WvrjESWx9eakzW8v+vF55q7oCAAAAAPgU39xQYN/O3KTN+04dNr0j6aieHbNMr17e0qPH/2fVbj3840Jt2e/8jCvbV9cjvRsrNjoi/w+28FvnuOnFUqnyCjhNLpJ+fUDatUzasViq1Ny7jz/tbTv/yRUaoUN93lHpkvn4HZar7SSMdi2XRg+R1kyUkp3h9GrYW+rzasHWVK3t8cRUf6dKyhwMWvcAAAAAoFggKYUC25roJItevKR5xpDxTXuP6Pav5ujHuZt1Seuq6lyvQr4fNyk5Rc+PWaZvZ22y56vGldBLl7ZQl/r5fyzLzBpaOtI53XyAAlKJOKdCaNlIaeF33k1KbZgmjX/COd3zeaVVapX/xzDVUiYpteQn57zZGa/nc1Kdsz1bW9XW0rUjncTUkX1OJZxpLQQAAAAA+D1mSqFAXC6Xtu1Ptqc71CmvplXK2EOvZpV07Zk17eWP/rRIySlp+Xrcict3qsewyRkJqWs71tTv93YreELK2DhNOrTTmTVkdnALVC2ucI4X/eAk4rzh4E7p++slV5rU7DKp3U0FexyTDAyLlErFS/3ekG6d7HlCyq1KK+m6UU411pm3O0PPAQAAAAB+j0opFEjikRQdOZ5wqlwmOst1D/ZqpN+X7tCGPYf1xp+r9HCv47N+crH/8DE9M3qpRszdYs/XLF9SL1/awia8POauzmnUVworQOtfcVH/fCfxdmCb9P110tmPSglNCv54aanSDzdKB7dLFRo6yaSCzqoylVtDFju78UWUKPiacnv8O4+37wEAAAAAigUqpVAgW49XSZUrFXnKgPHSUeF65qJm9vT7k9dq2bakXB/rtyXbdf5rk21CyuQ8bupSW+Pu6eadhFTm1j0zTyqQhUdJZx3fEW/ZKOmdjna3PO1YUrDHm/ics7tdRCnpii88r0CKSSichBQAAAAAoFgiKYUC2XZ8ntTJVVJu5zdJUO/mlZSW7tL/jVhkj0+25+BR3fX1XN36xRztOnBUdeNL6cfbO+nxvk1UIjKXnfTyw+z4Fgyte24d75Rum+IMPjeW/iK900n67hpp++K8P87yX6V/hjmnL3pLim9YOOsFAAAAAAQt2vdQIFsTnUqpymVyrnx5ql9T/b1qtxZs2q+Xxi1X6xplM67bdfCoXhu/UnsPHVNYaIhu7VZH/zqv/ilVVx5b+rNz3DjAW/cyq9RMuvxzp0Lqr5edxJQZgG4OjftJZz2c+yD0veukn25zTne4TWp2aZEtHQAAAAAQPEhKoUC27XcqparEZV8pZVSMjdb/XdBIj/202LbxZadRpRj957KWGbv3eVXm1r0mAd66l52EptLln0k7lznJKTNby7T1mYOZr2WSU5VbZL1PSrLT8nc0UarWXjr/375aPQAAAAAgwJGUQoFsy0OllHFluxpateOgFm9JzHK5mR11dsOKurlrHUWGF1IXabC17uWkYmNpwCdOEmryy9LiEdLy0c6hYR/pbJOcauncduyD0vaFUsny0oBPpfBIX68eAAAAABCgSEqhQLbmoVLKCA0N0VMXNpVPuHfdC6bWvdxUbCRd9rGTnDKVU4t/lFaMcQ4NezuJqbmfm5ShdOmHUpmqvl4xAAAAACCAMegchVop5TOmdc/MUArW1r3cmKHll30k3TlTan65FBIqrfhVmvSCc/05j0p1z/X1KgEAAAAAAY6kFPItPd2l7RlJqdwrpXxmwxTp0C5a93IT30C69AMnOdXiCic5ZWZNdX3A1ysDAAAAAAQB2veQb3sOHdOxtHQ7F6qSvyallgThrnsFVaG+dMn7Up9hUmQpZ+AXAAAAAACFjKQU8m1bojNPKr50lCLC/LDYjta9gokq7esVAAAAAACCiB9mFODvtu4/3roX56fzpDbPpnUPAAAAAAA/R1IKBa6UquKvrXubZznHNTvTugcAAAAAgJ8iKYXA23lvy2znuGprX68EAAAAAADkgKQU8m3r/uOVUnH+Wik1xzmu1tbXKwEAAAAAADkgKYXAqpQ6uFNK3CgpRKpyhq9XAwAAAAAAikNSasSIEerRo4fKly+vkJAQzZ8//5TbJCcn684777S3KV26tC699FLt2LEj4/q9e/eqX79+9rozzjhD8+bNy3J/c99XX321SJ5PoNp2vFKqsj9WSm05XiVVoYEUXcbXqwEAAAAAAMUhKXXo0CF16dJFL730Uo63uffeezVq1Ch9//33+uuvv7R161ZdcsklGdc/99xzOnDggObOnauzzz5bN998c8Z106dP14wZMzRkyJBCfy6BKi3dpR0HjtrTVfyxUsrsvGfQugcAAAAAgF8Llx+55ppr7PH69euzvT4xMVEfffSRvv76a5177rn2sk8++USNGze2CaczzzxTy5Yt08CBA9WgQQPdcsstev/99+3tUlJSdNttt+nDDz9UWFhYET6rwLLzQLJNTIWHhig+Jkp+WylVtY2vVwIAAAAAAIpLpdTpzJkzxyaXunfvnnFZo0aNVKNGDU2bNs2eb9mypSZMmKDU1FT99ttvatGihb385ZdftpVTbdtSQeOJrfudeVIJsdEKCw2RX0lPl7bMdU6TlAIAAAAAwK/5VaXU6Wzfvl2RkZGKi4vLcnlCQoK9zvi///s/3X777apbt65q1aplK6tWrVqlzz77zCauTLXU77//bpNTH3zwgcqUyX7u0NGjR+3BLSkpyR67XC57KA7ca/Xmet0771UuE+1/v4c9qxRyNFGu8GipYhPzC/D1igJOYcQUggsxBG8jpuAJ4gfeRkzB24gpFNe4yOvafJaU+uqrr3TrrbdmnB87dqy6du3q8eOaJJNp78vMtPr95z//sT9z7dq1WrFihZ019cwzz+Q49PyFF17Q008/nW0LoT//w2dm1nnw4EF72gyO94Z12/fZ4wolw+zvwp9ErPpHpczcq4rNdPDgYV8vJyAVRkwhuBBD8DZiCp4gfuBtxBS8jZhCcY0Ld2GP3yalLrzwQnXo0CHjfNWqVU97n0qVKunYsWPav39/lmops/ueuS47ZuaUue1FF11kB6L3799fERERGjBggJ544okcf9Yjjzyi++67L8svtHr16jbpFRsbq+LAnTwza/ZWoO47usUe14iPzbHKzGf2LrVHYTXa+9/aAkRhxBSCCzEEbyOm4AniB95GTMHbiCkU17jI67p8lpSKiYmxh/xo06aNTSj9+eefuvTSS+1lpupp48aN6tix4ym337Vrl62G+ueff+z5tLQ0O5PKMMfmfE6ioqLsIbtfrL/+o2fHvV5vrXlbojNTqkqZaP/7PWxxdt4LMTvv+dvaAoi3YwrBhxiCtxFT8ATxA28jpuBtxBSKY1z4fVIqO3v37rUJpq1bt2YknAxTBWUOJgs4ePBgW8FUrlw5W7F0991324SU2XnvZEOGDNH999+fUYXVuXNnffHFF+rRo4fdlc+cR/5sSzw+UyquhPxKSrK0Y7FzuirD7AEAAAAA8Hd+tfveyJEjdcYZZ6hPnz72/MCBA+35d999N+M2r732mvr27Wsrpbp162aTVSNGjDjlsczOe6tXr9Ydd9yRcdldd92lOnXq2LZB0wb45JNPFtEzCxxbMyql/CwptX2hlJ4qlYqX4mr4ejUAAAAAAKA4VUpdf/319pCb6Ohovf322/aQm549e9pDZiVLltTw4cO9stZgdCw1XbsPOjsSVo6Lll/Z7LTuqWobWvcAAAAAACgG/KpSCv5tR1KyzDy1yPBQlS8VKb+yZY5zTOseAAAAAADFAkkp5HvIeWU/HnKuam18vRIAAAAAAJAHJKWQ/yHnZfysde/QHmnfeud0lda+Xg0AAAAAAMgDklLIs637/XTIubt1r3x9qUScr1cDAAAAAACK26BzFJNKKV8NOU9PlxZ8Le1cJtXvIdXqIoWGZWrdY54UAAAAAADFBUkp5LtSqrIvKqVMImrUPdKmGc75af+VYqpIzS+TNkw5sfMeAAAAAAAoFkhKId+VUlWKslIqJVn6+xXpn9el9BQpsrTUoKe0+k/pwFZp6psnbktSCgAAAACAYoOkFAqw+14RVUqtmyyNGiLtXeOcb9hb6v0fqUw1KfWotGq8tPA7aeU4qUx1KaFZ0awLAAAAAAB4jKQU8iQ5JU17Dx0rmkHnh/dKvw+V5n/pnC9dyUlGNe4nhYQ4l4VHSY37Oodjh6XQcCk8snDXBQAAAAAAvIakFPJVJVUyMkyxJQopbFwuadH30rj/kw7vkRQitRssnfeEFF0m5/tFliyc9QAAAAAAgEJDUgp5sm3/8Z33ykQrxF2t5E1710lj7pPWTHDOxzeW+r0h1ejg/Z8FAAAAAAB8jqRUMElL1R9jf1SZfQu1oOYNUkhonu+6ZGuSPa4S5+XWvbQUadrb0qQXpdQjUliUdNaDUqd7aMcDAAAAACCAkZQKMp1n360SOqpHltbQale1fN+/WtnTtMod2CEd3i0lND39g22ZI428R9qxyDlfq6vU93WpQr18rwsAAAAAABQvJKWCSVi4tpduotoH52lwrd2aGZe/1rjoiFDd0q1O7jf65gpp63xp0A9S/e7Z3yYtVRr/hDTjHcmVLpUoK/V4Tmp11YlB5gAAAAAAIKCRlAoytVueJU2Zpysrb9eVF7by7oMnJ0lb5zmnR/1LumNa9gPKJz4nTX/bOd38cqnn81LpeO+uBQAAAAAA+LW8DxVCYKje3jnePNv7j71jyYnTSVuk3x479Tar/5D+Geac7v+udOkHJKQAAAAAAAhCJKWCTdW2zvHOZU5lkzdtX+gcl60lKUSa94WThHJL2iqNuMU53Xaw1OpK7/58AAAAAABQbJCUCjYxCVJcDUkuaevcwklKmZa8Drc6p0f+S0pOdOZI/XiTdHiPVKm507IHAAAAAACCFjOlglG1dtL+jdLmWVKds733uNuOJ6VM0qneedLK36R966TfH5dKJ0gbpkiRpaUBn0kR0d77uQAAAAAAoNihUioYVTs+V2rTLO89Zuoxaddy53TlFlJkKemi48PM534uTX7FOd3vDal8Xe/9XAAAAAAAUCyRlArWSinDVEq5XN55zN0rpLRjUlQZKa6mc1mtzlKH247fwCW1uV5qfpl3fh4AAAAAACjWaN8LRqa9LixKOrJX2rvWO5VL2xedeOyQkBOXn/eEtG2BFBYh9XrR858DAAAAAAACAkmpYBQeKVVuKW2eKW2e7Z2klHuelGndy8y08d04zvPHBwAAAAAAAYX2PQV7C99M7zxe5kopAAAAAACA0yApFayqZ5or5SkzlyojKXVSpRQAAAAAAEA2SEoFe6XU9sXSscOePda+9dLRRCksUopv6JXlAQAAAACAwEZSKljFVpViKkuuNGnbfM8ey10lVbGxM9AcAAAAAADgNEhKBSuzQ161tt5p4dt+fMg586QAAAAAAEAekZQKZu4Wvk0eDjvPmCfV0vM1AQAAAACAoEBSKphVa3+iUsoMKy+obccrpSoz5BwAAAAAAOQNSalgVrmlFBouHdwhJW4u2GMc2i0d2Gr6AaWEpt5eIQAAAAAACFAkpYJZZEkpoZlnc6Xc86TK1ZGiYry3NgAAAAAAENBISgU791ypzbM9nCfFkHMAAAAAAJB3JKWCXXX3XKkCDjtnnhQAAAAAACgAklLBrlpb53jbAin1qAeVUiSlAAAAAABA3pGUCnZla0sly0tpx04kmPLq2GFpzyrnNEkpAAAAAACQDySlgl1ISKa5Uvkcdr5jieRKl0pVlGISCmV5AAAAAAAgMJGUwokWvvwmpdw77zFPCgAAAAAA5BNJKUjVjg8735TfpBTzpAAAAAAAQMGQlIJUtbXp45MSN0oHtuf9fntWO8fxjQptaQAAAAAAIDCRlIIUFSNVbOKc3jw77/fbv9E5jqtROOsCAAAAAAABi6QUCjZXKj1NStrinCYpBQAAAAAA8omkFBzV2+cvKXVgm5SeKoWGSzGVCnVpAAAAAAAg8JCUgqNaO+d4y1wpLfX0t9+/yTmOrSqFhhXu2gAAAAAAQMAhKQVH+fpSVBkp9Yi0c8npb888KQAAAAAA4AGSUnCEhkrV2uS9hc/s1GeQlAIAAAAAAAVAUgqntvDlZQc+d/temeqFuyYAAAAAABCQSErhhGrHh51vmnn629K+BwAAAAAAPEBSCidUbe0c710jHd6b+20Tj1dKxVEpBQAAAAAA8o+kFE4oWc4ZeH66Fj6XS0rc7JymfQ8AAAAAABQASSnkMFcql2HnB3dKqclSSKgUW7XIlgYAAAAAAAIHSSlkVT0PSSl3615MZSk8smjWBQAAAAAAAgpJKWRfKbVljpSenvuQc1r3AAAAAABAAZGUQlbxjaWIUtLRJGn3iuxvw857AAAAAADAQySlkFVY+Ild+HJq4WPnPQAAAAAA4CGSUjhVtba5J6X2H09K0b4HAAAAAAAKiKQUTlWtvXO8eXb219O+BwAAAAAAPERSCjlXSu1cJiUnZr3O5crUvkdSCgAAAAAAFAxJKZyqdEUprqbJQElb5ma97sg+6dhB53SZaj5ZHgAAAAAAKP5ISiF71dpl38Lnbt0rFS9FlCj6dQEAAAAAgIBAUgrZq94++2HntO4BAAAAAAAvICmF0+/AZ+ZIubHzHgAAAAAA8AKSUsheQnMpLEo6slfauzabnfdISgEAAAAAgIIjKYXshUdKVVqd2sKX0b5nBqEDAAAAAAAUDEkp5GHY+axTK6Vo3wMAAAAAAB4gKYWCJaVo3wMAAAAAAB4I9+TOCJKk1PbF0rFDkitdSt7vXEalFAAAAAAA8ACVUshZmapSTBXJlSZtnX9i573oOCk61terAwAAAAAAxRhJKeSuWtsTLXy07gEAAAAAAC8hKYXcVW9/IinFznsAAAAAAMBLSEoh78PO929wTjNPCgAAAAAAeIikFHJXuaUUGi4d3CFtmOZcRvseAAAAAADwEEkp5C6ihFSpuXN6y2znOK6GT5cEAAAAAACKP5JSyHsLnxvtewAAAAAAwEMkpXB61Y4PO3ejUgoAAAAAAHiIpBROr1rbE6cjS0slyvpyNQAAAAAAIACQlMLpla0llaxwonUvJMTXKwIAAAAAAMUcSSmcnklCuedKsfMeAAAAAADwApJSyJs6ZznHCU19vRIAAAAAABAAwn29ABQTbQdL5etLNTv6eiUAAAAAACAAkJRC3oRHSvW7+3oVAAAAAAAgQNC+BwAAAAAAgCJHUgoAAAAAAABFjqQUAAAAAAAAihxJKQAAAAAAABQ5klIAAAAAAAAociSlAAAAAAAAUORISgEAAAAAACB4k1IpKSl6+OGH1bx5c5UqVUpVqlTRtddeq61bt2a53d69ezVo0CDFxsYqLi5OgwcP1sGDBzOuX79+vbp162Yfwxyb85n17dtXP/74Y5E9LwAAAAAAAPhxUurw4cOaO3euhg4dao9HjBihFStW6MILL8xyO5OQWrJkicaPH6/Ro0dr8uTJuuWWWzKuv//++1W1alXNnz9flStX1gMPPJBx3XfffafQ0FBdeumlRfrcAAAAAAAAkFW4/ESZMmVsoimz//73v2rfvr02btyoGjVqaNmyZRo3bpxmzZqltm3b2tu89dZb6t27t1555RVbXWVuM2zYMNWvX1/XX399RlJq//79evzxxzVhwgSfPD8AAAAAAAD4YaVUdhITExUSEmLb9Ixp06bZ0+6ElNG9e3db/TRjxgx7vmXLlvrjjz+Unp6u33//XS1atLCXP/jgg7rzzjtVvXp1Hz0bAAAAAAAA+F2l1MmSk5PtjKkrr7zSzo8ytm/frooVK2a5XXh4uMqVK2evM0zF1K233qpatWrZhNR7771nW/xMO99LL72kyy+/XLNnz1aPHj305ptvKjIyMtuff/ToUXtwS0pKsscul8seigP3WovLeuH/iCl4ihiCtxFT8ATxA28jpuBtxBSKa1zkdW0+S0p99dVXNnnkNnbsWHXt2jVj6LlJHpkn8c477+Trcc08KTNrys0klnr27KnPPvtMzz77rGJiYuysql69etmE1d13353t47zwwgt6+umns63e8ud/+MzMOt1D4E3FGeApYgqeIobgbcQUPEH8wNuIKXgbMYXiGhfuwh6/TUqZAeYdOnTIkkzKnJDasGGDnf/krpIyKlWqpJ07d2Z5nNTUVLsjn7kuO88//7ytimrTpo1uvvlmm5iKiIjQJZdcYh8/p6TUI488ovvuuy/LL9S0/pnZV5nX5M/cyTOzZn8NVBQvxBQ8RQzB24gpeIL4gbcRU/A2YgrFNS7yui6fJaVMxZI5ZOZOSK1atUoTJ05U+fLls1zfsWNHO7B8zpw5NslkmMSSmR+VOcHlZoaef/3117Z1z0hLS7M/w/2zzPmcREVF2UN2v1h//UfPjnu9xWnN8G/EFDxFDMHbiCl4gviBtxFT8DZiCsUxLvK6Lr8ZdG6SRJdddpmd92Ra+0zCyMyJModjx47Z2zRu3Ni23ZmKp5kzZ2rKlCm66667NHDgQLvz3smZw1tuuUWvvfaaSpUqZS/r3LmzPvjgA5us+vzzz+15AAAAAAAAFD2/SUpt2bJFI0eO1ObNm9WqVStVrlw54zB16tSM25mEVaNGjXTeeeepd+/e6tKli95///1THs9clpCQoL59+2Zc9tRTT9kB6qaqql69enY3PgAAAAAAABS9EFdxmdrtY2amlOnXNIPOi9NMKbNef+4zRfFCTMFTxBC8jZiCJ4gfeBsxBW8jplBc4yKvORS/qZQCAAAAAABA8PDZoPPixl1QltdtDf1lzWa9/jz8DMULMQVPEUPwNmIKniB+4G3EFLyNmEJxjQt37uR0zXkkpfLowIED9rh69eq+XgoAAAAAAECxyKWYNr6cMFMqj9LT07V161bFxMT4bSYyu8ykSaJt2rSp2MzBgn8jpuApYgjeRkzBE8QPvI2YgrcRUyiucWFSTSYhVaVKFYWG5jw5ikqpPDK/xGrVqqk4MkHqr4GK4omYgqeIIXgbMQVPED/wNmIK3kZMoTjGRW4VUm4MOgcAAAAAAECRIykFAAAAAACAIkdSKoBFRUXpySeftMeANxBT8BQxBG8jpuAJ4gfeRkzB24gpBHpcMOgcAAAAAAAARY5KKQAAAAAAABQ5klIAAAAAAAAociSlAAAAAAAAUORISgEAAAAAAKDIkZQCAAAAAABAkSMpVUwdPHhQiYmJ9jQbKMIbiCl4gviBtyUlJWnHjh32dHp6uq+Xg2KG1yR4GzEFbzty5IiOHj3q62XADx0JstggKVUMPfXUU2rWrJl++uknez4kJMTXS0IxR0zBE8QPvO3ZZ59VvXr19N///teeDw3l4wryjtckeBsxBW8bOnSo2rZtqxkzZvh6KfAzQ4MwNviUV4zs3btXN910k0aNGmXP//rrr1q1apU9zV9sUBDEFDxB/KAwKhHuuOMO/fzzz6pVq5Zmz56tKVOm2OuIKZwOr0nwNmIK3rZ9+3Zde+21GjNmjNavX69PP/00owIPwW17EMdGuK8XgNyZNzz3X2NSU1NVuXJlXXzxxSpRooSuueYa/fbbb/aDe0REhK+XimKCmIIniB8UZkxFRUWpRo0a6tatm2rXrq277rrLVia0bt3axljm2wIGr0nwNmIKhckkGeLj4/XGG2/Y0xdddJEuueQS9e3b19dLg48lBnFshLhI8/utY8eO2TdG8yHd/cZo/mJTsWJFe/6GG27QypUr9frrr6tdu3Y+Xi2KA2IKniB+4G3JyclKSUlRTEyMPW/i68CBA4qNjbXnn3jiCY0fP14PPfSQ/VIIZMZrEryNmIK3mRgyLejuNnTzvrdz5077Bxjj/PPPt5d99913qlKlio9Xi6JEbJxA+54f96536dLFZkjff/99+4YYHh5u3xTdA1/NzI0tW7bYNof9+/fby8gxIifEFDxB/MDbnnzySVsB1atXLz322GPatm2brU4wCSl3TJlKKfPl8JdfftHWrVvtZcQUDF6T4G3EFLztmWeeUY8ePXTllVdq7NixtkU9OjraJh3cMWVizbSpm/c580caBAdiIyuSUn6YMTW9pF999ZX9MF6uXDm9+eab9jI3k01NS0tT1apVbZ/7iBEjNH36dHud+UDPmyMyI6bgCeIHheHuu+/W119/bT+UnXnmmXZ+gvkiaD6UZY4p82Xw6quv1qJFizRy5Eh7HTEV3HhNgrcRUyiMndNMde+XX35pj3ft2qUHH3xQDzzwwCkxZVrV77zzTr300ktas2aNT9eNwkds5MC078F/rF271tWoUSPXyJEjMy77/fffXSVKlHANGzYs47K0tDR7nJ6e7mrZsqVr8ODB9r4///yz66233vLJ2uGfiCl4gviBN5n42LVrl6tVq1au9957L+PyVatWucqXL++69957XYcOHcoSU8bFF1/s6t+/v2vu3LmuH374wfX444/7ZP3wPV6T4G3EFLzNvFfVr1/fNW3atIzL3n33XVepUqVc3333nT2fmpqaJabKlCnjevjhh1379u1zjRo1KuN2CCzERvZISvmZFStWuEJCQlwbNmzIcvnzzz/viouLy3K5CVhj+PDhrvj4eFeNGjVc4eHhrjfffLPI1w3/RUzBE8QPvG379u2u0NBQ+8HMSElJscdffPGFKzIy0vXXX39l3Nb9oWz8+PGuevXq2cRVRESE65lnnvHR6uFrvCbB24gpeNs///zjioqKsn+Ecdu/f7/rjjvucCUkJGRcZhIO7pgyf6gx74GNGze2MfX555/7ZO0oXMRG9mjf8zOmVK9ly5Z2oFlmpnTPlBObafzu24WFhWnDhg2aMGGCdu/erfPOO087duywbRGAGzEFTxA/8DYzI8oMCP7kk0/seRM3hmnTa968ud5991173sxUMCXsJqa+//57W7p+4YUX2i2Thw4d6tPnAN/hNQneRkzB28xw6kaNGumPP/7IuKxMmTK644477OmXX37ZHpsCEXdMLViwwM4NMi3t5n3O7PSIwENsZI+klJ8xw80aNmyoGTNmaP369RkfzM3g19tvv10//PCDDWb3h3jzRmmGLZrbf/zxx/bNE8HldHMMiCnkhvhBUStZsqTOOusszZo1S4sXL7bzWMyOV8bDDz9s4ycpKSljN5ovvvhCP/30EzEVJHhNQlEjpuDt16m2bdvaodVTp061yUu3mjVrauDAgRo1apSOHj1q3+cOHz5sh+ybYdbumCpfvnwRPAv4ArGRPZJSRchkNmfPnm137chuyKJRqlQp9e/fX6tWrdLw4cPtZe4P5iaLat4gzVaRbmZIrNmxiG1pg9O+ffsyBgMb7t0aDGIKp2PeDM2ARfPXX4P4gafccZM5lk6+LjIy0u64Z+Lo7bffzrjMiImJscPNV69enXG/xx9/3MYYMRX4EhMT7Xua+wsfr0nwlDuG3O9zmRFTKIgDBw5k2Qktu9cpEzdmV7Vff/3VVtW5lS5d2r7Pmdc4923NH2peeOEFbd68mZgq5syOnaZy0v2HtsyvO8RG7khKFZF//etfti3B7Nhhjt0le+4PXmbLWRO4ZucPkyXt1KmT/cvw6NGjs3yBjIuLszt/ZA5gBCdTKm5eoPr162fLOM0HJPeHKIOYQm5MW4J5LTLb0fbs2dMmAYgfeOKee+5Rnz597OnMsZT5fc58eH/rrbd0zjnn2N32Jk6caP/y52bK1E3VQZMmTXzwDOArJkaGDBliK+hMwtLsema++Jk4cn/54zUJ+XXffffZtmDDXeVk8NkbBWHi5t5777WfmXr37q0nnnjC7qSW3evUuHHj7Hti3bp19emnn2bs1GiY6heTmChRokTGZZUqVfLJc4L3YsN81+/YsaMdM3DBBRdo//799nWH2MijHGZNwUuOHDniuuKKK1ydOnVyzZw507V8+XK7i1CbNm2y3O799993VaxY0dWjRw/XsWPHXMuWLXPdeOONdpjZ7bff7rrrrrvs5H337h5m+BmC04EDB1x9+/Z1de7c2Q4E/vDDD218nXHGGa7Fixdn3M4MxSOmkJ3777/fxsukSZPssMQuXbq4mjdv7po8eXLGbYgf5NXSpUtdvXv3tgN/zbDgL7/88pTd84wPPvjADvFs166dKzEx0bVt2zbX0KFD7X3M++Itt9ziiomJcT377LP2vsRUcDA7EJmdzM4880zXmDFjXE8//bTdCc18dsqMz0nIK7OJQvfu3e0gcrOpwrhx47JsquBGTCGvzOftJk2a2NepH3/80XXzzTfb8/fcc0+W25nPThUqVHANHDjQnp86dar9zG4uM69t9913nx2ebzb2QGAYPXq0fc/q2LGj3bXTfC8zsXH11VdnuR2xkTuSUoVs4cKFroYNG9qAdTM7dpx77rkZb46fffaZq1q1aq6PPvrolDfMV155xX5Q79mzp+vPP/8s8vXD//z999/2xW7+/PkZl23ZssXuSGXeJHfs2GHfMKtWrUpMIQvzgfrQoUM2KfDUU09lXH748GGbpBo0aJDdZeinn35yValShfhBnpjXG7M1+oQJE1xDhgxxVapUyX7By8xsYWxizHxYc+8m42YSow899JDrkksuIaaCjIkF829/5ZVX2j+4uJntrmvXrm13anTHSPXq1XlNQp6YL3/XXXedTXKaL4bNmjU75Tbmix8xhbwwn5tMgtK8z5nPS+7Xrpdeesl19tln253TDLMDY3R0tOvjjz/OElN79uyxr3Mm0d61a1diKsA88MAD9nD06NGMy+688077GuL22muvERunEWL+k9eqKuSfmZZ/xhln6Pfff1f37t3trASzU0fjxo3tBP3BgwcrIiJChw4dsj3tbuafxQx/BU5mSstNu17mWVImzkw5sek9fumllzRgwAB7feYSc2IKhplpZ4Ysvv/++7b10/S9m3k+Znezp59+2raF3nrrrbwm4bTcu+O5ZyiY9zUzJLhz5862/crMQXDvVmWcHFPu+yO4/fbbb7ZVoVu3bhmXffbZZ3YHItPWYGZsGKadz33a4DUJOTGvR2YGlGlRnzRpkq666io9+OCDtvXKtNKYz90GMYW8zrozw6fNMHwzNsP93vXcc89lbMJh3udM/JjbmnbP7GSOPQQOM5vVfL6pVatWxuuP+XxtRhSYlvQuXbrY2DAbuJjWvOykEBvMlPIm8wHcvOG99957GQPOzBazpu/YzJIyszbKli1r3wDNsZmmf+mll9rh5+aDeub8IG+KyCmmzFwDczC97G4mwWA+dJmklNkRxsj85c8gpoLPiBEj7Jugm3mNMbFTu3Ztffvtt/Yyd1LAJDLr1atnBy+aD/PED04XU+7YMTOgTELKqF69uh555BG9+uqr2rhxo/2g7h4Ce3JMkZAKPie/JhnmDyruhJR7KOyePXvs5yTzhxX3Z6PMyQOD1yTk9DkpISHBJqSMVq1a6brrrtOLL75ok1Dmi587zogp5CWmTCLBzCZzD5p2vyaZ1zLzecqdkDLxk1NCygj2pEOgvt7Ex8dnJKQ++ugjVatWzcaEmR9tNlB44IEH7OyxnBJSRgSxwUwpbzBzokw7lZnJYsrvypYta8s5p0yZkjFXavXq1a5zzjknS8vMypUrXXXr1rXte8DpYqpbt26uefPm2Vkrb7zxhp3DYmZJxcbGuurVq+dKSkqy5ejmtghuEydOtG3DJkZMG4Obex6GaVcw7Z7mNcj9GmWYXnhTXrx58+Ystwdyiqns7Nq1y9W2bVtX//79i2x9CIz4cc8hu+iii1wPP/ywPc3rEPLz2Xv69OmnxI357GRa+NztNCfPuwNyiykz9y5z3LiPzXXDhg2zp3mdCu7XGzfzPcy04LnjYeTIkXZGnZlXZxAnOePPlF4wZswYm/2cO3eurT5YunSp9u3bpzfeeMPuaBUdHa3k5GTbNnPDDTfY+5i/HNevX99O2V+zZo2vnwKKQUyZkuDnn3/e7k5ldngwu1YNGjRIX3/9td3G2PzFz/zVpk6dOvavzAhOy5Yt07vvvmvbhW+++WZbXm52Zsz8V2Cz81mHDh1022232fPmNcowf+mJiorSihUrstwewS23mMpOhQoV9OSTT+qXX37R5MmT7WWmhX3lypVFuGoUx/gx1XPmL8rz5s3T+eefn/E6ZB4DyMtn72HDhtnP1SZu3Nuqm0pO8373zTff2NuZODNtfWZ3LOB0MfXaa6/ZmDJx427dMy1aS5YsyajyNPHm/j7nrsRD8LzeuJnvZeeee27G5+cWLVrYeDG3N/hcnTOSUh4yb3jmRalixYoZczPM1o2PPfaYbV0wZXxGbGys1q1bp7Vr19rzJkDNh3RzW1O6DuQ1pkyrnmH6lO+4446MLdjNm+CUKVPsC2D58uV9+hzgO6aVynyZu/POO/XKK6/YuDCtVJmZ5NOjjz5q4+U///mP7Yc3zId0kyx3l6gDeY2pk5nZiVdccYVtmzHzE00JO18Ag1N+4+fvv/+2n5E6depkP8ibJHqbNm20ffv2Il03iv9nb7MFu2mrMn9sMaM0zGwX86XRHJvPTiaxAOQnptxt56Y1y/wBxrw2mdeps88+237+Nkl19/0RXLGRXdLJjFTp2LGj/UyE3JGU8pB5wzt69Kh9ETLZc3d23MxnMS9UZvjdwoULVblyZTuc2iSgbrnlFjvg/LLLLrN/OTQVC0BeYsoMqJ45c6b9K7KbqZIyWXrzgf+ff/6xcWawh0FwMrM0TEWm+cuwqZ7797//rf/+9792GH7mN80LLrjAXm6+HJoEp4kvM+TcJA8yz3EB8hJTJzOVwaZi01R2mtku5stf+/bti3TdKF7x437NWbRokf3Ab+Ymmi95VapUsfFjLgPy+tnb/TnJHVfmi6XZlMHEXaNGjWyS0wyuBvIbU4ZJRJk/4pkZiuZ1yswRMhWgZtMGBHdsbNq0yRaimM/UZpbdwIEDbZUVn6tPI5fWPpyGe1trMyshNDTU9qwb7q0eJ02aZGdGff/99/Z8cnKy69FHH3XdeOONrquuusq1YMECH64exTWmzPyo4cOHZ9znf//7n6tBgwauDh06uBYuXOijlcPfZO5bN7Fx4YUXnrLttWFm35ltjIcMGeKaP39+Ea8SgRhTZvZCu3btXE2bNnUtXry4iFeJ4h4/Zv6mmT1ltseeM2dOEa8Sgfg5adasWfZzUqtWrVxLlizx0coRSDFlZpS5Z7vyOhW48hsbq1atcj3yyCOuGjVq2Njgu37ehZj/nC5xFczMX3lNqZ7JgGfe2tr9VxeTPTXzonr16mUn548fPz7LlrJmNyuzNXbmndJOfhwEF2/ElGmJGTp0qD1v/vJn2kJNFRUCX17ix80dN6YdxpSWmzJis02tuZ+JG7NjCOCtmDLzFUw7g5l/t379erv7LAKft1+TzJxEU6154YUX+ugZwdcWL15sX0+6du16ynUF+ZxkqjaXL1+uzp07F/lzQeDElPv7nNnF0YzSMJV2ffv29cGzgb/GhrmdmTtl7ueeN4a8oX0vF2ZIq9nq05TfGe4PWu6yPROk5rT5AP7000/rr7/+ssM83Xk+E+BmC+yT5/uQkApe3oopM6PDzZwmIRUc8hI/5o3QPSfD/YZp3mivvPJKG1N//vmnnaXx5ptvKiUlxWfPBYEXU2ZzD1PibsrUSUgFB2+/JpnbXnXVVSSkgpTZYv2mm26y7VATJkzIcl1BPyeZy83ncBJSwcmbMeX+PmfakO+//34SUsVcYcSG2TjIzEMkIZV/JKVyYWb3mHlPZojZjz/+aC/L/FdA8wGqZMmSGjdunJ3JYnYbModbb73V/hXQzE0w2XSGm8GNmEJhx4+pMBg7duwpvetm5pj56417R6v77rvP/sUHwc3bMWUGCiN4eDt+MldVIbiYOWMmkWR2WjTzWcxnn8wK+jmJ3a6CV2HFFIo/YsMP5aPVL2ikpaXZ4zvvvNN19913uwYPHmxnGxw7dsxevn//ftegQYNcVapUcX322WdZ5iSY2Szmts2bN3e1bNnSNWPGDJ89D/gPYgpFFT+ff/55lvgx/fAmpiIiIuwcl7lz5/rsecB/EFPwBPEDbzJz6KKjo12XX355xmWrV6927dq1y3X06FF7/tChQ66BAwfyOQl5QkwhJ8SGfyIplQMTfD179nRNnz7dNXr0aFeTJk1cb7zxRsaHLTM0MSkp6ZQPaO7Ta9eu9cm64b+IKRRl/LiZN9bXX3/d9d577/lg1fBnxBQ8QfzAW8xGQE899ZT9Arhs2TL7ZbBhw4au+vXruy644ALXhAkT7O3Ml7/ExMSM+/E5CTkhppATYsM/Bf2g8x9++EFxcXFq2rSpKleunKX03Mw4+L//+z81adJEr7/+ukaOHKlmzZrZ7a1NmXlkZKSvlw8/REzBE8QPvI2YgieIHxRFTJmB+T169NCqVat0ww032O3WzfD7jz/+2B6/9957ateund2SPTSU6SPIiphCToiNYsIVpEw5ecWKFV3t27d3xcfHuzp37uz66aefMq7fu3evq1KlShllfPfee68t9StRooRr9uzZPlw5/BUxBU8QP/A2YgqeIH5QFDH1448/2utMHP3yyy+uf//731mqE2bOnOk699xzbasocDJiCjkhNoqXoEv9mZ1dzA5BL7zwgp5//nk7pMxsSVy3bl27vafZOcg4cuSIHWg2YsQIO5X/iy++UPfu3VWzZs2MYZ3uyfwIbsQUPEH8wNuIKXiC+EFRxtSHH35ot1E3VXXnnHOOhgwZotjY2Iz7mmoFE0fmNoAbMYWcEBvFU9AlpQ4dOqRdu3bpuuuus+V6JijN1o2m9DwpKSlji3QTkMOHD9e1115rt3U05X0vvfSSatWqpXvvvTfLZH4EN2IKniB+4G3EFDxB/KCoY8p8iTRiYmLsbo2Z7dmzx+5uZb5QAm7EFHJCbBRPQbH3rvmgVK9ePbstbJkyZXTZZZfZeQemR9TdK1q9enUbxO75B+b8N998o9q1a6t9+/b2MtOP2r9/fxus7r8CstVscCKm4AniB95GTMETxA/8IaYyM5UK+/bt0+OPP25jydwfwY2YQk6IjeIvoAedm7/gPfzww4qKirIBesstt2jw4MEZ12ceXjZo0CAbpJ988on9K2BERESWxzK/JhPo7uGeCE7EFDxB/MDbiCl4gviBv8RU5rgxjzFx4kR9//339ovlRx99pDp16vjsOcG3iCnkhNgIHAFbKTV+/HgbpA8++KAtwfv99991++232+C85pprFB0dbT88mQ9RZj7C4sWL7W2NzB+03EHr/ksfH7SCFzEFTxA/8DZiCp4gfuBPMZU5bho3bqyVK1fq66+/tjtkIXgRU8gJsRFYAi4p5f5L3bRp01S+fHndfPPN9sNTz549bWmeGdJZoUIFXXzxxRkfoMzWj6bHtEOHDhklgO+8846GDRvGhysQU/AI8QNvI6bgCeIH/hpT//vf//Taa6/ZagVzQPAippATYiMwBdygc3fwLV261GZNTZC6h3I+++yzNmv6yy+/aPv27Rn3+eOPP2yfaeXKlXXPPffYQWgbNmyw9wvg7kbkETEFTxA/8DZiCp4gfuCvMbVx40ZiChYxhZwQG4EpPBBK90aNGmV7P81kffewzfPOO0/333+/LSt3B2vZsmXtLjGvvPKKli9frkqVKtlAHD16tC3pMzvGmMtM5rVt27a+fmrwEWIKniB+4G3EFDxB/MDbiCl4GzGFnBAbwaHYVkpt27ZN/fr109VXX21L8j7++GPbBzpz5kx7/VlnnaXY2Fg9/fTT9rw7C2pK/Ez53vz58+35I0eO2EOpUqX09ttv24AlSIMTMQVPED/wNmIKniB+4G3EFLyNmEJOiI0g4yqGDh065LruuutcV1xxhWvt2rUZl7dv3951/fXX29NJSUmuZ5991lWiRAnXxo0b7WXp6en2+KyzznLddNNNGfebPXt2kT8H+BdiCp4gfuBtxBQ8QfzA24gpeBsxhZwQG8GnWFZKlSxZ0m79eP3116t27dpKTU21l/fu3VvLli2zmdKYmBhdddVVat26tS6//HI7+8D0oJr+0Z07d6p///4Zj9emTRsfPhv4A2IKniB+4G3EFDxB/MDbiCl4GzGFnBAbwSfEZKZ8vYiCMH2j7i2JzdaPoaGhGjRokC3NM1P33bZs2aKzzz7bBrMp1Zs6daoaNWpkt31MSEjw4TOAvyGm4AniB95GTMETxA+8jZiCtxFTyAmxEVyKbVIqO126dLF9pNddd50NXsME8OrVqzVnzhzNmDFDLVu2tNcDeUFMwRPED7yNmIIniB94GzEFbyOmkBNiI3AFTFJq7dq1diL/mDFjMkr0jh07psjISF8vDcUUMQVPED/wNmIKniB+4G3EFLyNmEJOiI3AVixnSmXmzqn9888/Kl26dEaQmkn899xzj+0pBfKDmIIniB94GzEFTxA/8DZiCt5GTCEnxEZwCFcxZwaaGWZ7yEsvvVTjx4/XLbfcosOHD+uLL75QxYoVfb1EFDPEFDxB/MDbiCl4gviBtxFT8DZiCjkhNoJDQLTvJScnq3nz5lqzZo0t4TOZ04cfftjXy0IxRkzBE8QPvI2YgieIH3gbMQVvI6aQE2Ij8AVEUso4//zzVb9+fQ0bNkzR0dG+Xg4CADEFTxA/8DZiCp4gfuBtxBS8jZhCToiNwBYwSam0tDSFhYX5ehkIIMQUPEH8wNuIKXiC+IG3EVPwNmIKOSE2AlvAJKUAAAAAAABQfBT73fcAAAAAAABQ/JCUAgAAAAAAQJEjKQUAAAAAAIAiR1IKAAAAAAAARY6kFAAAAAAAAIocSSkAAAAAAAAUOZJSAAAAAAAAKHIkpQAAAHzs+uuvV0hIiD1EREQoISFB559/vj7++GOlp6fn+XE+/fRTxcXFFepaAYqkqCMAAANzSURBVAAAvIWkFAAAgB/o1auXtm3bpvXr12vs2LE655xzdM8996hv375KTU319fIAAAC8jqQUAACAH4iKilKlSpVUtWpVtW7dWo8++qh++eUXm6AyFVDGsGHD1Lx5c5UqVUrVq1fXHXfcoYMHD9rrJk2apBtuuEGJiYkZVVdPPfWUve7o0aN64IEH7GOb+3bo0MHeHgAAwJdISgEAAPipc889Vy1bttSIESPs+dDQUL355ptasmSJPvvsM02YMEEPPfSQva5Tp056/fXXFRsbayuuzMEkooy77rpL06ZN07fffquFCxdqwIABtjJr1apVPn1+AAAguIW4XC6XrxcBAAAQ7DOl9u/fr59//vmU6wYOHGgTSUuXLj3luh9++EG33Xabdu/ebc+biqohQ4bYx3LbuHGj6tSpY4+rVKmScXn37t3Vvn17Pf/884X2vAAAAHITnuu1AAAA8Cnz90PTimf88ccfeuGFF7R8+XIlJSXZWVPJyck6fPiwSpYsme39Fy1apLS0NDVo0CDL5aalr3z58kXyHAAAALJDUgoAAMCPLVu2TLVr17YD0M3Q89tvv13PPfecypUrp3/++UeDBw/WsWPHckxKmZlTYWFhmjNnjj3OrHTp0kX0LAAAAE5FUgoAAMBPmZlRptLp3nvvtUml9PR0vfrqq3a2lDF8+PAst4+MjLRVUZmdccYZ9rKdO3eqa9euRbp+AACA3JCUAgAA8AOmnW779u02gbRjxw6NGzfOtuqZ6qhrr71WixcvVkpKit566y3169dPU6ZM0bvvvpvlMWrVqmUro/788087IN1UT5m2vUGDBtnHMAktk6TatWuXvU2LFi3Up08fnz1nAAAQ3Nh9DwAAwA+YJFTlypVtYsnsjDdx4kS7094vv/xi2+5MkmnYsGF66aWX1KxZM3311Vc2aZWZ2YHPDD6/4oorFB8fr5dfftle/sknn9ik1P3336+GDRuqf//+mjVrlmrUqOGjZwsAAMDuewAAAAAAAPABKqUAAAAAAABQ5EhKAQAAAAAAoMiRlAIAAAAAAECRIykFAAAAAACAIkdSCgAAAAAAAEWOpBQAAAAAAACKHEkpAAAAAAAAFDmSUgAAAAAAAChyJKUAAAAAAABQ5EhKAQAAAAAAoMiRlAIAAAAAAECRIykFAAAAAAAAFbX/B3UQuGa8DkWLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# Setting the figure size for the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Iterating through each strategy and plotting its cumulative returns\n",
    "for strategy in strategies:\n",
    "    if f'{strategy}_returns' in result.columns:\n",
    "        # Make sure dates are properly parsed\n",
    "        result.index = pd.to_datetime(result.index)\n",
    "        \n",
    "        # Extracting daily returns for the current strategy and converting to decimal format if necessary\n",
    "        returns = result[f'{strategy}_returns'].dropna() + 1  # Adds 1 for using cumprod()\n",
    "        \n",
    "        # Calculating cumulative returns and converting to percentage\n",
    "        cumulative_returns = (returns.cumprod() - 1) * 100  # Convert to percentage\n",
    "        \n",
    "        # Plotting cumulative returns with original colors\n",
    "        plt.plot(cumulative_returns.index, cumulative_returns, label=strategy)\n",
    "\n",
    "# Format y-axis as percentages\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0f}%'.format(y)))\n",
    "plt.ylabel('Cumulative Returns (%)')\n",
    "plt.xlabel('Date')\n",
    "\n",
    "# Format x-axis dates\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# Make sure dates are in the correct format and rotated\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "# Adding title and legend\n",
    "#plt.title('Cumulative Returns of DRL Strategies')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Add grid with light gray color\n",
    "plt.grid(True, linestyle='-', alpha=0.2)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results to CSV\n",
    "Needs to be changed for each agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# For df_account_value_ppo\n",
    "with open('results/5. AMZN/amzn_finrl_df_account_value_ppo.pkl', 'wb') as f:\n",
    "    pickle.dump(df_account_value_ppo, f)\n",
    "    \n",
    "# For df_actions_ppo\n",
    "with open('results/5. AMZN/amzn_finrl_df_actions_ppo.pkl', 'wb') as f:\n",
    "    pickle.dump(df_actions_ppo, f)\n",
    "\n",
    "# For buy_and_hold\n",
    "with open('results/5. AMZN/amzn_finrl_buy_and_hold.pkl', 'wb') as f:\n",
    "    pickle.dump(buy_and_hold, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
