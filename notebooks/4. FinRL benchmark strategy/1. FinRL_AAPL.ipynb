{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# FinRL and stable_baselines3 for machine learning and trading\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_primo_trading.env_primo_default import StockTradingEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "# Configuration files and helper functions from FinRL\n",
    "from finrl.config import INDICATORS\n",
    "from finrl.main import check_and_make_directories\n",
    "\n",
    "# Enabling chart display within Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "TRAINED_MODEL_DIR = 'files/models_AAPL'\n",
    "RESULTS_DIR = 'files/results_AAPL'\n",
    "DATA_DIR = 'files/data_AAPL'\n",
    "\n",
    "# Checking and creating directories\n",
    "check_and_make_directories([TRAINED_MODEL_DIR, DATA_DIR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a class called YahooDownloader that uses yfinance to fetch data from Yahoo Finance.\n",
    "\n",
    "In the YahooDownloader of FinRL, we modified the data frame into a format suitable for further data processing. We use a custom closing price instead of the regular closing price and add a column that represents the day of the week (0-4 corresponding to Monday-Friday)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and trading intervals\n",
    "TRAIN_START_DATE = '2022-04-01'\n",
    "TRAIN_END_DATE = '2024-07-31'\n",
    "TRADE_START_DATE = '2024-08-01'\n",
    "TRADE_END_DATE = '2025-02-28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (729, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetching all data\n",
    "df_raw = YahooDownloader(start_date = TRAIN_START_DATE,\n",
    "                         end_date = TRADE_END_DATE,\n",
    "                         ticker_list = ['AAPL']).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>171.530624</td>\n",
       "      <td>174.309998</td>\n",
       "      <td>174.880005</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>78751300</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>175.594742</td>\n",
       "      <td>178.440002</td>\n",
       "      <td>178.490005</td>\n",
       "      <td>174.570007</td>\n",
       "      <td>76468400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>172.268616</td>\n",
       "      <td>175.059998</td>\n",
       "      <td>178.300003</td>\n",
       "      <td>177.500000</td>\n",
       "      <td>73401800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>169.090149</td>\n",
       "      <td>171.830002</td>\n",
       "      <td>173.630005</td>\n",
       "      <td>172.360001</td>\n",
       "      <td>89058800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>169.395187</td>\n",
       "      <td>172.139999</td>\n",
       "      <td>173.360001</td>\n",
       "      <td>171.160004</td>\n",
       "      <td>77594700</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close    volume   tic  \\\n",
       "0  2022-04-01  171.530624  174.309998  174.880005  174.029999  78751300  AAPL   \n",
       "1  2022-04-04  175.594742  178.440002  178.490005  174.570007  76468400  AAPL   \n",
       "2  2022-04-05  172.268616  175.059998  178.300003  177.500000  73401800  AAPL   \n",
       "3  2022-04-06  169.090149  171.830002  173.630005  172.360001  89058800  AAPL   \n",
       "4  2022-04-07  169.395187  172.139999  173.360001  171.160004  77594700  AAPL   \n",
       "\n",
       "   day  \n",
       "0    4  \n",
       "1    0  \n",
       "2    1  \n",
       "3    2  \n",
       "4    3  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the defined class FeatureEngineer to process data and add technical indicators.\n",
    "\n",
    "The use_vix option includes the VIX index, known as the \"fear index,\" which represents the expected volatility of the stock market based on S&P 500 options. The VIX helps the model understand market uncertainty, with higher values indicating greater uncertainty.\n",
    "\n",
    "The use_turbulence option includes the turbulence index, which measures unusual market fluctuations and serves as an indicator of risk and market shocks. It is useful for identifying periods of high volatility, helping the model to adapt to financial crises.\n",
    "\n",
    "Overall, a quite handy class that contains useful methods for processing financial data and can be applied to numerous other purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Shape of DataFrame:  (728, 8)\n",
      "Successfully added vix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     tech_indicator_list = INDICATORS,\n",
    "                     use_vix=True,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of unique stock tickers from the 'tic' column of the 'processed' DataFrame.\n",
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "\n",
    "# Creates a list of dates between the earliest and latest dates in the 'processed' DataFrame, converting them to strings.\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "\n",
    "# Creates combinations of all dates and stock tickers using the Cartesian product.\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "# Creates a new DataFrame 'processed_full' with columns \"date\" and \"tic\", containing all combinations of dates and stock tickers.\n",
    "# Merges this DataFrame with the original 'processed' DataFrame based on the \"date\" and \"tic\" columns, using a 'left' join.\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "\n",
    "# Filters the 'processed_full' DataFrame to only include rows where the dates are present in the original 'processed' DataFrame.\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "\n",
    "# Sorts the 'processed_full' DataFrame by date and stock ticker.\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "# Replaces all missing values (NaN) with 0 in the 'processed_full' DataFrame.\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>vix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>171.530624</td>\n",
       "      <td>174.309998</td>\n",
       "      <td>174.880005</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>78751300.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>175.063690</td>\n",
       "      <td>173.536316</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>174.029999</td>\n",
       "      <td>20.620001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>175.594742</td>\n",
       "      <td>178.440002</td>\n",
       "      <td>178.490005</td>\n",
       "      <td>174.570007</td>\n",
       "      <td>76468400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012116</td>\n",
       "      <td>175.063690</td>\n",
       "      <td>173.536316</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>174.300003</td>\n",
       "      <td>174.300003</td>\n",
       "      <td>20.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>172.268616</td>\n",
       "      <td>175.059998</td>\n",
       "      <td>178.300003</td>\n",
       "      <td>177.500000</td>\n",
       "      <td>73401800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106297</td>\n",
       "      <td>179.100958</td>\n",
       "      <td>171.632379</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>43.969716</td>\n",
       "      <td>90.914062</td>\n",
       "      <td>175.366669</td>\n",
       "      <td>175.366669</td>\n",
       "      <td>18.790001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>169.090149</td>\n",
       "      <td>171.830002</td>\n",
       "      <td>173.630005</td>\n",
       "      <td>172.360001</td>\n",
       "      <td>89058800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.039051</td>\n",
       "      <td>178.897135</td>\n",
       "      <td>170.332869</td>\n",
       "      <td>39.364874</td>\n",
       "      <td>-100.437724</td>\n",
       "      <td>11.413008</td>\n",
       "      <td>174.615002</td>\n",
       "      <td>174.615002</td>\n",
       "      <td>21.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-04-07</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>169.395187</td>\n",
       "      <td>172.139999</td>\n",
       "      <td>173.360001</td>\n",
       "      <td>171.160004</td>\n",
       "      <td>77594700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.164959</td>\n",
       "      <td>178.751228</td>\n",
       "      <td>169.096776</td>\n",
       "      <td>34.336570</td>\n",
       "      <td>-85.472465</td>\n",
       "      <td>7.457922</td>\n",
       "      <td>173.924002</td>\n",
       "      <td>173.924002</td>\n",
       "      <td>21.969999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>167.377853</td>\n",
       "      <td>170.089996</td>\n",
       "      <td>171.779999</td>\n",
       "      <td>171.779999</td>\n",
       "      <td>76575500.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.211035</td>\n",
       "      <td>178.225658</td>\n",
       "      <td>168.907678</td>\n",
       "      <td>38.533055</td>\n",
       "      <td>-92.229714</td>\n",
       "      <td>22.048346</td>\n",
       "      <td>173.566668</td>\n",
       "      <td>173.566668</td>\n",
       "      <td>21.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-04-11</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>163.107101</td>\n",
       "      <td>165.750000</td>\n",
       "      <td>169.029999</td>\n",
       "      <td>168.710007</td>\n",
       "      <td>72246700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.376025</td>\n",
       "      <td>178.491299</td>\n",
       "      <td>167.254420</td>\n",
       "      <td>29.029701</td>\n",
       "      <td>-140.365903</td>\n",
       "      <td>39.284074</td>\n",
       "      <td>172.872859</td>\n",
       "      <td>172.872859</td>\n",
       "      <td>23.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>164.986633</td>\n",
       "      <td>167.660004</td>\n",
       "      <td>169.869995</td>\n",
       "      <td>168.020004</td>\n",
       "      <td>79265200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.513426</td>\n",
       "      <td>178.497819</td>\n",
       "      <td>166.034687</td>\n",
       "      <td>27.455331</td>\n",
       "      <td>-102.292069</td>\n",
       "      <td>20.190045</td>\n",
       "      <td>172.266253</td>\n",
       "      <td>172.266253</td>\n",
       "      <td>24.940001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-04-13</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>167.682938</td>\n",
       "      <td>170.399994</td>\n",
       "      <td>171.039993</td>\n",
       "      <td>167.389999</td>\n",
       "      <td>70618900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.632018</td>\n",
       "      <td>178.398748</td>\n",
       "      <td>165.050146</td>\n",
       "      <td>26.117467</td>\n",
       "      <td>-66.710964</td>\n",
       "      <td>0.127844</td>\n",
       "      <td>171.724447</td>\n",
       "      <td>171.724447</td>\n",
       "      <td>23.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-04-14</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>162.654404</td>\n",
       "      <td>165.289993</td>\n",
       "      <td>171.270004</td>\n",
       "      <td>170.619995</td>\n",
       "      <td>75329400.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.540574</td>\n",
       "      <td>177.945244</td>\n",
       "      <td>165.282759</td>\n",
       "      <td>41.290567</td>\n",
       "      <td>-71.255354</td>\n",
       "      <td>0.127844</td>\n",
       "      <td>171.614001</td>\n",
       "      <td>171.614001</td>\n",
       "      <td>21.719999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>162.437943</td>\n",
       "      <td>165.070007</td>\n",
       "      <td>166.600006</td>\n",
       "      <td>163.919998</td>\n",
       "      <td>69023900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.823861</td>\n",
       "      <td>178.504184</td>\n",
       "      <td>163.324909</td>\n",
       "      <td>28.660368</td>\n",
       "      <td>-135.508432</td>\n",
       "      <td>23.469323</td>\n",
       "      <td>170.914547</td>\n",
       "      <td>170.914547</td>\n",
       "      <td>24.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>164.730789</td>\n",
       "      <td>167.399994</td>\n",
       "      <td>167.820007</td>\n",
       "      <td>165.020004</td>\n",
       "      <td>67723800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.959919</td>\n",
       "      <td>178.420076</td>\n",
       "      <td>162.426593</td>\n",
       "      <td>32.183573</td>\n",
       "      <td>-89.639244</td>\n",
       "      <td>10.079594</td>\n",
       "      <td>170.423335</td>\n",
       "      <td>170.423335</td>\n",
       "      <td>22.549999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-04-20</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>164.563477</td>\n",
       "      <td>167.229996</td>\n",
       "      <td>168.880005</td>\n",
       "      <td>168.759995</td>\n",
       "      <td>67929800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.836825</td>\n",
       "      <td>178.007077</td>\n",
       "      <td>162.583694</td>\n",
       "      <td>42.220083</td>\n",
       "      <td>-53.316223</td>\n",
       "      <td>10.079594</td>\n",
       "      <td>170.295386</td>\n",
       "      <td>170.295386</td>\n",
       "      <td>21.129999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>163.766403</td>\n",
       "      <td>166.419998</td>\n",
       "      <td>171.529999</td>\n",
       "      <td>168.910004</td>\n",
       "      <td>87227800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.725125</td>\n",
       "      <td>177.642497</td>\n",
       "      <td>162.750362</td>\n",
       "      <td>42.572727</td>\n",
       "      <td>-37.524694</td>\n",
       "      <td>10.079594</td>\n",
       "      <td>170.196430</td>\n",
       "      <td>170.196430</td>\n",
       "      <td>20.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>159.210236</td>\n",
       "      <td>161.789993</td>\n",
       "      <td>167.869995</td>\n",
       "      <td>166.460007</td>\n",
       "      <td>84882400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.777021</td>\n",
       "      <td>177.377445</td>\n",
       "      <td>162.517225</td>\n",
       "      <td>38.593117</td>\n",
       "      <td>-107.001893</td>\n",
       "      <td>24.346771</td>\n",
       "      <td>169.947335</td>\n",
       "      <td>169.947335</td>\n",
       "      <td>22.709999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>160.282867</td>\n",
       "      <td>162.880005</td>\n",
       "      <td>163.169998</td>\n",
       "      <td>161.119995</td>\n",
       "      <td>96046400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.130503</td>\n",
       "      <td>177.822166</td>\n",
       "      <td>160.969086</td>\n",
       "      <td>31.874852</td>\n",
       "      <td>-152.431869</td>\n",
       "      <td>37.516691</td>\n",
       "      <td>169.395626</td>\n",
       "      <td>169.395626</td>\n",
       "      <td>30.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>154.299805</td>\n",
       "      <td>156.800003</td>\n",
       "      <td>162.339996</td>\n",
       "      <td>162.250000</td>\n",
       "      <td>95623200.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.316123</td>\n",
       "      <td>177.839988</td>\n",
       "      <td>160.110602</td>\n",
       "      <td>34.375622</td>\n",
       "      <td>-168.313000</td>\n",
       "      <td>39.442565</td>\n",
       "      <td>168.975295</td>\n",
       "      <td>168.975295</td>\n",
       "      <td>27.379999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>154.073486</td>\n",
       "      <td>156.570007</td>\n",
       "      <td>159.789993</td>\n",
       "      <td>155.910004</td>\n",
       "      <td>88063200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.841857</td>\n",
       "      <td>178.827442</td>\n",
       "      <td>157.671449</td>\n",
       "      <td>28.337982</td>\n",
       "      <td>-191.341493</td>\n",
       "      <td>44.845499</td>\n",
       "      <td>168.249446</td>\n",
       "      <td>168.249446</td>\n",
       "      <td>31.110001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>161.030762</td>\n",
       "      <td>163.639999</td>\n",
       "      <td>164.520004</td>\n",
       "      <td>159.250000</td>\n",
       "      <td>130216800.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-2.009228</td>\n",
       "      <td>178.854067</td>\n",
       "      <td>156.697514</td>\n",
       "      <td>34.598163</td>\n",
       "      <td>-96.036961</td>\n",
       "      <td>15.332388</td>\n",
       "      <td>167.775791</td>\n",
       "      <td>167.775791</td>\n",
       "      <td>29.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>155.136230</td>\n",
       "      <td>157.649994</td>\n",
       "      <td>166.199997</td>\n",
       "      <td>161.839996</td>\n",
       "      <td>131747600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.945157</td>\n",
       "      <td>178.583754</td>\n",
       "      <td>156.374247</td>\n",
       "      <td>38.881174</td>\n",
       "      <td>-96.688116</td>\n",
       "      <td>15.332388</td>\n",
       "      <td>167.479001</td>\n",
       "      <td>167.479001</td>\n",
       "      <td>28.969999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022-05-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>155.441284</td>\n",
       "      <td>157.960007</td>\n",
       "      <td>158.229996</td>\n",
       "      <td>156.710007</td>\n",
       "      <td>123055300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.211736</td>\n",
       "      <td>178.255079</td>\n",
       "      <td>154.970923</td>\n",
       "      <td>34.281195</td>\n",
       "      <td>-144.814873</td>\n",
       "      <td>32.037992</td>\n",
       "      <td>166.966192</td>\n",
       "      <td>166.966192</td>\n",
       "      <td>33.349998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2022-05-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>156.937057</td>\n",
       "      <td>159.479996</td>\n",
       "      <td>160.710007</td>\n",
       "      <td>158.149994</td>\n",
       "      <td>88966500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.295182</td>\n",
       "      <td>177.387219</td>\n",
       "      <td>154.196783</td>\n",
       "      <td>36.463936</td>\n",
       "      <td>-108.115144</td>\n",
       "      <td>27.090739</td>\n",
       "      <td>166.565455</td>\n",
       "      <td>166.565455</td>\n",
       "      <td>31.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2022-05-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>163.372787</td>\n",
       "      <td>166.020004</td>\n",
       "      <td>166.479996</td>\n",
       "      <td>159.669998</td>\n",
       "      <td>108256500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.229422</td>\n",
       "      <td>175.395004</td>\n",
       "      <td>154.405997</td>\n",
       "      <td>38.687606</td>\n",
       "      <td>-41.595400</td>\n",
       "      <td>8.924971</td>\n",
       "      <td>166.265653</td>\n",
       "      <td>166.265653</td>\n",
       "      <td>29.120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-05-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>154.270279</td>\n",
       "      <td>156.770004</td>\n",
       "      <td>164.080002</td>\n",
       "      <td>163.850006</td>\n",
       "      <td>130525300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.864671</td>\n",
       "      <td>174.368941</td>\n",
       "      <td>154.581061</td>\n",
       "      <td>44.239395</td>\n",
       "      <td>-73.613068</td>\n",
       "      <td>13.612519</td>\n",
       "      <td>166.165001</td>\n",
       "      <td>166.165001</td>\n",
       "      <td>25.969999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>154.999542</td>\n",
       "      <td>157.279999</td>\n",
       "      <td>159.440002</td>\n",
       "      <td>156.009995</td>\n",
       "      <td>116124600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.104027</td>\n",
       "      <td>173.774901</td>\n",
       "      <td>153.660100</td>\n",
       "      <td>37.628446</td>\n",
       "      <td>-120.304751</td>\n",
       "      <td>21.675155</td>\n",
       "      <td>165.758801</td>\n",
       "      <td>165.758801</td>\n",
       "      <td>32.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>149.855240</td>\n",
       "      <td>152.059998</td>\n",
       "      <td>155.830002</td>\n",
       "      <td>154.929993</td>\n",
       "      <td>131577900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.341530</td>\n",
       "      <td>172.911659</td>\n",
       "      <td>152.838341</td>\n",
       "      <td>36.843841</td>\n",
       "      <td>-150.580043</td>\n",
       "      <td>27.147614</td>\n",
       "      <td>165.342308</td>\n",
       "      <td>165.342308</td>\n",
       "      <td>31.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>152.269699</td>\n",
       "      <td>154.509995</td>\n",
       "      <td>156.740005</td>\n",
       "      <td>155.520004</td>\n",
       "      <td>115366700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.457396</td>\n",
       "      <td>172.370497</td>\n",
       "      <td>152.060503</td>\n",
       "      <td>37.579407</td>\n",
       "      <td>-124.303448</td>\n",
       "      <td>21.202292</td>\n",
       "      <td>164.978519</td>\n",
       "      <td>164.978519</td>\n",
       "      <td>33.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>144.375839</td>\n",
       "      <td>146.500000</td>\n",
       "      <td>155.449997</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>142689800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.663538</td>\n",
       "      <td>171.968199</td>\n",
       "      <td>151.010800</td>\n",
       "      <td>36.090678</td>\n",
       "      <td>-156.574560</td>\n",
       "      <td>23.159371</td>\n",
       "      <td>164.568572</td>\n",
       "      <td>164.568572</td>\n",
       "      <td>32.869999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>140.492966</td>\n",
       "      <td>142.559998</td>\n",
       "      <td>146.199997</td>\n",
       "      <td>142.770004</td>\n",
       "      <td>182602000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-3.566890</td>\n",
       "      <td>173.291748</td>\n",
       "      <td>147.225252</td>\n",
       "      <td>29.638666</td>\n",
       "      <td>-220.410442</td>\n",
       "      <td>35.113584</td>\n",
       "      <td>163.816897</td>\n",
       "      <td>163.816897</td>\n",
       "      <td>33.740002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>144.977005</td>\n",
       "      <td>147.110001</td>\n",
       "      <td>148.100006</td>\n",
       "      <td>144.589996</td>\n",
       "      <td>113990900.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.098518</td>\n",
       "      <td>172.806756</td>\n",
       "      <td>145.107244</td>\n",
       "      <td>31.778665</td>\n",
       "      <td>-172.966681</td>\n",
       "      <td>25.202180</td>\n",
       "      <td>163.176000</td>\n",
       "      <td>163.176000</td>\n",
       "      <td>31.090000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   tic        open        high         low       close  \\\n",
       "0   2022-04-01  AAPL  171.530624  174.309998  174.880005  174.029999   \n",
       "3   2022-04-04  AAPL  175.594742  178.440002  178.490005  174.570007   \n",
       "4   2022-04-05  AAPL  172.268616  175.059998  178.300003  177.500000   \n",
       "5   2022-04-06  AAPL  169.090149  171.830002  173.630005  172.360001   \n",
       "6   2022-04-07  AAPL  169.395187  172.139999  173.360001  171.160004   \n",
       "7   2022-04-08  AAPL  167.377853  170.089996  171.779999  171.779999   \n",
       "10  2022-04-11  AAPL  163.107101  165.750000  169.029999  168.710007   \n",
       "11  2022-04-12  AAPL  164.986633  167.660004  169.869995  168.020004   \n",
       "12  2022-04-13  AAPL  167.682938  170.399994  171.039993  167.389999   \n",
       "13  2022-04-14  AAPL  162.654404  165.289993  171.270004  170.619995   \n",
       "17  2022-04-18  AAPL  162.437943  165.070007  166.600006  163.919998   \n",
       "18  2022-04-19  AAPL  164.730789  167.399994  167.820007  165.020004   \n",
       "19  2022-04-20  AAPL  164.563477  167.229996  168.880005  168.759995   \n",
       "20  2022-04-21  AAPL  163.766403  166.419998  171.529999  168.910004   \n",
       "21  2022-04-22  AAPL  159.210236  161.789993  167.869995  166.460007   \n",
       "24  2022-04-25  AAPL  160.282867  162.880005  163.169998  161.119995   \n",
       "25  2022-04-26  AAPL  154.299805  156.800003  162.339996  162.250000   \n",
       "26  2022-04-27  AAPL  154.073486  156.570007  159.789993  155.910004   \n",
       "27  2022-04-28  AAPL  161.030762  163.639999  164.520004  159.250000   \n",
       "28  2022-04-29  AAPL  155.136230  157.649994  166.199997  161.839996   \n",
       "31  2022-05-02  AAPL  155.441284  157.960007  158.229996  156.710007   \n",
       "32  2022-05-03  AAPL  156.937057  159.479996  160.710007  158.149994   \n",
       "33  2022-05-04  AAPL  163.372787  166.020004  166.479996  159.669998   \n",
       "34  2022-05-05  AAPL  154.270279  156.770004  164.080002  163.850006   \n",
       "35  2022-05-06  AAPL  154.999542  157.279999  159.440002  156.009995   \n",
       "38  2022-05-09  AAPL  149.855240  152.059998  155.830002  154.929993   \n",
       "39  2022-05-10  AAPL  152.269699  154.509995  156.740005  155.520004   \n",
       "40  2022-05-11  AAPL  144.375839  146.500000  155.449997  153.500000   \n",
       "41  2022-05-12  AAPL  140.492966  142.559998  146.199997  142.770004   \n",
       "42  2022-05-13  AAPL  144.977005  147.110001  148.100006  144.589996   \n",
       "\n",
       "         volume  day      macd     boll_ub     boll_lb      rsi_30  \\\n",
       "0    78751300.0  4.0  0.000000  175.063690  173.536316  100.000000   \n",
       "3    76468400.0  0.0  0.012116  175.063690  173.536316  100.000000   \n",
       "4    73401800.0  1.0  0.106297  179.100958  171.632379  100.000000   \n",
       "5    89058800.0  2.0 -0.039051  178.897135  170.332869   39.364874   \n",
       "6    77594700.0  3.0 -0.164959  178.751228  169.096776   34.336570   \n",
       "7    76575500.0  4.0 -0.211035  178.225658  168.907678   38.533055   \n",
       "10   72246700.0  0.0 -0.376025  178.491299  167.254420   29.029701   \n",
       "11   79265200.0  1.0 -0.513426  178.497819  166.034687   27.455331   \n",
       "12   70618900.0  2.0 -0.632018  178.398748  165.050146   26.117467   \n",
       "13   75329400.0  3.0 -0.540574  177.945244  165.282759   41.290567   \n",
       "17   69023900.0  0.0 -0.823861  178.504184  163.324909   28.660368   \n",
       "18   67723800.0  1.0 -0.959919  178.420076  162.426593   32.183573   \n",
       "19   67929800.0  2.0 -0.836825  178.007077  162.583694   42.220083   \n",
       "20   87227800.0  3.0 -0.725125  177.642497  162.750362   42.572727   \n",
       "21   84882400.0  4.0 -0.777021  177.377445  162.517225   38.593117   \n",
       "24   96046400.0  0.0 -1.130503  177.822166  160.969086   31.874852   \n",
       "25   95623200.0  1.0 -1.316123  177.839988  160.110602   34.375622   \n",
       "26   88063200.0  2.0 -1.841857  178.827442  157.671449   28.337982   \n",
       "27  130216800.0  3.0 -2.009228  178.854067  156.697514   34.598163   \n",
       "28  131747600.0  4.0 -1.945157  178.583754  156.374247   38.881174   \n",
       "31  123055300.0  0.0 -2.211736  178.255079  154.970923   34.281195   \n",
       "32   88966500.0  1.0 -2.295182  177.387219  154.196783   36.463936   \n",
       "33  108256500.0  2.0 -2.229422  175.395004  154.405997   38.687606   \n",
       "34  130525300.0  3.0 -1.864671  174.368941  154.581061   44.239395   \n",
       "35  116124600.0  4.0 -2.104027  173.774901  153.660100   37.628446   \n",
       "38  131577900.0  0.0 -2.341530  172.911659  152.838341   36.843841   \n",
       "39  115366700.0  1.0 -2.457396  172.370497  152.060503   37.579407   \n",
       "40  142689800.0  2.0 -2.663538  171.968199  151.010800   36.090678   \n",
       "41  182602000.0  3.0 -3.566890  173.291748  147.225252   29.638666   \n",
       "42  113990900.0  4.0 -4.098518  172.806756  145.107244   31.778665   \n",
       "\n",
       "        cci_30       dx_30  close_30_sma  close_60_sma        vix  \n",
       "0    66.666667  100.000000    174.029999    174.029999  20.620001  \n",
       "3    66.666667  100.000000    174.300003    174.300003  20.750000  \n",
       "4    43.969716   90.914062    175.366669    175.366669  18.790001  \n",
       "5  -100.437724   11.413008    174.615002    174.615002  21.270000  \n",
       "6   -85.472465    7.457922    173.924002    173.924002  21.969999  \n",
       "7   -92.229714   22.048346    173.566668    173.566668  21.250000  \n",
       "10 -140.365903   39.284074    172.872859    172.872859  23.090000  \n",
       "11 -102.292069   20.190045    172.266253    172.266253  24.940001  \n",
       "12  -66.710964    0.127844    171.724447    171.724447  23.520000  \n",
       "13  -71.255354    0.127844    171.614001    171.614001  21.719999  \n",
       "17 -135.508432   23.469323    170.914547    170.914547  24.520000  \n",
       "18  -89.639244   10.079594    170.423335    170.423335  22.549999  \n",
       "19  -53.316223   10.079594    170.295386    170.295386  21.129999  \n",
       "20  -37.524694   10.079594    170.196430    170.196430  20.240000  \n",
       "21 -107.001893   24.346771    169.947335    169.947335  22.709999  \n",
       "24 -152.431869   37.516691    169.395626    169.395626  30.040001  \n",
       "25 -168.313000   39.442565    168.975295    168.975295  27.379999  \n",
       "26 -191.341493   44.845499    168.249446    168.249446  31.110001  \n",
       "27  -96.036961   15.332388    167.775791    167.775791  29.910000  \n",
       "28  -96.688116   15.332388    167.479001    167.479001  28.969999  \n",
       "31 -144.814873   32.037992    166.966192    166.966192  33.349998  \n",
       "32 -108.115144   27.090739    166.565455    166.565455  31.760000  \n",
       "33  -41.595400    8.924971    166.265653    166.265653  29.120001  \n",
       "34  -73.613068   13.612519    166.165001    166.165001  25.969999  \n",
       "35 -120.304751   21.675155    165.758801    165.758801  32.230000  \n",
       "38 -150.580043   27.147614    165.342308    165.342308  31.900000  \n",
       "39 -124.303448   21.202292    164.978519    164.978519  33.660000  \n",
       "40 -156.574560   23.159371    164.568572    164.568572  32.869999  \n",
       "41 -220.410442   35.113584    163.816897    163.816897  33.740002  \n",
       "42 -172.966681   25.202180    163.176000    163.176000  31.090000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584\n",
      "143\n"
     ]
    }
   ],
   "source": [
    "# Preparing the training and trade set according to the defined dates\n",
    "train = data_split(processed_full, TRAIN_START_DATE,TRAIN_END_DATE)\n",
    "trade = data_split(processed_full, TRADE_START_DATE,TRADE_END_DATE)\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data\n",
    "train.to_csv(DATA_DIR + '/train_data.csv')\n",
    "trade.to_csv(DATA_DIR + '/trade_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stock_dimension represents the number of unique stocks in the dataset. This value is used to determine how many different stocks the model can trade.\n",
    "\n",
    "state_space denotes the total size of the state space that the model uses for decision-making. The state space includes current stock data (such as prices and technical indicators) and information about the current portfolio (such as the number of shares owned). The size of the state space is determined by a formula that takes into account the number of stocks and the number of technical indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 11\n"
     ]
    }
   ],
   "source": [
    "# Calculating the dimension (number of unique stocks) from the 'train' DataFrame.\n",
    "stock_dimension = len(train.tic.unique())\n",
    "\n",
    "# Calculating the state size based on the dimension and the number of technical indicators.\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates lists of buy and sell costs for each stock.\n",
    "buy_cost_list = sell_cost_list = [0] * stock_dimension\n",
    "\n",
    "# Initializes the number of shares for each stock to 0.\n",
    "num_stock_shares = [0] * stock_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e_train_gym is an instance of the StockTradingEnv class, which represents the trading environment. This environment uses the data and parameters defined to simulate the stock market. The model learns how to trade within this environment, trying to maximize the total reward (profit) through a series of trading decisions.\n",
    "\n",
    "env_train is obtained by calling the get_sb_env() method on the e_train_gym instance. This method returns an environment compatible with the Stable Baselines 3 library, which is used for implementing reinforcement learning algorithms. The second return element, which is ignored here (_), can be used for additional information or functionalities provided by the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "# Define arguments for the trading environment.\n",
    "env_kwargs = {\n",
    "    \"hmax\": 1000,  # Maximum number of shares that can be bought or sold in a single transaction.\n",
    "    \"initial_amount\": 100000,  # Initial amount of capital.\n",
    "    \"num_stock_shares\": num_stock_shares,  # Initial number of shares for each stock in the portfolio, initially set to 0.\n",
    "    \"buy_cost_pct\": buy_cost_list,  # Percentages of costs for buying and selling stocks, simulating actual transaction costs.\n",
    "    \"sell_cost_pct\": sell_cost_list,  # Percentages of costs for buying and selling stocks, simulating actual transaction costs.\n",
    "    \"state_space\": state_space,  # Previously defined sizes that affect the structure of the environment.\n",
    "    \"stock_dim\": stock_dimension,  # Previously defined sizes that affect the structure of the environment.\n",
    "    \"tech_indicator_list\": INDICATORS,  # List of technical indicators to be used for market state analysis.\n",
    "    \"action_space\": stock_dimension,  # Size of the action space, i.e., the number of different actions the model can take.\n",
    "    \"reward_scaling\": 1e-4  # Scaling factor for the reward, used to adjust the reward size to facilitate learning.\n",
    "}\n",
    "\n",
    "# Create the training environment.\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "# Retrieve the environment suitable for Stable Baselines and an unused object.\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training DRL Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the deep reinforcement learning (DRL) algorithms from the Stable Baselines 3 library. This is a library that has implemented popular DRL algorithms using PyTorch.\n",
    "\n",
    "As an alternative, the ElegantRL and Ray RLlib libraries can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 5 different DRL agents (A2C, DDPG, PPO, TD3, SAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the appropriate values to 'True' for the algorithms you want to use\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 1: A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.00025}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# A new instance of the DRL agent is created with the given environment (it is not necessary to do this again, but for easier instructions, it remains)\n",
    "agent = DRLAgent(env = env_train)\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.01, \"learning_rate\": 0.00025}\n",
    "model_a2c = agent.get_model(\"a2c\", model_kwargs = A2C_PARAMS)\n",
    "\n",
    "if if_using_a2c:\n",
    "  # Setting up the logger to monitor and record information during training\n",
    "  tmp_path = RESULTS_DIR + '/a2c'\n",
    "  # Configures a new logger that will print information to standard output, log to a CSV file, and TensorBoard\n",
    "  new_logger_a2c = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Sets the new logger for the A2C model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the A2C model with the defined total number of time steps, only if if_using_a2c is set to True.\n",
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=50000) if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained A2C model to the defined directory, only if if_using_a2c is set to True.\n",
    "trained_a2c.save(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.00025}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.00025}\n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs = DDPG_PARAMS)\n",
    "\n",
    "if if_using_ddpg:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ddpg'\n",
    "  new_logger_ddpg = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ddpg.set_logger(new_logger_ddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000) if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ddpg.save(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to files/results_AAPL/ppo\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "       \"n_steps\": 2048,\n",
    "       \"ent_coef\": 0.01,\n",
    "       \"learning_rate\": 0.00025,\n",
    "       \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
    "\n",
    "if if_using_ppo:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/ppo'\n",
    "  new_logger_ppo = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_ppo.set_logger(new_logger_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    fps             | 2494        |\n",
      "|    iterations      | 1           |\n",
      "|    time_elapsed    | 0           |\n",
      "|    total_timesteps | 2048        |\n",
      "| train/             |             |\n",
      "|    reward          | -0.13938288 |\n",
      "------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053539188 |\n",
      "|    clip_fraction        | 0.0443       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -6.2         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.082        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.291        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 10\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 108027.50\n",
      "total_reward: 8027.50\n",
      "total_cost: 0.00\n",
      "total_trades: 492\n",
      "Sharpe: 0.267\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2346         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029595536 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0153       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0691       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    reward               | -0.10045566  |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 0.16         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2401         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048148837 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.104       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0338       |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    reward               | 0.052545227  |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 0.111        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2306         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018787798 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.0236      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0378       |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    reward               | 0.15351018   |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.109        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 20\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 109378.10\n",
      "total_reward: 9378.10\n",
      "total_cost: 0.00\n",
      "total_trades: 535\n",
      "Sharpe: 0.286\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2271         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022025397 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.02        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0392       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    reward               | -0.03449605  |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 0.138        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2305         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029050433 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0254       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0487       |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    reward               | 0.013694122  |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 0.138        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2272          |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058434677 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | 0.0106        |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.0636        |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    reward               | -0.13024764   |\n",
      "|    std                  | 0.991         |\n",
      "|    value_loss           | 0.163         |\n",
      "-------------------------------------------\n",
      "day: 583, episode: 30\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 109998.83\n",
      "total_reward: 9998.83\n",
      "total_cost: 0.00\n",
      "total_trades: 536\n",
      "Sharpe: 0.298\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2242         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043203025 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.014       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0749       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 0.184        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2265         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012214666 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0583       |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    reward               | 0.20166443   |\n",
      "|    std                  | 0.991        |\n",
      "|    value_loss           | 0.116        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2242         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030740984 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0223       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0628       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    reward               | -0.26680514  |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 0.162        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 40\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 96357.88\n",
      "total_reward: -3642.12\n",
      "total_cost: 0.00\n",
      "total_trades: 549\n",
      "Sharpe: 0.043\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2227         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042669624 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0221       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0777       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | -0.39372018  |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 0.169        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2252        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005175854 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0593      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    reward               | -0.1099     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 50\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 116166.37\n",
      "total_reward: 16166.37\n",
      "total_cost: 0.00\n",
      "total_trades: 540\n",
      "Sharpe: 0.402\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2230         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038648904 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0558       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0579       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    reward               | 0.12484586   |\n",
      "|    std                  | 0.974        |\n",
      "|    value_loss           | 0.179        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2248         |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026030913 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0684       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0517       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 0.151        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2225         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028324178 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.065        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0463       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    reward               | 0.1947521    |\n",
      "|    std                  | 0.982        |\n",
      "|    value_loss           | 0.155        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 60\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 92015.18\n",
      "total_reward: -7984.82\n",
      "total_cost: 0.00\n",
      "total_trades: 552\n",
      "Sharpe: -0.039\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2221         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056403945 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.06         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0922       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    reward               | 0.21999893   |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 0.185        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2230         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028257307 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.0985       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0513       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    reward               | 0.057120398  |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 0.133        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2218        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004952648 |\n",
      "|    clip_fraction        | 0.0362      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0892      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    reward               | 0.101267435 |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 70\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 164077.59\n",
      "total_reward: 64077.59\n",
      "total_cost: 0.00\n",
      "total_trades: 568\n",
      "Sharpe: 1.036\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2202         |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037465636 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0787       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    reward               | 0.037399948  |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 0.193        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2213         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005745802  |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.143        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0951       |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    reward               | -0.018080069 |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.19         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2201        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005041952 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0663      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    reward               | -0.14569943 |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 0.211       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 80\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 121256.08\n",
      "total_reward: 21256.08\n",
      "total_cost: 0.00\n",
      "total_trades: 567\n",
      "Sharpe: 0.479\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2199         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048381174 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0583       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.961        |\n",
      "|    value_loss           | 0.172        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2208         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047241473 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0559       |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    reward               | -0.04024807  |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 0.182        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2192         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066287937 |\n",
      "|    clip_fraction        | 0.0606       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.167        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0935       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    reward               | 0.13845795   |\n",
      "|    std                  | 0.957        |\n",
      "|    value_loss           | 0.233        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 90\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 163991.99\n",
      "total_reward: 63991.99\n",
      "total_cost: 0.00\n",
      "total_trades: 580\n",
      "Sharpe: 0.985\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2184         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005652396  |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0965       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    reward               | -0.114660464 |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 0.204        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2196         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066939774 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0789       |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    reward               | -0.057215944 |\n",
      "|    std                  | 0.941        |\n",
      "|    value_loss           | 0.227        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2186         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051589357 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0867       |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    reward               | 0.018630853  |\n",
      "|    std                  | 0.944        |\n",
      "|    value_loss           | 0.203        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 147073.36\n",
      "total_reward: 47073.36\n",
      "total_cost: 0.00\n",
      "total_trades: 578\n",
      "Sharpe: 0.798\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2197         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037570186 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0621       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    reward               | 0.009135557  |\n",
      "|    std                  | 0.937        |\n",
      "|    value_loss           | 0.188        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2190        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006560771 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0696      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    reward               | -0.07270915 |\n",
      "|    std                  | 0.935       |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2189         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069399257 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0859       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    reward               | -0.007867966 |\n",
      "|    std                  | 0.926        |\n",
      "|    value_loss           | 0.222        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 151910.94\n",
      "total_reward: 51910.94\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.856\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2193        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005978804 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0626      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    reward               | -0.06038346 |\n",
      "|    std                  | 0.92        |\n",
      "|    value_loss           | 0.191       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2193         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074475934 |\n",
      "|    clip_fraction        | 0.0764       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0814       |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.921        |\n",
      "|    value_loss           | 0.205        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 120\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 135726.74\n",
      "total_reward: 35726.74\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.671\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2201         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070388373 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.293        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0847       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    reward               | -0.21254335  |\n",
      "|    std                  | 0.914        |\n",
      "|    value_loss           | 0.194        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2196         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049808994 |\n",
      "|    clip_fraction        | 0.0601       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0968       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    reward               | 0.052909303  |\n",
      "|    std                  | 0.922        |\n",
      "|    value_loss           | 0.2          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2190        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008872043 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0903      |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -0.21935095 |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 155376.04\n",
      "total_reward: 55376.04\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.890\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2199        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011133645 |\n",
      "|    clip_fraction        | 0.0733      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0862      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2194         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057156156 |\n",
      "|    clip_fraction        | 0.068        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.103        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    reward               | 0.04356004   |\n",
      "|    std                  | 0.928        |\n",
      "|    value_loss           | 0.212        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2187         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037833403 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0873       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    reward               | -0.30146953  |\n",
      "|    std                  | 0.93         |\n",
      "|    value_loss           | 0.211        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 161947.80\n",
      "total_reward: 61947.80\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.948\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2191         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075343396 |\n",
      "|    clip_fraction        | 0.0672       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.092        |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    reward               | 0.39513633   |\n",
      "|    std                  | 0.931        |\n",
      "|    value_loss           | 0.223        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2189         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073095933 |\n",
      "|    clip_fraction        | 0.0598       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0882       |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    reward               | -0.019569937 |\n",
      "|    std                  | 0.931        |\n",
      "|    value_loss           | 0.227        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2194         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061252415 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0803       |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    reward               | 0.4732959    |\n",
      "|    std                  | 0.933        |\n",
      "|    value_loss           | 0.187        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 174306.10\n",
      "total_reward: 74306.10\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 1.065\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2190         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070625185 |\n",
      "|    clip_fraction        | 0.0637       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0937       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    reward               | 0.2827439    |\n",
      "|    std                  | 0.939        |\n",
      "|    value_loss           | 0.194        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2185         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 41           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090942895 |\n",
      "|    clip_fraction        | 0.0706       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0766       |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    reward               | 0.4556002    |\n",
      "|    std                  | 0.932        |\n",
      "|    value_loss           | 0.181        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2193         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045838812 |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0907       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    reward               | -0.14050642  |\n",
      "|    std                  | 0.933        |\n",
      "|    value_loss           | 0.224        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 160\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 169276.56\n",
      "total_reward: 69276.56\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 1.008\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2188        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004714952 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0815      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2194        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008306636 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0578      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2187         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071921935 |\n",
      "|    clip_fraction        | 0.0625       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0915       |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    reward               | -0.08556762  |\n",
      "|    std                  | 0.926        |\n",
      "|    value_loss           | 0.192        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 170\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 150456.23\n",
      "total_reward: 50456.23\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.824\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2185         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 45           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064889756 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.085        |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    reward               | -0.02785324  |\n",
      "|    std                  | 0.918        |\n",
      "|    value_loss           | 0.206        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2189        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007567362 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0925      |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    reward               | -0.17810036 |\n",
      "|    std                  | 0.927       |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2187         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009401534  |\n",
      "|    clip_fraction        | 0.0833       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.067        |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    reward               | -0.080086134 |\n",
      "|    std                  | 0.932        |\n",
      "|    value_loss           | 0.193        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 180\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 143390.87\n",
      "total_reward: 43390.87\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.756\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2182         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068605365 |\n",
      "|    clip_fraction        | 0.0612       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0796       |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    reward               | -0.14441462  |\n",
      "|    std                  | 0.932        |\n",
      "|    value_loss           | 0.185        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2185         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.007676622  |\n",
      "|    clip_fraction        | 0.0622       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0855       |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -0.060549736 |\n",
      "|    std                  | 0.925        |\n",
      "|    value_loss           | 0.196        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 190\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159615.56\n",
      "total_reward: 59615.56\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.926\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2181        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004810841 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.085       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    reward               | -0.3369594  |\n",
      "|    std                  | 0.924       |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2186        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006629691 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0663      |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    reward               | -0.15493596 |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2181        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007365311 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0876      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    reward               | 0.0960141   |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 200\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159270.09\n",
      "total_reward: 59270.09\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.918\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2176        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008006779 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0821      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    reward               | 0.26838025  |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2172         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100764865 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0731       |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    reward               | -0.006173749 |\n",
      "|    std                  | 0.927        |\n",
      "|    value_loss           | 0.18         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2165        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 55          |\n",
      "|    total_timesteps      | 120832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010017604 |\n",
      "|    clip_fraction        | 0.0727      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.059       |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    reward               | -0.01940157 |\n",
      "|    std                  | 0.926       |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 210\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 128853.02\n",
      "total_reward: 28853.02\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.569\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2160        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011808764 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0912      |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    reward               | 0.16071993  |\n",
      "|    std                  | 0.925       |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2162         |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074142944 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0837       |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    reward               | 0.1277756    |\n",
      "|    std                  | 0.92         |\n",
      "|    value_loss           | 0.207        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2162        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012855972 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0765      |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    reward               | 0.102479555 |\n",
      "|    std                  | 0.917       |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 220\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 142191.41\n",
      "total_reward: 42191.41\n",
      "total_cost: 0.00\n",
      "total_trades: 580\n",
      "Sharpe: 0.750\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2159        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008280637 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0721      |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    reward               | 0.1204493   |\n",
      "|    std                  | 0.915       |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2164        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008088551 |\n",
      "|    clip_fraction        | 0.0671      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0606      |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 0.07644665  |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2164        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008886684 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0865      |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    reward               | 0.5623318   |\n",
      "|    std                  | 0.913       |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 230\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 122690.87\n",
      "total_reward: 22690.87\n",
      "total_cost: 0.00\n",
      "total_trades: 580\n",
      "Sharpe: 0.479\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2167        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.00817726  |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0533      |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    reward               | -0.08226347 |\n",
      "|    std                  | 0.907       |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2166       |\n",
      "|    iterations           | 67         |\n",
      "|    time_elapsed         | 63         |\n",
      "|    total_timesteps      | 137216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00853752 |\n",
      "|    clip_fraction        | 0.0645     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.5        |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.109      |\n",
      "|    n_updates            | 660        |\n",
      "|    policy_gradient_loss | -0.00145   |\n",
      "|    reward               | 0.14687538 |\n",
      "|    std                  | 0.902      |\n",
      "|    value_loss           | 0.2        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2164         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 64           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068154223 |\n",
      "|    clip_fraction        | 0.0742       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0698       |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    reward               | -0.04177174  |\n",
      "|    std                  | 0.897        |\n",
      "|    value_loss           | 0.179        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 240\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 167833.73\n",
      "total_reward: 67833.73\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.999\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2169        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010417648 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.06        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    reward               | 0.061235733 |\n",
      "|    std                  | 0.895       |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2165         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011316887  |\n",
      "|    clip_fraction        | 0.0565       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0676       |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    reward               | -0.031923406 |\n",
      "|    std                  | 0.879        |\n",
      "|    value_loss           | 0.194        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2168         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 145408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008573981  |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0604       |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    reward               | -0.061697904 |\n",
      "|    std                  | 0.876        |\n",
      "|    value_loss           | 0.192        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 250\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 156755.59\n",
      "total_reward: 56755.59\n",
      "total_cost: 0.00\n",
      "total_trades: 581\n",
      "Sharpe: 0.903\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2166         |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084364135 |\n",
      "|    clip_fraction        | 0.0714       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    reward               | 0.084084466  |\n",
      "|    std                  | 0.875        |\n",
      "|    value_loss           | 0.231        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2165         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066896062 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.072        |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    reward               | 0.1505247    |\n",
      "|    std                  | 0.868        |\n",
      "|    value_loss           | 0.185        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 260\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 163295.57\n",
      "total_reward: 63295.57\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2167        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008918481 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.082       |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    reward               | -0.09516592 |\n",
      "|    std                  | 0.861       |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2165         |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086026285 |\n",
      "|    clip_fraction        | 0.0841       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.081        |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    reward               | 0.0          |\n",
      "|    std                  | 0.86         |\n",
      "|    value_loss           | 0.214        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2164        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008218252 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    reward               | -0.16379143 |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 270\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 180449.89\n",
      "total_reward: 80449.89\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.109\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2167        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009523313 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0774      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00291    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2164        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012216365 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    reward               | 0.19788024  |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2169        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018723832 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    reward               | -0.5182248  |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 280\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 174367.29\n",
      "total_reward: 74367.29\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.058\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2165        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006268013 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0779      |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    reward               | 0.0667486   |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2169        |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010018631 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0842      |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    reward               | -0.12662965 |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2166          |\n",
      "|    iterations           | 82            |\n",
      "|    time_elapsed         | 77            |\n",
      "|    total_timesteps      | 167936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009322061   |\n",
      "|    clip_fraction        | 0.0613        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.26         |\n",
      "|    explained_variance   | 0.574         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.0504        |\n",
      "|    n_updates            | 810           |\n",
      "|    policy_gradient_loss | -0.00292      |\n",
      "|    reward               | -0.0056001283 |\n",
      "|    std                  | 0.859         |\n",
      "|    value_loss           | 0.203         |\n",
      "-------------------------------------------\n",
      "day: 583, episode: 290\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 186210.13\n",
      "total_reward: 86210.13\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.167\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2165       |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 78         |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00824355 |\n",
      "|    clip_fraction        | 0.0903     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.561      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0956     |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.00475   |\n",
      "|    reward               | 0.26128057 |\n",
      "|    std                  | 0.858      |\n",
      "|    value_loss           | 0.184      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2167         |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074129365 |\n",
      "|    clip_fraction        | 0.0655       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0699       |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    reward               | -0.46464023  |\n",
      "|    std                  | 0.856        |\n",
      "|    value_loss           | 0.21         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2165        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015240686 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0589      |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    reward               | -0.4549202  |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 300\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 169381.06\n",
      "total_reward: 69381.06\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.014\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2163        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011522682 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0739      |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.00121    |\n",
      "|    reward               | -0.0378     |\n",
      "|    std                  | 0.86        |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2167        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008233016 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0491      |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.000999   |\n",
      "|    reward               | 0.13722895  |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2165        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010616392 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0526      |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    reward               | 0.20135236  |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 310\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 175793.25\n",
      "total_reward: 75793.25\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.071\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2166        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011386626 |\n",
      "|    clip_fraction        | 0.0978      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0758      |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.000644   |\n",
      "|    reward               | 0.23305812  |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2162        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009082887 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.000359   |\n",
      "|    reward               | 0.21968193  |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 0.201       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 320\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 170792.55\n",
      "total_reward: 70792.55\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.022\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2161         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075602857 |\n",
      "|    clip_fraction        | 0.0788       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0794       |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    reward               | 0.07238451   |\n",
      "|    std                  | 0.864        |\n",
      "|    value_loss           | 0.184        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2164        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007654141 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0817      |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    reward               | 0.11414336  |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2154        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 190464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008410325 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0883      |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    reward               | 0.32339954  |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.199       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 330\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 144058.60\n",
      "total_reward: 44058.60\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.765\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2152         |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.004744808  |\n",
      "|    clip_fraction        | 0.0599       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.107        |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | 0.0015       |\n",
      "|    reward               | -0.059280228 |\n",
      "|    std                  | 0.857        |\n",
      "|    value_loss           | 0.199        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2154        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 90          |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008775158 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0607      |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    reward               | -0.16214937 |\n",
      "|    std                  | 0.861       |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2152        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010470657 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    reward               | 0.12211168  |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 340\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 163404.66\n",
      "total_reward: 63404.66\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.977\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2151        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011795978 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0644      |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.000516   |\n",
      "|    reward               | -0.04788008 |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2155       |\n",
      "|    iterations           | 98         |\n",
      "|    time_elapsed         | 93         |\n",
      "|    total_timesteps      | 200704     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01023832 |\n",
      "|    clip_fraction        | 0.0923     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0867     |\n",
      "|    n_updates            | 970        |\n",
      "|    policy_gradient_loss | -0.0045    |\n",
      "|    reward               | 0.15279596 |\n",
      "|    std                  | 0.86       |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2154        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011496205 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.000167   |\n",
      "|    reward               | -0.12594451 |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 350\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 181642.80\n",
      "total_reward: 81642.80\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.117\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2155         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.005931405  |\n",
      "|    clip_fraction        | 0.0659       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0702       |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    reward               | -0.097023904 |\n",
      "|    std                  | 0.857        |\n",
      "|    value_loss           | 0.214        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2155        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008685662 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0544      |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    reward               | 0.019560846 |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2154        |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 96          |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009919657 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0854      |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    reward               | 0.009615587 |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 360\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 160072.06\n",
      "total_reward: 60072.06\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 0.931\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2157        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015038103 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0668      |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    reward               | -0.08234817 |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2157         |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111664105 |\n",
      "|    clip_fraction        | 0.0726       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0822       |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | 0.000581     |\n",
      "|    reward               | -0.010233955 |\n",
      "|    std                  | 0.881        |\n",
      "|    value_loss           | 0.189        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2160        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013002522 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0559      |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    reward               | -0.06796739 |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 370\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 176634.99\n",
      "total_reward: 76634.99\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2158        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013317214 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0808      |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -1.04e-05   |\n",
      "|    reward               | 0.045770362 |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2157        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008610543 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    reward               | -0.24040727 |\n",
      "|    std                  | 0.88        |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2159        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009550518 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0751      |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00089    |\n",
      "|    reward               | 0.057867236 |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 380\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 178535.20\n",
      "total_reward: 78535.20\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.112\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2158        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011771505 |\n",
      "|    clip_fraction        | 0.0836      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0613      |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    reward               | -0.20085496 |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2160        |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013808213 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0842      |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.87        |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 390\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 153708.71\n",
      "total_reward: 53708.71\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.856\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2159         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062953075 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0665       |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -3.86e-05    |\n",
      "|    reward               | 0.25443023   |\n",
      "|    std                  | 0.86         |\n",
      "|    value_loss           | 0.187        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2159        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009509785 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0574      |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    reward               | -0.30107954 |\n",
      "|    std                  | 0.869       |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2160        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016103057 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0592      |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    reward               | 0.42277235  |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 400\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 175971.90\n",
      "total_reward: 75971.90\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.080\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2159         |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014294862  |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0703       |\n",
      "|    n_updates            | 1130         |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    reward               | -0.076759756 |\n",
      "|    std                  | 0.868        |\n",
      "|    value_loss           | 0.178        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2162        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007883726 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0709      |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.000261   |\n",
      "|    reward               | 0.55229205  |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2161        |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011387986 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | 0.26384392  |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 410\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 186730.67\n",
      "total_reward: 86730.67\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.181\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2160         |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109836785 |\n",
      "|    clip_fraction        | 0.0913       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0974       |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.000514    |\n",
      "|    reward               | 0.4936802    |\n",
      "|    std                  | 0.859        |\n",
      "|    value_loss           | 0.183        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2162        |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 241664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018219117 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0681      |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    reward               | -0.13023739 |\n",
      "|    std                  | 0.864       |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2161        |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011130039 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0681      |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 420\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 194014.73\n",
      "total_reward: 94014.73\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.244\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2163        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013488922 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0787      |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    reward               | -0.1405241  |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2163        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 114         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017719937 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0727      |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.000107   |\n",
      "|    reward               | -0.08523163 |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2166         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 115          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.017147636  |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0912       |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    reward               | -0.029715188 |\n",
      "|    std                  | 0.853        |\n",
      "|    value_loss           | 0.185        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 430\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 176726.60\n",
      "total_reward: 76726.60\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.097\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2164        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 251904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010844994 |\n",
      "|    clip_fraction        | 0.0889      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0919      |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.000194   |\n",
      "|    reward               | -0.2019384  |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2163         |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016318498  |\n",
      "|    clip_fraction        | 0.0845       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    reward               | -0.101624906 |\n",
      "|    std                  | 0.848        |\n",
      "|    value_loss           | 0.208        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2165        |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 256000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009992601 |\n",
      "|    clip_fraction        | 0.0925      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0631      |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    reward               | -0.17831478 |\n",
      "|    std                  | 0.847       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 440\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 189341.08\n",
      "total_reward: 89341.08\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.206\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2164         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010106526  |\n",
      "|    clip_fraction        | 0.0794       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.625        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0641       |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.000705    |\n",
      "|    reward               | -0.057469748 |\n",
      "|    std                  | 0.847        |\n",
      "|    value_loss           | 0.191        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2163        |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 120         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012049829 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0689      |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    reward               | -0.3283194  |\n",
      "|    std                  | 0.844       |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2164        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011091322 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.058       |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    reward               | -0.17312595 |\n",
      "|    std                  | 0.835       |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 450\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 171399.87\n",
      "total_reward: 71399.87\n",
      "total_cost: 0.00\n",
      "total_trades: 582\n",
      "Sharpe: 1.042\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2163        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010802576 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0601      |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | 2.88e-05    |\n",
      "|    reward               | 0.09052409  |\n",
      "|    std                  | 0.832       |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2165        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013456186 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0697      |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | 0.000788    |\n",
      "|    reward               | 0.2837362   |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 460\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 184300.72\n",
      "total_reward: 84300.72\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.153\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 2164          |\n",
      "|    iterations           | 131           |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 268288        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011706004   |\n",
      "|    clip_fraction        | 0.106         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.23         |\n",
      "|    explained_variance   | 0.577         |\n",
      "|    learning_rate        | 0.00025       |\n",
      "|    loss                 | 0.0386        |\n",
      "|    n_updates            | 1300          |\n",
      "|    policy_gradient_loss | -0.00262      |\n",
      "|    reward               | -0.0065517332 |\n",
      "|    std                  | 0.826         |\n",
      "|    value_loss           | 0.164         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2163         |\n",
      "|    iterations           | 132          |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015125555  |\n",
      "|    clip_fraction        | 0.0885       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0526       |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    reward               | -0.025868762 |\n",
      "|    std                  | 0.819        |\n",
      "|    value_loss           | 0.169        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2165       |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 125        |\n",
      "|    total_timesteps      | 272384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0317133  |\n",
      "|    clip_fraction        | 0.0809     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0832     |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | -0.00177   |\n",
      "|    reward               | 0.28576785 |\n",
      "|    std                  | 0.814      |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "day: 583, episode: 470\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 162827.47\n",
      "total_reward: 62827.47\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.940\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2165        |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019011278 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0864      |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    reward               | 0.11915163  |\n",
      "|    std                  | 0.819       |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2167        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013544355 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0526      |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    reward               | 0.09925957  |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2166        |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0155496   |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 1350        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    reward               | 0.007007959 |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 0.226       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 480\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159261.30\n",
      "total_reward: 59261.30\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.937\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2165         |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081893485 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0539       |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.000487    |\n",
      "|    reward               | 0.06742558   |\n",
      "|    std                  | 0.829        |\n",
      "|    value_loss           | 0.16         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2168       |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 130        |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01911186 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0489     |\n",
      "|    n_updates            | 1370       |\n",
      "|    policy_gradient_loss | -0.000358  |\n",
      "|    reward               | 0.5505398  |\n",
      "|    std                  | 0.826      |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2168         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.018744586  |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0748       |\n",
      "|    n_updates            | 1380         |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    reward               | -0.073631525 |\n",
      "|    std                  | 0.827        |\n",
      "|    value_loss           | 0.17         |\n",
      "------------------------------------------\n",
      "day: 583, episode: 490\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 190634.15\n",
      "total_reward: 90634.15\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.209\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2168        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017914806 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0996      |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    reward               | 0.17578046  |\n",
      "|    std                  | 0.824       |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2170        |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018030725 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.079       |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | 0.00272     |\n",
      "|    reward               | -0.04501672 |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2169        |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009447262 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0559      |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    reward               | 0.0688797   |\n",
      "|    std                  | 0.835       |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 500\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 154099.55\n",
      "total_reward: 54099.55\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.855\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2171        |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 134         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013899288 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0717      |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.000374   |\n",
      "|    reward               | -0.03656932 |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2170        |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021243151 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.000958   |\n",
      "|    reward               | -0.3914814  |\n",
      "|    std                  | 0.847       |\n",
      "|    value_loss           | 0.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2172        |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011679221 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0592      |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.000221   |\n",
      "|    reward               | 0.10296057  |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 510\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 178610.87\n",
      "total_reward: 78610.87\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2171        |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 137         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018731616 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    reward               | 0.18085265  |\n",
      "|    std                  | 0.849       |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2171         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.016972525  |\n",
      "|    clip_fraction        | 0.0919       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0567       |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | 0.000844     |\n",
      "|    reward               | -0.117962904 |\n",
      "|    std                  | 0.854        |\n",
      "|    value_loss           | 0.176        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 520\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 153989.94\n",
      "total_reward: 53989.94\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.854\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2172        |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 139         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008555219 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0674      |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | 0.000768    |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2171        |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011847908 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0702      |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | 0.00038     |\n",
      "|    reward               | -0.16727144 |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2173        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015588723 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0413      |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    reward               | 0.07175531  |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 530\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 165068.74\n",
      "total_reward: 65068.74\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.957\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2173        |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016591428 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -3.94e-05   |\n",
      "|    reward               | 0.19303523  |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2172       |\n",
      "|    iterations           | 152        |\n",
      "|    time_elapsed         | 143        |\n",
      "|    total_timesteps      | 311296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01509871 |\n",
      "|    clip_fraction        | 0.085      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0838     |\n",
      "|    n_updates            | 1510       |\n",
      "|    policy_gradient_loss | 0.000651   |\n",
      "|    reward               | -0.5135208 |\n",
      "|    std                  | 0.866      |\n",
      "|    value_loss           | 0.164      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2174        |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012311304 |\n",
      "|    clip_fraction        | 0.0798      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0741      |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    reward               | 0.065354586 |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 540\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 184749.53\n",
      "total_reward: 84749.53\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.155\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2173        |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011281071 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0693      |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.000579   |\n",
      "|    reward               | -0.11979567 |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2175         |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 145          |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013578378  |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.07         |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | 0.00306      |\n",
      "|    reward               | -0.006256143 |\n",
      "|    std                  | 0.853        |\n",
      "|    value_loss           | 0.156        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2174        |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013954449 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0987      |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.00044    |\n",
      "|    reward               | 0.25355256  |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 550\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159259.53\n",
      "total_reward: 59259.53\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.902\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2173        |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 321536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02565344  |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0639      |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    reward               | -0.46585023 |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2175        |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012153309 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0541      |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.000473   |\n",
      "|    reward               | -0.47124022 |\n",
      "|    std                  | 0.865       |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2174        |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017217305 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0564      |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    reward               | -0.14315    |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 560\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 167532.15\n",
      "total_reward: 67532.15\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.982\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2173        |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014799364 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.000165   |\n",
      "|    reward               | 0.14169498  |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2175        |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 329728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011339439 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0841      |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | 0.00197     |\n",
      "|    reward               | 0.21192133  |\n",
      "|    std                  | 0.856       |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2172        |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013703644 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0417      |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    reward               | 0.22983612  |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 570\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159555.48\n",
      "total_reward: 59555.48\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.931\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2172        |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012537691 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0419      |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    reward               | 0.24757805  |\n",
      "|    std                  | 0.854       |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2173        |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016117524 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0754      |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | 0.000483    |\n",
      "|    reward               | 0.06537646  |\n",
      "|    std                  | 0.852       |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2173       |\n",
      "|    iterations           | 165        |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 337920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0237168  |\n",
      "|    clip_fraction        | 0.0798     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.669      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.0733     |\n",
      "|    n_updates            | 1640       |\n",
      "|    policy_gradient_loss | 0.000276   |\n",
      "|    reward               | 0.12910728 |\n",
      "|    std                  | 0.846      |\n",
      "|    value_loss           | 0.165      |\n",
      "----------------------------------------\n",
      "day: 583, episode: 580\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 176037.05\n",
      "total_reward: 76037.05\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.076\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2175        |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 156         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016209729 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0759      |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | 0.00263     |\n",
      "|    reward               | 0.2947996   |\n",
      "|    std                  | 0.847       |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2174         |\n",
      "|    iterations           | 167          |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 342016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134038925 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0519       |\n",
      "|    n_updates            | 1660         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    reward               | -0.061120234 |\n",
      "|    std                  | 0.847        |\n",
      "|    value_loss           | 0.167        |\n",
      "------------------------------------------\n",
      "day: 583, episode: 590\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 190470.48\n",
      "total_reward: 90470.48\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.220\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2173        |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010243873 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0533      |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | 0.000502    |\n",
      "|    reward               | -0.16050437 |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2175        |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012145979 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0675      |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | 0.00135     |\n",
      "|    reward               | 0.010098056 |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2174        |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498313 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    reward               | -0.04701608 |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 600\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 153005.86\n",
      "total_reward: 53005.86\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.850\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2173        |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 350208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011111867 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.000648   |\n",
      "|    reward               | 0.17034395  |\n",
      "|    std                  | 0.855       |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2175        |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011334337 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.061       |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    reward               | -0.12630852 |\n",
      "|    std                  | 0.845       |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2175        |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.02418264  |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0585      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    reward               | -0.09779191 |\n",
      "|    std                  | 0.844       |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 610\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 188359.55\n",
      "total_reward: 88359.55\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.190\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2174        |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016761698 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0514      |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | 0.000564    |\n",
      "|    reward               | 0.021761829 |\n",
      "|    std                  | 0.848       |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2176        |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0193833   |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0556      |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.000429   |\n",
      "|    reward               | 0.011610708 |\n",
      "|    std                  | 0.841       |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2176        |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013019247 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -1.97e-05   |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 620\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 173629.89\n",
      "total_reward: 73629.89\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.044\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2178         |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.015334295  |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.072        |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | 0.00185      |\n",
      "|    reward               | -0.011101952 |\n",
      "|    std                  | 0.836        |\n",
      "|    value_loss           | 0.173        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2177        |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013596915 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0933      |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | 0.00158     |\n",
      "|    reward               | -0.06585541 |\n",
      "|    std                  | 0.841       |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2177        |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 366592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017068857 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.063       |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -6.13e-05   |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.833       |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 630\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 188755.13\n",
      "total_reward: 88755.13\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.204\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2179        |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012669815 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0838      |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | 0.000686    |\n",
      "|    reward               | -0.22777131 |\n",
      "|    std                  | 0.838       |\n",
      "|    value_loss           | 0.174       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2179        |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.0156877   |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0793      |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -4.29e-05   |\n",
      "|    reward               | 0.060383204 |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2181        |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022480285 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0784      |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | 0.000795    |\n",
      "|    reward               | -0.20143296 |\n",
      "|    std                  | 0.841       |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 640\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 152656.50\n",
      "total_reward: 52656.50\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2180         |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 374784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01953046   |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.641        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0828       |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    reward               | -0.046000887 |\n",
      "|    std                  | 0.843        |\n",
      "|    value_loss           | 0.181        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2181        |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011118149 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0875      |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.000702   |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.837       |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2182        |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 173         |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020164281 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    reward               | -0.28547955 |\n",
      "|    std                  | 0.826       |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 650\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 167705.54\n",
      "total_reward: 67705.54\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.001\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2182        |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021350604 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0702      |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    reward               | 0.43864837  |\n",
      "|    std                  | 0.823       |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2184        |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010914093 |\n",
      "|    clip_fraction        | 0.0986      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0711      |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | 0.0018      |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.837       |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 660\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 189833.17\n",
      "total_reward: 89833.17\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.216\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2183        |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020837212 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0872      |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | 0.000742    |\n",
      "|    reward               | 0.46103787  |\n",
      "|    std                  | 0.838       |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2183        |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013342297 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0584      |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00074    |\n",
      "|    reward               | 0.3073139   |\n",
      "|    std                  | 0.839       |\n",
      "|    value_loss           | 0.183       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2185        |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 178         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011911686 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.658       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.000344   |\n",
      "|    reward               | 0.47940022  |\n",
      "|    std                  | 0.839       |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 670\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 159922.26\n",
      "total_reward: 59922.26\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 0.917\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2185        |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008854322 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0769      |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | 0.00262     |\n",
      "|    reward               | -0.10839532 |\n",
      "|    std                  | 0.836       |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2186        |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013024578 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0426      |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.000348   |\n",
      "|    reward               | 0.0         |\n",
      "|    std                  | 0.831       |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2185        |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016680142 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0866      |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.000583   |\n",
      "|    reward               | -0.1369121  |\n",
      "|    std                  | 0.834       |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "day: 583, episode: 680\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 174067.80\n",
      "total_reward: 74067.80\n",
      "total_cost: 0.00\n",
      "total_trades: 583\n",
      "Sharpe: 1.060\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2185         |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 181          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011879644  |\n",
      "|    clip_fraction        | 0.0991       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.0475       |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.000751    |\n",
      "|    reward               | -0.073919676 |\n",
      "|    std                  | 0.831        |\n",
      "|    value_loss           | 0.181        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2186         |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013062678  |\n",
      "|    clip_fraction        | 0.0799       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 0.106        |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | 0.00164      |\n",
      "|    reward               | -0.009613737 |\n",
      "|    std                  | 0.831        |\n",
      "|    value_loss           | 0.202        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2186        |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012243945 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0968      |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    reward               | -0.22440645 |\n",
      "|    std                  | 0.83        |\n",
      "|    value_loss           | 0.179       |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=400000) if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_ppo.save(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
    "\n",
    "if if_using_td3:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/td3'\n",
    "  new_logger_td3 = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_td3.set_logger(new_logger_td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=50000) if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_td3.save(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.00025, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
    "\n",
    "if if_using_sac:\n",
    "  # set up logger\n",
    "  tmp_path = RESULTS_DIR + '/sac'\n",
    "  new_logger_sac = configure(tmp_path, [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "  # Set new logger\n",
    "  model_sac.set_logger(new_logger_sac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=50000) if if_using_sac else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_sac.save(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preparation for backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, we load the delayed data if we have restarted the process (not needed)\n",
    "train = pd.read_csv(DATA_DIR + '/train_data.csv')\n",
    "trade = pd.read_csv(DATA_DIR + '/trade_data.csv')\n",
    "\n",
    "train = train.set_index(train.columns[0])\n",
    "train.index.names = ['']\n",
    "trade = trade.set_index(trade.columns[0])\n",
    "trade.index.names = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary, we load the delayed training data if we have restarted the process (not needed)\n",
    "if_using_a2c = False\n",
    "if_using_ddpg = False\n",
    "if_using_ppo = True\n",
    "if_using_td3 = False\n",
    "if_using_sac = False\n",
    "\n",
    "trained_a2c = A2C.load(TRAINED_MODEL_DIR + \"/agent_a2c\") if if_using_a2c else None\n",
    "trained_ddpg = DDPG.load(TRAINED_MODEL_DIR + \"/agent_ddpg\") if if_using_ddpg else None\n",
    "trained_ppo = PPO.load(TRAINED_MODEL_DIR + \"/agent_ppo\") if if_using_ppo else None\n",
    "trained_td3 = TD3.load(TRAINED_MODEL_DIR + \"/agent_td3\") if if_using_td3 else None\n",
    "trained_sac = SAC.load(TRAINED_MODEL_DIR + \"/agent_sac\") if if_using_sac else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Trading (data outside the training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we now use the trade dataset for trading, which has never been used for training. Additionally, with a similar approach, we could fine-tune the existing saved model.\n",
    "\n",
    "Numerous hyperparameters, such as the learning rate and the total number of training samples, affect the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 1, State Space: 11\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(trade.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_cost_list = sell_cost_list = [0] * stock_dimension\n",
    "num_stock_shares = [0] * stock_dimension\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 1000,\n",
    "    \"initial_amount\": 100000,\n",
    "    \"num_stock_shares\": num_stock_shares,\n",
    "    \"buy_cost_pct\": buy_cost_list,\n",
    "    \"sell_cost_pct\": sell_cost_list,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section relates to the use of deep reinforcement learning (DRL) for simulating real-time trading using a previously trained model (in this case, A2C). StockTradingEnv is an environment that simulates the stock market based on historical data, a turbulence threshold (which is used to determine market volatility), and 'VIX' as a risk indicator. After initializing the environment, the get_sb_env() method is used to retrieve the environment and initial observations that are compatible with the Stable Baselines library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of the trading environment with the defined DataFrame 'trade', turbulence threshold, and risk indicator 'vix',\n",
    "# along with other environment parameters ('env_kwargs').\n",
    "e_trade_gym = StockTradingEnv(df = trade, **env_kwargs)\n",
    "\n",
    "# Retrieving the environment compatible with Stable Baselines and initial observations.\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DRL agent is then used to predict trading actions and changes in account value based on the trained model. This allows for the evaluation of the model's performance in an out-of-sample scenario, providing insight into how the model might perform in real trading conditions. If the use of the A2C algorithm is selected (as indicated by the variable if_using_a2c), predictions are made; otherwise, the result is set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the DRL agent for prediction using the trained model 'trained_a2c' and the defined trading environment 'e_trade_gym'.\n",
    "# The results are two DataFrames: 'df_account_value_a2c' with account values and 'df_actions_a2c' with the actions taken,\n",
    "# if 'if_using_a2c' is set to True; otherwise, it returns (None, None).\n",
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, \n",
    "    environment = e_trade_gym) if if_using_a2c else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, \n",
    "    environment = e_trade_gym) if if_using_ddpg else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_account_value_ppo, df_actions_ppo = DRLAgent.DRL_prediction(\n",
    "    model=trained_ppo, \n",
    "    environment = e_trade_gym) if if_using_ppo else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_td3, df_actions_td3 = DRLAgent.DRL_prediction(\n",
    "    model=trained_td3, \n",
    "    environment = e_trade_gym) if if_using_td3 else (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_account_value_sac, df_actions_sac = DRLAgent.DRL_prediction(\n",
    "    model=trained_sac, \n",
    "    environment = e_trade_gym) if if_using_sac else (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. B&H for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (144, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_aapl = YahooDownloader(start_date = TRADE_START_DATE,\n",
    "                     end_date = TRADE_END_DATE,\n",
    "                     ticker_list = ['AAPL']).fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aapl = df_aapl[['date','close']]\n",
    "fst_day = df_aapl['close'].iloc[0]\n",
    "buy_and_hold = pd.merge(df_aapl['date'], df_aapl['close'].div(fst_day).mul(100000), \n",
    "                        how='outer', left_index=True, right_index=True).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Backtesting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the index of the account value DataFrames for each of the DRL strategies, if selected.\n",
    "df_result_a2c = df_account_value_a2c.set_index(df_account_value_a2c.columns[0]) if if_using_a2c else None\n",
    "df_result_ddpg = df_account_value_ddpg.set_index(df_account_value_ddpg.columns[0]) if if_using_ddpg else None\n",
    "df_result_ppo = df_account_value_ppo.set_index(df_account_value_ppo.columns[0]) if if_using_ppo else None\n",
    "df_result_td3 = df_account_value_td3.set_index(df_account_value_td3.columns[0]) if if_using_td3 else None\n",
    "df_result_sac = df_account_value_sac.set_index(df_account_value_sac.columns[0]) if if_using_sac else None\n",
    "\n",
    "# Creating an empty DataFrame for results.\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# Merging the results of all DRL strategies into one DataFrame, if selected.\n",
    "if if_using_a2c: result = pd.merge(result, df_result_a2c, how='outer', left_index=True, right_index=True)\n",
    "if if_using_ddpg: result = pd.merge(result, df_result_ddpg, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_ppo: result = pd.merge(result, df_result_ppo, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_td3: result = pd.merge(result, df_result_td3, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "if if_using_sac: result = pd.merge(result, df_result_sac, how='outer', left_index=True, right_index=True, suffixes=('', '_drop'))\n",
    "\n",
    "# Merging the results of the mean variance optimization and the DJIA index with the main results.\n",
    "result = pd.merge(result, buy_and_hold, how='outer', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column names based on the selected strategies.\n",
    "col_name = []\n",
    "col_name.append('A2C') if if_using_a2c else None\n",
    "col_name.append('DDPG') if if_using_ddpg else None\n",
    "col_name.append('PPO') if if_using_ppo else None\n",
    "col_name.append('TD3') if if_using_td3 else None\n",
    "col_name.append('SAC') if if_using_sac else None\n",
    "col_name.append('B&H')\n",
    "result.columns = col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPO</th>\n",
       "      <th>B&amp;H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-02</th>\n",
       "      <td>97677.099457</td>\n",
       "      <td>97673.485165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>97677.099457</td>\n",
       "      <td>88732.896854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-06</th>\n",
       "      <td>100720.002747</td>\n",
       "      <td>91500.649605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-07</th>\n",
       "      <td>100720.002747</td>\n",
       "      <td>92213.753353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PPO            B&H\n",
       "date                                    \n",
       "2024-08-01  100000.000000  100000.000000\n",
       "2024-08-02   97677.099457   97673.485165\n",
       "2024-08-05   97677.099457   88732.896854\n",
       "2024-08-06  100720.002747   91500.649605\n",
       "2024-08-07  100720.002747   92213.753353"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the results\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we plot a graph that shows the total portfolio value over time for each strategy and the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='date'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the figure size for the plots and drawing the performance charts of the trading strategies.\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
    "plt.figure()\n",
    "result.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the portfolio values, we calculate daily returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/0nrxt8bn57bdz8wy1xv7fb6m0000gn/T/ipykernel_66914/597744444.py:11: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  result[f'{strategy}_returns'] = result[column_name].pct_change()\n"
     ]
    }
   ],
   "source": [
    "from pyfolio import timeseries\n",
    "import pandas as pd\n",
    "\n",
    "# List of strategies for which you want to generate statistics\n",
    "strategies = ['A2C', 'DDPG', 'PPO', 'TD3', 'SAC', \"B&H\"]\n",
    "\n",
    "for strategy in strategies:\n",
    "    column_name = f'{strategy}'\n",
    "    if column_name in result.columns:\n",
    "        # Calculating daily returns from portfolio values\n",
    "        result[f'{strategy}_returns'] = result[column_name].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PPO</th>\n",
       "      <th>B&amp;H</th>\n",
       "      <th>PPO_returns</th>\n",
       "      <th>B&amp;H_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-02</th>\n",
       "      <td>97677.099457</td>\n",
       "      <td>97673.485165</td>\n",
       "      <td>-0.023229</td>\n",
       "      <td>-0.023265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-05</th>\n",
       "      <td>97677.099457</td>\n",
       "      <td>88732.896854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.091535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-06</th>\n",
       "      <td>100720.002747</td>\n",
       "      <td>91500.649605</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.031192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-07</th>\n",
       "      <td>100720.002747</td>\n",
       "      <td>92213.753353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      PPO            B&H  PPO_returns  B&H_returns\n",
       "date                                                              \n",
       "2024-08-01  100000.000000  100000.000000          NaN          NaN\n",
       "2024-08-02   97677.099457   97673.485165    -0.023229    -0.023265\n",
       "2024-08-05   97677.099457   88732.896854     0.000000    -0.091535\n",
       "2024-08-06  100720.002747   91500.649605     0.031153     0.031192\n",
       "2024-08-07  100720.002747   92213.753353     0.000000     0.007793"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating returns for the selected strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategy A2C was not found in the results.\n",
      "\n",
      "Strategy DDPG was not found in the results.\n",
      "\n",
      "==============Strategy Stats (PPO)==============\n",
      "Annual return          0.066794\n",
      "Cumulative returns     0.037372\n",
      "Annual volatility      0.189044\n",
      "Sharpe ratio           0.436970\n",
      "Calmar ratio           0.536759\n",
      "Stability              0.051560\n",
      "Max drawdown          -0.124439\n",
      "Omega ratio            1.101078\n",
      "Sortino ratio          0.575544\n",
      "Skew                  -1.343737\n",
      "Kurtosis               8.344390\n",
      "Tail ratio             1.107375\n",
      "Daily value at risk   -0.023489\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Strategy TD3 was not found in the results.\n",
      "\n",
      "Strategy SAC was not found in the results.\n",
      "\n",
      "==============Strategy Stats (B&H)==============\n",
      "Annual return          0.121129\n",
      "Cumulative returns     0.067032\n",
      "Annual volatility      0.262701\n",
      "Sharpe ratio           0.568393\n",
      "Calmar ratio           0.814433\n",
      "Stability              0.426793\n",
      "Max drawdown          -0.148728\n",
      "Omega ratio            1.110614\n",
      "Sortino ratio          0.717096\n",
      "Skew                  -1.756746\n",
      "Kurtosis               7.616596\n",
      "Tail ratio             0.970082\n",
      "Daily value at risk   -0.032505\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We assume that the result DataFrame already contains portfolio values for each strategy\n",
    "for strategy in strategies:\n",
    "    # Check if the strategy exists in the DataFrame\n",
    "    if f'{strategy}_returns' in result.columns:\n",
    "        # Extract daily returns for the current strategy\n",
    "        returns = result[f'{strategy}_returns'].dropna()\n",
    "        returns.index = pd.to_datetime(returns.index)\n",
    "\n",
    "        # Calculate performance statistics for the current strategy\n",
    "        perf_stats = timeseries.perf_stats(returns=returns, factor_returns=None, positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "\n",
    "        # Print performance statistics\n",
    "        print(f\"==============Strategy Stats ({strategy})==============\")\n",
    "        print(perf_stats)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(f\"Strategy {strategy} was not found in the results.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting cumulative returns for each strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# Setting the figure size for the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Iterating through each strategy and plotting its cumulative returns\n",
    "for strategy in strategies:\n",
    "    if f'{strategy}_returns' in result.columns:\n",
    "        # Make sure dates are properly parsed\n",
    "        result.index = pd.to_datetime(result.index)\n",
    "        \n",
    "        # Extracting daily returns for the current strategy and converting to decimal format if necessary\n",
    "        returns = result[f'{strategy}_returns'].dropna() + 1  # Adds 1 for using cumprod()\n",
    "        \n",
    "        # Calculating cumulative returns and converting to percentage\n",
    "        cumulative_returns = (returns.cumprod() - 1) * 100  # Convert to percentage\n",
    "        \n",
    "        # Plotting cumulative returns with original colors\n",
    "        plt.plot(cumulative_returns.index, cumulative_returns, label=strategy)\n",
    "\n",
    "# Format y-axis as percentages\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0f}%'.format(y)))\n",
    "plt.ylabel('Cumulative Returns (%)')\n",
    "plt.xlabel('Date')\n",
    "\n",
    "# Format x-axis dates\n",
    "plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# Make sure dates are in the correct format and rotated\n",
    "plt.gcf().autofmt_xdate()\n",
    "\n",
    "# Adding title and legend\n",
    "#plt.title('Cumulative Returns of DRL Strategies')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Add grid with light gray color\n",
    "plt.grid(True, linestyle='-', alpha=0.2)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results to CSV\n",
    "Needs to be changed for each agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# For df_account_value_ppo\n",
    "with open('results/1. AAPL/aapl_finrl_df_account_value_ppo.pkl', 'wb') as f:\n",
    "    pickle.dump(df_account_value_ppo, f)\n",
    "    \n",
    "# For df_actions_ppo\n",
    "with open('results/1. AAPL/aapl_finrl_df_actions_ppo.pkl', 'wb') as f:\n",
    "    pickle.dump(df_actions_ppo, f)\n",
    "\n",
    "# For buy_and_hold\n",
    "with open('results/1. AAPL/aapl_finrl_buy_and_hold.pkl', 'wb') as f:\n",
    "    pickle.dump(buy_and_hold, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
