{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Feature Generation for PrimoGPT Training\n",
    "\n",
    "This notebook is responsible for collecting and processing stock data that will be used to train the PrimoGPT model. The process involves:\n",
    "\n",
    "1. Downloading historical stock data, news, and press releases using Finnhub and Yahoo Finance APIs\n",
    "2. Processing this data through GPT-4 to generate labeled features for training\n",
    "3. Saving both processed data in structured formats\n",
    "\n",
    "## Key Parameters\n",
    "- `is_for_train=True`: Enables special prompt template that includes future price information\n",
    "- `custom_gpt=False`: Uses GPT-4o instead of custom PrimoGPT model for feature generation (in this moment we don't have custom model)\n",
    "\n",
    "## Process Flow\n",
    "1. Downloads stock price data and calculates returns\n",
    "2. Fetches relevant news and press releases\n",
    "3. Processes each day's data through GPT-4 to generate features like:\n",
    "   - News relevance (0-2)\n",
    "   - Sentiment (-1 to 1)\n",
    "   - Price impact potential (-3 to 3)\n",
    "   - Trend direction (-1 to 1)\n",
    "   - Earnings impact (-2 to 2)\n",
    "   - Investor confidence (-3 to 3)\n",
    "   - Risk profile change (-2 to 2)\n",
    "\n",
    "## Related Files\n",
    "- `primogpt/prepare_data.py`: Handles data collection and preprocessing\n",
    "- `primogpt/create_prompt.py`: Manages prompt engineering and GPT interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules and set up paths\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from primogpt.create_prompt import *\n",
    "from primogpt.prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stock symbol and date range for data collection\n",
    "stock_symbol = \"AMD\"\n",
    "start_date = \"2021-09-01\"\n",
    "end_date = \"2024-07-31\"\n",
    "\n",
    "# Create directory for storing data\n",
    "data_dir = f\"data/{stock_symbol}_{start_date}_{end_date}\"\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads and processes raw stock data\n",
    "prepare_data_for_symbol(stock_symbol, data_dir, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output CSV filename\n",
    "csv_file_name = f\"{stock_symbol}_{start_date}_{end_date}.csv\"\n",
    "csv_file_path = os.path.join(data_dir, csv_file_name)\n",
    "\n",
    "# Load and display raw data for verification\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample news content to verify data quality\n",
    "news_content = df.loc[1, 'News']\n",
    "news_content_json = json.loads(news_content) \n",
    "\n",
    "print(\"News:\")\n",
    "for news_item in news_content_json:\n",
    "    print(f\"Date: {news_item['date']}, Headline: {news_item['headline']}, Summary: {news_item['summary']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample press releases to verify data quality\n",
    "press_releases = df.loc[1, 'PressReleases']\n",
    "press_releases_json = json.loads(press_releases)\n",
    "\n",
    "print(\"Press Releases:\")\n",
    "for release in press_releases_json:\n",
    "    print(f\"Date: {release['date']}, Headline: {release['headline']}, Description: {release['description']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates features using GPT-4o and saves results to CSV\n",
    "results = process_stock_data(stock_symbol, data_dir, start_date, end_date, is_for_train=True, custom_gpt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display processed data with GPT-generated features\n",
    "csv_file_name = f\"{stock_symbol}_{start_date}_{end_date}_gpt.csv\"\n",
    "csv_file_path = os.path.join(data_dir, csv_file_name)\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
