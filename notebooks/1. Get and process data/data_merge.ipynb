{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merging and Filtering for PrimoGPT Training\n",
    "\n",
    "This notebook handles the merging and filtering of GPT-generated features from multiple stock datasets. It processes JSON files containing GPT-4's responses and prepares them for training the PrimoGPT model.\n",
    "\n",
    "## Key Functions\n",
    "1. Loading and merging multiple JSON files containing GPT responses\n",
    "2. Parsing and validating GPT-generated feature values\n",
    "3. Filtering out invalid or zero-value samples\n",
    "4. Saving the cleaned, merged dataset\n",
    "\n",
    "## Process Flow\n",
    "1. Loads all JSON files from the data directory\n",
    "2. Parses GPT responses and validates feature values\n",
    "3. Filters out samples where all features are zero or invalid\n",
    "4. Saves the merged and filtered dataset for model training\n",
    "\n",
    "## Data Quality Checks\n",
    "- Validates JSON response format\n",
    "- Ensures non-zero feature values\n",
    "- Converts all feature values to consistent string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and combine all JSON files from a directory\n",
    "def load_json_files(directory):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.json'):\n",
    "            with open(os.path.join(directory, filename), 'r') as file:\n",
    "                data.extend(json.load(file))\n",
    "    return data\n",
    "\n",
    "# Function to parse GPT response and extract feature values\n",
    "def parse_response(response_str):\n",
    "    match = re.search(r'\\{.*\\}', response_str)\n",
    "    if match:\n",
    "        try:\n",
    "            response_dict = json.loads(match.group())\n",
    "            # Convert all values to strings and replace None with '0'\n",
    "            return {k: str(v) if v is not None else '0' for k, v in response_dict.items()}\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Function to filter samples based on feature values\n",
    "def filter_samples(data):\n",
    "    filtered_data = []\n",
    "    removed_samples = []\n",
    "    \n",
    "    for sample in data:\n",
    "        response = parse_response(sample['response'])\n",
    "        # Keep sample if at least one feature has non-zero value\n",
    "        if response and any(int(value) != 0 if value is not None else False for value in response.values()):\n",
    "            filtered_data.append(sample)\n",
    "        else:\n",
    "            removed_samples.append(sample)\n",
    "    \n",
    "    return filtered_data, removed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all JSON files from the @data directory\n",
    "data_directory = Path('data')\n",
    "all_samples = load_json_files(data_directory)\n",
    "\n",
    "# Filter samples\n",
    "#filtered_samples, removed_samples = filter_samples(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(f\"Total samples before filtering: {len(all_samples)}\")\n",
    "print(f\"Total samples after filtering: {len(filtered_samples)}\")\n",
    "print(f\"Number of samples removed: {len(removed_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered samples to a new JSON file\n",
    "output_file = data_directory / 'filtered_samples.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(all_samples, f, indent=2)\n",
    "\n",
    "print(f\"\\nFiltered samples saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
